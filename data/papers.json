[
  {
    "id": "2.1",
    "session": 2,
    "title": "AMD Instinct MI350 Series GPUs: CDNA 4-Based 3D-Stacked 3nm XCDs and 6nm IODs for AI Applications",
    "title_zh": "AMD Instinct MI350系列GPU：基于CDNA 4架构的3D堆叠3nm XCD与6nm IOD AI处理器",
    "title_annotation": {
      "segments": [
        {
          "text": "AMD Instinct MI350",
          "meaning": "AMD旗舰AI加速卡系列",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "CDNA 4",
          "meaning": "第4代计算DNA架构",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "3D-Stacked",
          "meaning": "三维堆叠封装",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "3nm XCDs",
          "meaning": "3nm加速计算芯粒",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "6nm IODs",
          "meaning": "6nm I/O芯粒",
          "color": "#3498db",
          "type": "system"
        }
      ]
    },
    "challenges": [
      {
        "text": "AI算力需求增长但功耗受限于封装散热",
        "related_idea_idx": 0,
        "text_en": "AI compute demand growth but power constrained by package thermal limitations"
      },
      {
        "text": "3nm高密度设计导致电流密度和电压跌落加剧",
        "related_idea_idx": 1,
        "text_en": "3nm high density design leads to increased current density and voltage supply droop"
      },
      {
        "text": "数据搬运功耗占比大制约HBM带宽能效",
        "related_idea_idx": 2,
        "text_en": "Data movement power consumption constrains HBM bandwidth power efficiency"
      },
      {
        "text": "计算单元动态功耗随吞吐提升显著增加",
        "related_idea_idx": 3,
        "text_en": "Compute unit dynamic power increases significantly with throughput scaling"
      }
    ],
    "ideas": [
      {
        "text": "异构3D堆叠架构集成8个3nm XCD与6nm IOD",
        "type": "system",
        "color": "#3498db",
        "text_en": "Heterogeneous 3D-stacked architecture integrates eight 3nm XCD with 6nm IOD"
      },
      {
        "text": "自适应时钟与去耦电容协同抑制电压跌落",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Advanced di/dt-based adaptive clocking with decoupling capacitance mitigates voltage droop"
      },
      {
        "text": "IOD合并与互连拓扑优化降低数据搬运功耗",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "IOD consolidation and interconnect topology optimization reduces data movement power consumption"
      },
      {
        "text": "低功耗触发器与ML驱动的CAC优化降低动态功耗",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Low-power flops and ML-based flows reduce wire CAC for dynamic power optimization"
      }
    ],
    "affiliation": "AMD",
    "authors": "AMD",
    "process_node": "3nm/6nm",
    "die_area_mm2": "CoWoS-S",
    "power_mw": "1000000",
    "energy_efficiency": "3x gen-over-gen inference",
    "target_model": "LLM/AI Training",
    "application": "数据中心AI训练与推理",
    "innovations": [
      {
        "tag": "CDNA 4架构 FP6/FP4支持",
        "type": "hw-arch"
      },
      {
        "tag": "3D堆叠异构XCD+IOD",
        "type": "system"
      },
      {
        "tag": "HBM3E高带宽内存集成",
        "type": "system"
      }
    ],
    "tags": [
      "GPU",
      "AI",
      "3D堆叠",
      "HBM3E",
      "数据中心",
      "CDNA"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "AMD Instinct MI300 vs. AMD Instinct MI350 power, performance and area comparison.",
        "path": "images/2.1/fig_1.png"
      },
      {
        "num": 2,
        "caption": "AMD Instinct MI350 XCD. 43 2 [4] MI350-036 (n.d.). Based on testing by AMD Performance Labs in June 2025, on the AMD Instinct MI350X vs.",
        "path": "images/2.1/fig_2.png"
      },
      {
        "num": 3,
        "caption": "AMD Instinct MI350 IOD.",
        "path": "images/2.1/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Generational peak theoretical performance improvement.",
        "path": "images/2.1/fig_4.png"
      },
      {
        "num": 5,
        "caption": "AMD Instinct MI350 XCD Cac breakdown.",
        "path": "images/2.1/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Inference throughput comparison between AMD Instinct MI355X (FP4) and AMD Instinct MI300X(FP8).",
        "path": "images/2.1/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Inference throughput comparison between AMD Instinct MI355X vs. Nvidia B200 and Nvidia GB200.",
        "path": "images/2.1/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "3nm/6nm",
      "die_area_mm2": "CoWoS-S",
      "power_mw": "1000000",
      "energy_efficiency": "3x gen-over-gen inference",
      "target_model": "LLM/AI Training",
      "source_figure": "fig_7"
    },
    "data_path": "data/2.1/",
    "analytical_tags": [
      "混合精度",
      "3D堆叠/HBM",
      "业界"
    ],
    "affiliation_info": {
      "name": "AMD",
      "name_zh": "AMD",
      "type": "industry",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/amd.svg"
    },
    "abstract": "The AMD Instinct MI350 Series GPU, based on a 4th-generation AMD CDNA architecture, features eight stacked accelerator complex dies (XCD), two I/O dies (IOD) interconnected with AMD Inﬁnity Fabric, and interfaces for eight stacks of 12-hi HBM3E memory. The MI350 Series GPU delivers over 3× generational inference performance increase by improving energy efﬁciency, increasing compute throughput, supporting new lower-precision FP6/FP4 datatypes, and increasing both memory bandwidth and capacity.",
    "metrics_detailed": {
      "technology": "3nm FinFET (N3P) for XCD, 6nm FinFET (N6) for IOD",
      "die_area": {
        "value": "CoWoS-S module",
        "unit": "multi-die package",
        "note": "8 XCD accelerator dies + 2 IOD dies + 8 HBM3E stacks"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "various",
            "unit": "V",
            "condition": "compute and IO domains"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "boosted",
            "unit": "GHz",
            "condition": "target 5% technology process-neutral GPU device-level frequency increase"
          }
        ]
      },
      "hbm_bandwidth": {
        "values": [
          {
            "value": "1.5x",
            "unit": "improvement",
            "condition": "peak HBM bandwidth vs MI300X"
          }
        ]
      },
      "compute_throughput": {
        "values": [
          {
            "value": "1.9x",
            "unit": "improvement",
            "condition": "peak theoretical performance for 16b and 8b formats vs prior generation"
          },
          {
            "value": "3.85x",
            "unit": "improvement",
            "condition": "peak theoretical performance for FP4 vs FP8 of previous generation"
          }
        ]
      },
      "power_efficiency": {
        "values": [
          {
            "value": "30% reduction in process-neutral CAC/op",
            "unit": "relative improvement",
            "condition": "vs prior XCD design for critical workloads"
          },
          {
            "value": "2x compute throughput with <2x power",
            "unit": "power efficiency gain",
            "condition": "generational improvement"
          },
          {
            "value": "3x",
            "unit": "generational improvement",
            "condition": "inference performance increase for broad AI use cases"
          },
          {
            "value": "1.3x better",
            "unit": "HBM read BW/Watt",
            "condition": "vs MI300X"
          }
        ]
      },
      "comparison": "Over 3x generational inference performance increase with improved energy efficiency compared to MI300X, supporting new FP6/FP4 lower-precision datatypes and increased memory bandwidth/capacity.",
      "quantization": "FP6, FP4, FP8, FP16, INT8 support"
    },
    "page_images": [
      "images/2.1/page_1.png",
      "images/2.1/page_2.png",
      "images/2.1/page_3.png"
    ]
  },
  {
    "id": "2.2",
    "session": 2,
    "title": "A Quad-Chiplet AI SoC with Full-Chip Scalable Mesh Over 16Gb/s UCIe-Advanced Die-to-Die Interface for LLM Applications",
    "title_zh": "四芯粒AI SoC：基于16Gb/s UCIe-Advanced互连的全芯片可扩展Mesh架构LLM处理器",
    "title_annotation": {
      "segments": [
        {
          "text": "Quad-Chiplet",
          "meaning": "四芯粒封装",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Scalable Mesh",
          "meaning": "可扩展网格互连",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "16Gb/s UCIe-Advanced",
          "meaning": "16Gb/s通用芯粒互连",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "LLM Applications",
          "meaning": "大语言模型应用",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "LLM预填充阶段需要海量浮点算力",
        "related_idea_idx": 0,
        "text_en": "The compute-bound prefill phase requires a massive amount of floating-point operations"
      },
      {
        "text": "百万Token上下文KV缓存带宽受限",
        "related_idea_idx": 1,
        "text_en": "Memory-bound decoding phase is limited by KV cache bandwidth with context windows extending to millions of tokens"
      },
      {
        "text": "多芯粒间数据同步与一致性开销大",
        "related_idea_idx": 2,
        "text_en": "Data synchronization and consistency overhead across multi-chiplet configuration"
      },
      {
        "text": "高瞬态电流导致供电网络电压波动",
        "related_idea_idx": 3,
        "text_en": "High transient current causing power supply network voltage fluctuations"
      }
    ],
    "ideas": [
      {
        "text": "四芯粒可扩展Mesh互连与混合精度统一计算单元",
        "type": "system",
        "color": "#3498db",
        "text_en": "Quad-chiplet scalable mesh interconnect with unified multiple- and mixed-precision arithmetic unit"
      },
      {
        "text": "512MB片上SRAM分层存储架构支撑KV缓存",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "512MB on-chip SRAM multi-cycle, multi-bank architecture supporting KV cache"
      },
      {
        "text": "UCIe低延迟Load-Store语义实现虚拟单片互连",
        "type": "system",
        "color": "#3498db",
        "text_en": "UCIe low-latency load-store memory semantics enabling virtually monolithic interconnect"
      },
      {
        "text": "硬件交错启动与集成硅电容抑制瞬态电压噪声",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Hardware interleaved startup with integrated silicon capacitors suppressing transient voltage noise"
      }
    ],
    "affiliation": "Rebellions",
    "authors": "Rebellions",
    "process_node": "4nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "56.8TPS on Llama 3.3 70B",
    "target_model": "Llama 3.3 70B",
    "application": "LLM推理",
    "innovations": [
      {
        "tag": "四芯粒可扩展Mesh架构",
        "type": "hw-arch"
      },
      {
        "tag": "UCIe-Advanced Die-to-Die",
        "type": "hw-circuit"
      },
      {
        "tag": "HBM3E集成与同步机制",
        "type": "system"
      }
    ],
    "tags": [
      "LLM",
      "芯粒",
      "UCIe",
      "NPU",
      "HBM3E",
      "可扩展"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Full-chip block diagram with four NPU chiplets, four HBM3E modules and four ISCs.",
        "path": "images/2.2/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Full-chip scale mesh with neural cores, DMA, synchronization manager connected with three logically independent channels.",
        "path": "images/2.2/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Chiplet interface subsystem with advanced UCIe die-to-die links. Bathtub and eye diagram snapshots at target speed during silicon bring-up.",
        "path": "images/2.2/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Hardware-based staggering technique and core-group closed-loop control for voltage droop and temperature, with per-cluster DVFS control loop.",
        "path": "images/2.2/fig_4.png"
      },
      {
        "num": 5,
        "caption": "ISC for power integrity enhancement of HBM3E operation. Measured bandwidth performance and eye diagram; the eye diagram at the target speed (9.6Gbps) will be updated after silicon bring-up.",
        "path": "images/2.2/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Performance (TPS) and power efﬁciency (TPS/W) comparison on silicon vs. ﬂagship AI processors. Weight-only quantization applied due to DRAM limits on the 70B model.",
        "path": "images/2.2/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Package photo with four NPU chiplets, four HBM3E modules and four ISC dies. Various package conﬁgurations are being developed in parallel with the NPU chiplet.",
        "path": "images/2.2/fig_7.png"
      }
    ],
    "metrics": {
      "sram_kb": "512MB of on-chip SRAM",
      "throughput": "128TOPS",
      "technology": "4nm",
      "energy_efficiency": "56.8TPS on Llama 3.3 70B",
      "target_model": "Llama 3.3 70B",
      "source_figure": "fig_7"
    },
    "data_path": "data/2.2/",
    "analytical_tags": [
      "芯粒/Chiplet",
      "可重构",
      "LLM/NLP",
      "业界"
    ],
    "affiliation_info": {
      "name": "Rebellions",
      "name_zh": "Rebellions",
      "type": "industry",
      "country": "韩国",
      "country_code": "KR",
      "logo": "assets/logos/rebellions.svg"
    },
    "abstract": "A 4nm-based quad-chiplet with an advanced packaged LLM accelerator achieving 56.8TPS on LLaMA v3.3 70B with single-batch 2k/2k input/output sequences. The architecture combines chiplet-based design, low-latency die-to-die interfaces, uniﬁed mixed-precision compute, holistic synchronization, and HBM3E with advanced power schemes to sustain bandwidth, capacity and thermal stability. The SoC integrates four NPU chiplets, four HBM3E modules, and four ISCs for stable power delivery.",
    "metrics_detailed": {
      "technology": "4nm process",
      "die_area": {
        "value": "quad-chiplet",
        "unit": "multi-chip module",
        "note": "4 NPU chiplets, 4 HBM3E modules, 4 ISCs in advanced package"
      },
      "frequency": {
        "values": [
          {
            "value": "design-target configuration",
            "unit": "GHz",
            "condition": "multiple chiplets"
          }
        ]
      },
      "compute_throughput": {
        "values": [
          {
            "value": "2",
            "unit": "PFLOPS",
            "condition": "FP8 compute capability"
          }
        ]
      },
      "on_chip_memory": {
        "values": [
          {
            "value": "512",
            "unit": "MB",
            "condition": "total on-chip SRAM"
          },
          {
            "value": "256",
            "unit": "MB",
            "condition": "high-density scratchpad memory with 128TB/s aggregated bandwidth"
          },
          {
            "value": "256",
            "unit": "MB",
            "condition": "shared memory with 64TB/s aggregated bandwidth"
          }
        ]
      },
      "interconnect": {
        "values": [
          {
            "value": "16",
            "unit": "Gbps",
            "condition": "UCIe die-to-die interface per channel"
          },
          {
            "value": "11",
            "unit": "ns",
            "condition": "FDI-to-FDI latency at 16Gbps"
          }
        ]
      },
      "dma_bandwidth": {
        "values": [
          {
            "value": "2.6",
            "unit": "TB/s",
            "condition": "per-DMA bandwidth sustained"
          }
        ]
      },
      "model_performance": {
        "values": [
          {
            "value": "56.8",
            "unit": "TPS",
            "condition": "LLaMA 3.3 70B with single-batch 2k/2k input/output sequences"
          }
        ]
      },
      "power_efficiency": {
        "values": [
          {
            "value": "1.7x higher",
            "unit": "power efficiency",
            "condition": "vs H200 during silicon bring-up measurements"
          }
        ]
      },
      "thermal_design_power": {
        "value": "600",
        "unit": "W",
        "note": "TDP specification"
      },
      "comparison": "Petaflop-class LLM solution matching/surpassing leading commercial accelerators with efficient chiplet-based design, advanced die-to-die interfaces, and comprehensive power management for datacenters.",
      "quantization": "Mixed-precision support with per-operand configurability"
    },
    "page_images": [
      "images/2.2/page_1.png",
      "images/2.2/page_2.png",
      "images/2.2/page_3.png"
    ]
  },
  {
    "id": "2.3",
    "session": 2,
    "title": "A 71.3mJ/Frame End-to-End Driving Processor with Flexible Heterogeneous Core Orchestration via Sparsity-Aware Reconfiguration",
    "title_zh": "71.3mJ/帧端到端自动驾驶处理器：基于稀疏感知重配置的灵活异构核协调",
    "title_annotation": {
      "segments": [
        {
          "text": "71.3mJ/Frame",
          "meaning": "每帧能耗71.3毫焦",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "End-to-End Driving",
          "meaning": "端到端自动驾驶",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Heterogeneous Core",
          "meaning": "异构计算核",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Sparsity-Aware Reconfiguration",
          "meaning": "稀疏感知动态重配置",
          "color": "#9b59b6",
          "type": "co-design"
        }
      ]
    },
    "challenges": [
      {
        "text": "多模态融合层稀疏性剧烈波动难以利用",
        "related_idea_idx": 0,
        "text_en": "Multimodal fusion layers suffer from drastic sparsity fluctuations across layers where transformer layers exhibit no structural patterns for strongly related tokens, causing sparsity vanishing and hindering sparsity exploitation"
      },
      {
        "text": "固定稀疏-密集核比例限制硬件利用率",
        "related_idea_idx": 1,
        "text_en": "Fixed sparse-dense core ratio (RMAC) limits peak utilization to a narrow sparsity range, leading to significant accuracy loss in sensor-fusion models where sparsity patterns vary across modalities"
      },
      {
        "text": "时序注意力长短期记忆需大量片外访存",
        "related_idea_idx": 2,
        "text_en": "Temporal attention requires massive memory demand for long-/short-term data with substantial external memory access, accounting for 34.1% of the total EMA"
      }
    ],
    "ideas": [
      {
        "text": "基于帧间相关性的稀疏推理单元预测并生成稀疏性",
        "type": "sw",
        "color": "#2ecc71",
        "text_en": "Sparsity reasoning unit (SRU) predicts and generates sparsity by referencing past-future correlations to maximize sparsity exploitation in the current frame"
      },
      {
        "text": "稀疏感知自适应核编排与分段聚合网络",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Sparsity-aware adaptive core orchestrator with N-to-N segmented aggregation network (SAN) enables flexible sparse-dense heterogeneous architecture and dynamic multi-core aggregation"
      },
      {
        "text": "ROI渐进式记忆剪枝减少92.8%时序注意力访存",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "ROI-based progressive memory pruning in long-/short-term memory unit (LSTMU) reduces 92.8% temporal attention memory access by discarding irrelevant temporal memories"
      }
    ],
    "affiliation": "UNIST",
    "authors": "UNIST",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "71.3mJ/frame",
    "target_model": "EED Model",
    "application": "自动驾驶",
    "innovations": [
      {
        "tag": "稀疏感知异构核重配置",
        "type": "co-design"
      },
      {
        "tag": "时序注意力片外访存优化",
        "type": "hw-arch"
      },
      {
        "tag": "CNN+Transformer融合加速",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "自动驾驶",
      "异构",
      "稀疏",
      "Transformer",
      "CNN",
      "BEV"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Overview of end-to-end driving (EED) model and design challenges.",
        "path": "images/2.3/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall chip architecture. 47 2 processing speed, achieving real-time performance for multi-sensor fusion (>10fps), while reducing energy per frame by 218×.",
        "path": "images/2.3/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Details of operations and architecture of the sparsity reasoning unit (SRU) with past-future guided sparsity speculation and generation.",
        "path": "images/2.3/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Core orchestrator and segmented aggregation network with sparsity-aware adaptive core orchestration and dynamic tile reordering.",
        "path": "images/2.3/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Long-/short-term memory unit (LSTMU) with temporal attention pipeline and progressive memory pruning.",
        "path": "images/2.3/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and performance comparison table.",
        "path": "images/2.3/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and performance summary.",
        "path": "images/2.3/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "die_area_mm2": "10.5",
      "energy_efficiency": "71.3mJ/frame",
      "target_model": "EED Model",
      "source_figure": "fig_7"
    },
    "data_path": "data/2.3/",
    "analytical_tags": [
      "稀疏化",
      "可重构",
      "视觉/CV",
      "学界"
    ],
    "affiliation_info": {
      "name": "UNIST",
      "name_zh": "蔚山科学技术大学",
      "type": "academia",
      "country": "韩国",
      "country_code": "KR",
      "logo": "assets/logos/unist.svg"
    },
    "abstract": "A multi-modal end-to-end driving processor is proposed with 4 features: 1) a sparsity reasoning unit to maximize sparsity exploitation, 2) a flexible sparse-dense heterogeneous architecture with a sparsity-aware adaptive core orchestrator to maximize core utilization, 3) an energy-efﬁcient segmented aggregation network, and 4) a long-/short-term memory unit to minimize external memory access (EMA) of temporal attention. It achieves 10.3fps at 71.3mJ/frame, consuming 218× less energy than a state-of-the-art driving SoC.",
    "metrics_detailed": {
      "technology": "28nm CMOS",
      "die_area": {
        "value": "10.5",
        "unit": "mm²",
        "note": "complete end-to-end driving processor"
      },
      "frequency": {
        "values": [
          {
            "value": "varies",
            "unit": "MHz",
            "condition": "multiple operating points for power-performance tradeoff"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "10.3",
            "unit": "fps",
            "condition": "end-to-end driving with multi-sensor fusion"
          },
          {
            "value": "2.67x higher",
            "unit": "processing speed improvement",
            "condition": "vs state-of-the-art autonomous driving SoC [23]"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "71.3",
            "unit": "mJ/frame",
            "condition": "real-time end-to-end driving consumption"
          },
          {
            "value": "218x lower",
            "unit": "energy per frame",
            "condition": "vs state-of-the-art driving SoC [23]"
          },
          {
            "value": "544x lower",
            "unit": "power consumption",
            "condition": "vs GPU implementation [22]"
          }
        ]
      },
      "benchmark_performance": {
        "values": [
          {
            "value": "69.6",
            "unit": "driving score",
            "condition": "Town05 Long benchmark in CARLA simulator"
          }
        ]
      },
      "memory_optimization": {
        "values": [
          {
            "value": "73.9% reduction",
            "unit": "memory demand for statistics",
            "condition": "sparsity reasoning unit optimization"
          },
          {
            "value": "92.8% reduction",
            "unit": "external memory access",
            "condition": "temporal attention with LSTMU and progressive memory pruning"
          },
          {
            "value": "34.3% reduction",
            "unit": "computational load",
            "condition": "transformer layers via sparsity generation"
          }
        ]
      },
      "core_orchestration": {
        "values": [
          {
            "value": "39.6% reduction",
            "unit": "total processing time",
            "condition": "flexible core allocation and reconﬁgurable aggregation"
          },
          {
            "value": "89.9% reduction",
            "unit": "power consumption",
            "condition": "segmented aggregation network vs baseline"
          },
          {
            "value": "83.2% reduction",
            "unit": "area",
            "condition": "segmented aggregation network vs baseline"
          }
        ]
      },
      "comparison": "Real-time end-to-end driving processor consuming 218x less energy than SOTA autonomous driving SoC while achieving comparable throughput to GPU implementations, processing entire multi-sensor/modal/temporal information pipeline.",
      "quantization": "Not explicitly stated"
    },
    "page_images": [
      "images/2.3/page_1.png",
      "images/2.3/page_2.png",
      "images/2.3/page_3.png"
    ]
  },
  {
    "id": "2.4",
    "session": 2,
    "title": "UniC-Vision: A 14.4Gb/s 7.3pJ/b Universal Vision Transformer OFDM Channel Estimation Accelerator for B5G/6G",
    "title_zh": "UniC-Vision：14.4Gb/s 7.3pJ/b通用ViT OFDM信道估计加速器(面向B5G/6G)",
    "title_annotation": {
      "segments": [
        {
          "text": "14.4Gb/s 7.3pJ/b",
          "meaning": "吞吐14.4Gbps，能效7.3pJ/bit",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Vision Transformer",
          "meaning": "视觉Transformer模型",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "OFDM Channel Estimation",
          "meaning": "正交频分复用信道估计",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "B5G/6G",
          "meaning": "超5G/6G通信",
          "color": "#3498db",
          "type": "system"
        }
      ]
    },
    "challenges": [
      {
        "text": "ViT信道估计模型参数量大无法片上存储",
        "related_idea_idx": 0,
        "text_en": "ViT channel estimation model has large parameter count that cannot be stored on-chip"
      },
      {
        "text": "Softmax等非线性运算需外部处理器增加延迟",
        "related_idea_idx": 1,
        "text_en": "Softmax and other nonlinear operations require external processor access which increases latency"
      },
      {
        "text": "B5G/6G多频段覆盖需通用高效估计器",
        "related_idea_idx": 2,
        "text_en": "B5G/6G multi-frequency band coverage requires universal efficient estimator"
      }
    ],
    "ideas": [
      {
        "text": "信道感知压缩将权重参数缩减95%实现片上存储",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Channel-aware compression reduces weight parameters by 95% enabling on-chip storage"
      },
      {
        "text": "松弛自注意力用Taylor展开消除非线性查找表",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Relaxed self-attention uses Taylor expansion to eliminate nonlinear look-up tables"
      },
      {
        "text": "频段模式切换与四Patch并行架构提升吞吐量5倍",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Mode switching for frequency bands and quad-patch architecture boost throughput by 5×"
      }
    ],
    "affiliation": "KAIST",
    "authors": "KAIST",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "7.3pJ/b",
    "target_model": "ViT",
    "application": "6G通信信道估计",
    "innovations": [
      {
        "tag": "通用多频段ViT信道估计",
        "type": "co-design"
      },
      {
        "tag": "低延迟高吞吐加速架构",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "6G",
      "ViT",
      "信道估计",
      "OFDM",
      "MIMO",
      "通信"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "AI-RAN OFDM channel estimation accelerator solutions to meet B5G/6G system requirements.",
        "path": "images/2.4/fig_1.png"
      },
      {
        "num": 2,
        "caption": "System architecture of the proposed UniC-Vision OFDM channel estimation accelerator.",
        "path": "images/2.4/fig_2.png"
      },
      {
        "num": 3,
        "caption": "CAC and RSA algorithm-hardware co-optimization eliminating external access for real-time processing.",
        "path": "images/2.4/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Mode switching to support FR2 and FR3 bands with the maximum utilization of the on-chip PE.",
        "path": "images/2.4/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Channel estimation performance evaluation and efﬁciency analysis with SOTA wireless system fabrics, and channel estimation circuits.",
        "path": "images/2.4/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Link-level performance evaluation and comparison with silicon-proven SOTA wireless communications system.",
        "path": "images/2.4/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and summary.",
        "path": "images/2.4/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "supply_voltage": "1.0V",
      "frequency_mhz": "250",
      "power_mw": "104.6",
      "energy_efficiency": "7.3pJ/b",
      "throughput": "throughput of 14.4Gb/s",
      "target_model": "ViT",
      "source_figure": "fig_7"
    },
    "supply_voltage": "1.0V",
    "frequency_mhz": "250",
    "data_path": "data/2.4/",
    "analytical_tags": [
      "视觉/CV",
      "学界"
    ],
    "affiliation_info": {
      "name": "KAIST",
      "name_zh": "韩国科学技术院",
      "type": "academia",
      "country": "韩国",
      "country_code": "KR",
      "logo": "assets/logos/kaist.svg"
    },
    "abstract": "This work presents an AI-RAN channel estimation accelerator for next-generation communications, offering hyper reliability, low latency, and universal frequency range coverage, thereby meeting B5G/6G requirements. Utilizing algorithm-hardware co- optimization and architecture optimizations, the prototype achieves a throughput of 14.4Gb/s at 7.3pJ/b in 28nm CMOS, surpassing the state-of-the-art channel estimation systems by 7.7 to 18.9dB in reliability and 16-to-39× in throughput.",
    "metrics_detailed": {
      "technology": "28nm CMOS",
      "die_area": {
        "value": "not explicitly stated",
        "unit": "mm²",
        "note": "chip photo referenced in Fig 2.4.7"
      },
      "frequency": {
        "values": [
          {
            "value": "250",
            "unit": "MHz",
            "condition": "maximum operating frequency"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "1.0",
            "unit": "V",
            "condition": "nominal supply voltage"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "14.4",
            "unit": "Gb/s",
            "condition": "steady throughput"
          }
        ]
      },
      "power_consumption": {
        "value": "104.6",
        "unit": "mW",
        "note": "at 250MHz, 1.0V"
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "7.3",
            "unit": "pJ/b",
            "condition": "energy efficiency at peak throughput"
          },
          {
            "value": "5.4x better",
            "unit": "energy efficiency improvement",
            "condition": "vs latest SOTA channel estimation fabric [9]"
          }
        ]
      },
      "latency": {
        "values": [
          {
            "value": "0.28-0.7",
            "unit": "ms",
            "condition": "end-to-end latency per PRB"
          }
        ]
      },
      "channel_estimation_performance": {
        "values": [
          {
            "value": "24",
            "unit": "dB",
            "condition": "maximum estimation gain"
          },
          {
            "value": "7.7-18.9",
            "unit": "dB improvement",
            "condition": "in reliability vs SOTA systems"
          },
          {
            "value": "16-39x improvement",
            "unit": "throughput",
            "condition": "vs SOTA channel estimation systems"
          },
          {
            "value": "5% MSE loss",
            "unit": "from baseline",
            "condition": "with all cost optimizations applied"
          }
        ]
      },
      "quantization_efficiency": {
        "values": [
          {
            "value": "95% reduction",
            "unit": "storage",
            "condition": "via channel-aware compression (CAC)"
          },
          {
            "value": "83% reduction",
            "unit": "MHA latency",
            "condition": "via relaxed self-attention (RSA)"
          }
        ]
      },
      "universal_coverage": {
        "value": "FR1/FR2/FR3 frequency bands",
        "unit": "spectrum range",
        "note": "mode switching enables universal frequency range coverage"
      },
      "comparison": "AI-RAN channel estimation accelerator for B5G/6G achieving hyper-reliability, low-latency performance with universal frequency range coverage, surpassing SOTA systems by 7.7-18.9dB in reliability and 16-39x in throughput.",
      "quantization": "12b fixed-point 2's complement with iterative quantization-aware training"
    },
    "page_images": [
      "images/2.4/page_1.png",
      "images/2.4/page_2.png",
      "images/2.4/page_3.png"
    ]
  },
  {
    "id": "2.5",
    "session": 2,
    "title": "A 1.1mm² 14.4ns 13.1pJ/b Forward Error Correction with Ordered-Statistics Post Processing for Ultra-Reliable Low-Latency Communication",
    "title_zh": "1.1mm² 14.4ns 13.1pJ/b前向纠错译码器：基于有序统计后处理的超可靠低延迟通信",
    "title_annotation": {
      "segments": [
        {
          "text": "1.1mm² 14.4ns",
          "meaning": "面积1.1mm²，延迟14.4ns",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Forward Error Correction",
          "meaning": "前向纠错编码",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Ordered-Statistics",
          "meaning": "有序统计译码(OSD)",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Ultra-Reliable Low-Latency",
          "meaning": "超可靠低延迟(URLLC)",
          "color": "#3498db",
          "type": "system"
        }
      ]
    },
    "challenges": [
      {
        "text": "OSD高阶译码候选数指数增长延迟过高",
        "related_idea_idx": 0,
        "text_en": "OSD high-order decoding candidate number grows exponentially causing excessive latency"
      },
      {
        "text": "高斯消元固有串行性占译码延迟60%以上",
        "related_idea_idx": 1,
        "text_en": "Gaussian elimination inherent sequential nature accounts for over 60% of decoding latency"
      },
      {
        "text": "URLLC要求亚毫秒最坏延迟与高可靠性兼顾",
        "related_idea_idx": 2,
        "text_en": "URLLC requires both sub-millisecond worst-case latency and high reliability"
      }
    ],
    "ideas": [
      {
        "text": "Chase+1阶OSD两级互补译码降低复杂度156倍",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Chase + order-1 OSD two-stage complementary decoding reduces complexity by 156×"
      },
      {
        "text": "预排序基更新替代完整高斯消元减少75%延迟",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Pre-sorted basis update (PSBU) replaces complete Gaussian elimination reducing latency by 75%"
      },
      {
        "text": "四级提前退出机制实现14.4ns平均译码延迟",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Four-level early exit mechanism achieves 14.4ns average decoding latency"
      }
    ],
    "affiliation": "University of Michigan",
    "authors": "University of Michigan",
    "process_node": "16nm",
    "die_area_mm2": "1.1",
    "power_mw": "",
    "energy_efficiency": "13.1pJ/b",
    "target_model": "Short codes (≤128b)",
    "application": "URLLC/6G通信",
    "innovations": [
      {
        "tag": "Chase+OSD两阶段译码",
        "type": "sw"
      },
      {
        "tag": "确定性低延迟流水线",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "FEC",
      "URLLC",
      "6G",
      "译码器",
      "OSD",
      "短码"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "SOTA FECs for URLLC and OSD. (MRB: most reliable bit; WHD: weighted Hamming distance).",
        "path": "images/2.5/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Design challenges for OSD hardware implementations and design features. 51 2 for high-rate codes.",
        "path": "images/2.5/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Two-stage decoding and BLER and latency evaluations. (Pf,Chase: failure probability of Chase decoder).",
        "path": "images/2.5/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Pre-sorted basis update (PSBU) and comparisons with full GE and reduced GE.",
        "path": "images/2.5/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Architecture block diagram and latency evaluation.",
        "path": "images/2.5/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Comparison of state-of-the-art FECs.",
        "path": "images/2.5/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die photo and measurement results.",
        "path": "images/2.5/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "16nm",
      "supply_voltage": "0.9V",
      "energy_efficiency": "13.1pJ/b",
      "throughput": "throughput of 83Mbps",
      "die_area_mm2": "1.1",
      "target_model": "Short codes (≤128b)",
      "source_figure": "fig_7"
    },
    "supply_voltage": "0.9V",
    "data_path": "data/2.5/",
    "analytical_tags": [
      "学界"
    ],
    "affiliation_info": {
      "name": "University of Michigan",
      "name_zh": "密歇根大学",
      "type": "academia",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/university-of-michigan.svg"
    },
    "abstract": "We present a two-stage FEC decoder that combines soft-decision Chase decoding with order-1 ordered statistics decoding, offering robust error correction for URLLC. A 1.1mm2, 16nm decoder prototype with optimized Gaussian elimination and early exits achieves an average latency of 14.4ns and a worst-case latency of 132.6ns, improving upon prior work by 53× and ﬁve orders of magnitude, respectively. The prototype delivers 15.2Gbps at 13.1pJ/b, outperforming state-of-the-art URLLC FEC decoders.",
    "metrics_detailed": {
      "technology": "16nm FinFET (Intel 16)",
      "die_area": {
        "value": "1.1",
        "unit": "mm²",
        "note": "total silicon area with Chase decoder 0.8mm² and order-1 OSD 0.3mm²"
      },
      "frequency": {
        "values": [
          {
            "value": "950",
            "unit": "MHz",
            "condition": "operating frequency at room temperature and 0.9V"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.9",
            "unit": "V",
            "condition": "nominal supply voltage"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "15.2",
            "unit": "Gbps",
            "condition": "information throughput for BCH (127,64) code"
          }
        ]
      },
      "latency": {
        "values": [
          {
            "value": "14.4",
            "unit": "ns",
            "condition": "average latency for BCH (127,64) at 5dB SNR"
          },
          {
            "value": "132.6",
            "unit": "ns",
            "condition": "worst-case latency for BCH (127,64) at 5dB SNR"
          },
          {
            "value": "53x improvement",
            "unit": "average latency reduction",
            "condition": "vs state-of-the-art HDD + order-3 OSD decoder [5]"
          },
          {
            "value": "5 orders of magnitude",
            "unit": "worst-case latency reduction",
            "condition": "vs state-of-the-art decoder"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "13.1",
            "unit": "pJ/b",
            "condition": "energy efficiency at peak throughput"
          },
          {
            "value": "26x lower",
            "unit": "energy",
            "condition": "vs state-of-the-art HDD + order-3 OSD decoder"
          }
        ]
      },
      "error_correction_performance": {
        "values": [
          {
            "value": "10-5",
            "unit": "BLER",
            "condition": "block error rate target"
          },
          {
            "value": "183x higher",
            "unit": "information throughput",
            "condition": "vs state-of-the-art decoder"
          }
        ]
      },
      "decoder_architecture": {
        "values": [
          {
            "value": "14.4 ns average, 132.6 ns worst-case",
            "unit": "latency",
            "condition": "two-stage Chase + order-1 OSD"
          },
          {
            "value": "156x reduction",
            "unit": "average latency improvement",
            "condition": "two-stage vs single-stage order-2 OSD at 5dB SNR"
          }
        ]
      },
      "code_support": {
        "values": [
          {
            "value": "BCH (127,64), BCH (127,85)",
            "unit": "short codes",
            "condition": "supported code lengths ≤128b"
          }
        ]
      },
      "comparison": "Two-stage FEC decoder combining soft-decision Chase decoding with order-1 OSD achieves ultra-low latency (14.4ns average, 132.6ns worst-case) and high energy efficiency (13.1pJ/b) for URLLC, improving on prior work by 53x average and 5 orders of magnitude worst-case latency with 26x better energy.",
      "quantization": "Not explicitly stated"
    },
    "page_images": [
      "images/2.5/page_1.png",
      "images/2.5/page_2.png",
      "images/2.5/page_3.png"
    ]
  },
  {
    "id": "2.6",
    "session": 2,
    "title": "Spyre: An Inference-Optimized Scalable AI Accelerator for Enterprise Workloads",
    "title_zh": "Spyre：面向企业工作负载的推理优化可扩展AI加速器",
    "title_annotation": {
      "segments": [
        {
          "text": "Spyre",
          "meaning": "IBM企业级AI加速器",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Inference-Optimized",
          "meaning": "推理优化",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Scalable",
          "meaning": "可扩展(PCIe多卡)",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Enterprise Workloads",
          "meaning": "企业级工作负载",
          "color": "#3498db",
          "type": "system"
        }
      ]
    },
    "challenges": [
      {
        "text": "单槽PCIe功耗预算限制加速器性能",
        "related_idea_idx": 0,
        "text_en": "Single-slot PCIe power budget constrains accelerator performance"
      },
      {
        "text": "单环路功率控制浪费短时功耗余量",
        "related_idea_idx": 1,
        "text_en": "Single-loop power control wastes short-term power headroom"
      },
      {
        "text": "多卡推理扩展依赖专有互连方案",
        "related_idea_idx": 2,
        "text_en": "Multi-card inference scaling relies on proprietary interconnect solutions"
      },
      {
        "text": "硅前功耗建模不准导致频率次优",
        "related_idea_idx": 3,
        "text_en": "Pre-silicon power modeling inaccuracy leads to suboptimal frequency"
      }
    ],
    "ideas": [
      {
        "text": "双电压域设计(0.55V/0.75V)降低功耗",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Dual voltage domain design (0.55V/0.75V) reduces power consumption"
      },
      {
        "text": "双环路峰值电流控制提升吞吐28%",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Dual-loop peak power control improves throughput by 28%"
      },
      {
        "text": "标准PCIe Fabric实现多卡弹性扩展",
        "type": "system",
        "color": "#3498db",
        "text_en": "Standard PCIe fabric enables multi-card elastic scaling"
      },
      {
        "text": "工作负载驱动的物理设计功耗优化",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Workload-driven physical design power optimization"
      }
    ],
    "affiliation": "IBM",
    "authors": "IBM",
    "process_node": "5nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "",
    "target_model": "Granite/Foundation Models",
    "application": "企业AI推理",
    "innovations": [
      {
        "tag": "32核AI加速器+混合精度",
        "type": "hw-arch"
      },
      {
        "tag": "PCIe Gen5多卡扩展",
        "type": "system"
      },
      {
        "tag": "n:4结构化稀疏",
        "type": "sw"
      }
    ],
    "tags": [
      "企业AI",
      "IBM",
      "PCIe",
      "混合精度",
      "稀疏",
      "LPDDR5"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Spyre chip, card and system diagrams.",
        "path": "images/2.6/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Chip ﬂoorplan annotated with voltage domains, ring bus, core and IP blocks. Design metrics from frequency scaling experiments: power and cell area vs.",
        "path": "images/2.6/fig_2.png"
      },
      {
        "num": 3,
        "caption": "(a) Peak power speciﬁcation across different systems; (b) Dual loop control for peak current management.",
        "path": "images/2.6/fig_3.png"
      },
      {
        "num": 4,
        "caption": "(a) Performance enhancement with dual-loop control; (b) performance against core frequency; (c) measured waves with and without a micro-controller-based loop.",
        "path": "images/2.6/fig_4.png"
      },
      {
        "num": 5,
        "caption": "(a) Measured normalized performance (1/ITL) as a function of Spyre instance count; (b) Inference with 1, 2, and 4 Spyres, identical time scales, showing TTFT and ITL improvements.",
        "path": "images/2.6/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Spyre technical speciﬁcations.",
        "path": "images/2.6/fig_6.jpeg"
      },
      {
        "num": 7,
        "caption": "Photos of the die and the PCIe card.",
        "path": "images/2.6/fig_7.png"
      }
    ],
    "metrics": {
      "throughput": "629 TOPS",
      "technology": "5nm",
      "target_model": "Granite/Foundation Models",
      "source_figure": "fig_7"
    },
    "data_path": "data/2.6/",
    "analytical_tags": [
      "混合精度",
      "稀疏化",
      "LLM/NLP",
      "片外访存优化",
      "业界"
    ],
    "affiliation_info": {
      "name": "IBM",
      "name_zh": "IBM",
      "type": "industry",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/ibm.svg"
    },
    "abstract": "Spyre is a scalable, power-efﬁcient AI accelerator product for enterprise workloads. Featuring 32 AI cores, mixed-precision support, and LPDDR5 memory, it ﬁts in a single- slot PCIe form factor and scales over a standard PCIE fabric. Optimized for inference workloads, Spyre achieves 2-to-3× better power/performance than GPUs on encoder-class models and scales up to 4 or more devices for large generative models.",
    "metrics_detailed": {
      "technology": "5nm technology",
      "die_area": {
        "value": "330",
        "unit": "mm²",
        "note": "single-slot PCIe card form factor"
      },
      "transistor_count": {
        "value": "26",
        "unit": "billion transistors",
        "note": "total on chip"
      },
      "on_chip_memory": {
        "values": [
          {
            "value": "64",
            "unit": "MB",
            "condition": "embedded SRAM on SoC"
          },
          {
            "value": "128",
            "unit": "GB",
            "condition": "external DRAM via 16 LPDDR5 interfaces"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "1.2",
            "unit": "GHz",
            "condition": "cores and ring maximum"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.55",
            "unit": "V",
            "condition": "compute regions domain (42% of die area)"
          },
          {
            "value": "0.75",
            "unit": "V",
            "condition": "ring domain"
          }
        ]
      },
      "memory_bandwidth": {
        "values": [
          {
            "value": "204",
            "unit": "GB/sec",
            "condition": "peak bandwidth from 16 LPDDR5 channels @ 6.4Gbps"
          }
        ]
      },
      "compute_throughput": {
        "values": [
          {
            "value": "98",
            "unit": "TOPS",
            "condition": "FP16 precision (dense)"
          },
          {
            "value": "157",
            "unit": "TOPS",
            "condition": "FP8 precision (dense)"
          },
          {
            "value": "315",
            "unit": "TOPS",
            "condition": "INT8 precision (dense)"
          },
          {
            "value": "629",
            "unit": "TOPS",
            "condition": "INT4 precision (dense)"
          }
        ]
      },
      "power_efficiency": {
        "values": [
          {
            "value": "2-3x better",
            "unit": "power/performance improvement",
            "condition": "vs GPU solutions on encoder-class models"
          },
          {
            "value": "8% reduction",
            "unit": "power savings",
            "condition": "from power analysis methodology during physical design"
          },
          {
            "value": "6% reduction",
            "unit": "cell area reduction",
            "condition": "from opportunistic frequency tuning"
          }
        ]
      },
      "power_management": {
        "values": [
          {
            "value": "28% improvement",
            "unit": "throughput enhancement",
            "condition": "with dual-loop control vs single-loop for relevant enterprise workloads"
          }
        ]
      },
      "scaling_capability": {
        "values": [
          {
            "value": "up to 8",
            "unit": "cards",
            "condition": "in single z17 mainframe server I/O drawer"
          },
          {
            "value": "up to 96",
            "unit": "Spyres",
            "condition": "in full system"
          }
        ]
      },
      "model_support": {
        "values": [
          {
            "value": "Granite v3.3 8B",
            "unit": "model",
            "condition": "with good scalability across multi-card configurations"
          }
        ]
      },
      "comparison": "Scalable, power-efficient AI accelerator for enterprise workloads fitting single-slot PCIe form factor, achieving 2-3x better power/performance than GPUs on encoder-class models with support for mixed-precision FP16/FP8/INT8/INT4 and structured sparsity.",
      "quantization": "FP16, FP8 (e4m3/e5m2), INT8, INT4 mixed-precision support"
    },
    "page_images": [
      "images/2.6/page_1.png",
      "images/2.6/page_2.png",
      "images/2.6/page_3.png"
    ]
  },
  {
    "id": "2.7",
    "session": 2,
    "title": "Tiamat: A 98-to-134ms/Step Transformer-Based Diffusion Model Processor Supporting Classifier-Free Guidance for Image Generation",
    "title_zh": "Tiamat：98~134ms/步Transformer扩散模型处理器(支持无分类器引导图像生成)",
    "title_annotation": {
      "segments": [
        {
          "text": "Tiamat",
          "meaning": "处理器代号",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "98-to-134ms/Step",
          "meaning": "每步推理98~134毫秒",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Transformer-Based Diffusion",
          "meaning": "基于Transformer的扩散模型",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Classifier-Free Guidance",
          "meaning": "无分类器引导(CFG)",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "CFG双样本推理使权重访存翻倍",
        "related_idea_idx": 0,
        "text_en": "CFG dual-sample inference doubles weight EMA"
      },
      {
        "text": "MX量化沿输入通道截断误差大",
        "related_idea_idx": 1,
        "text_en": "MX quantization along input channels causes large truncation errors"
      },
      {
        "text": "浮点残差连接需要大容量片上缓存",
        "related_idea_idx": 2,
        "text_en": "Floating-point residual connections require large on-chip buffers"
      }
    ],
    "ideas": [
      {
        "text": "CFG批差分处理减少50%权重访存",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "CFG batch difference processing reduces weight EMA by 50%"
      },
      {
        "text": "权重重排量化配合两阶段特征对齐",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Weight-reordered quantization combined with two-stage block-aware FM alignment"
      },
      {
        "text": "混合MX分块数据通路降低缓存37%",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Hybrid MX blocking datapath reduces buffer requirements by 37%"
      }
    ],
    "affiliation": "NTHU",
    "authors": "NTHU",
    "process_node": "16nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "98-134ms/step",
    "target_model": "DiT (Diffusion Transformer)",
    "application": "图像生成(扩散模型)",
    "innovations": [
      {
        "tag": "CFG批差分处理(CBDP)",
        "type": "sw"
      },
      {
        "tag": "权重重排量化(WRQ)",
        "type": "co-design"
      },
      {
        "tag": "混合MX分块数据通路",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "扩散模型",
      "Transformer",
      "CFG",
      "量化",
      "图像生成",
      "MX格式"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Overview of transformer-based diffusion models and design challenges.",
        "path": "images/2.7/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Proposed classiﬁer-free guidance batch difference processing (CBDP) ﬂow and overall system architecture.",
        "path": "images/2.7/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Proposed weight-reordered quantization (WRQ) and two-stage block- aware feature map alignment (TSBFA).",
        "path": "images/2.7/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Proposed hybrid microscaling blocking datapath (HMBD) and two-stage quantization (TSQ).",
        "path": "images/2.7/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Measurement and inference results of Tiamat.",
        "path": "images/2.7/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Performance comparison table and EMA optimization summary.",
        "path": "images/2.7/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and performance summary.",
        "path": "images/2.7/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "16nm",
      "energy_efficiency": "98-134ms/step",
      "throughput": "7.37TOPS",
      "target_model": "DiT (Diffusion Transformer)",
      "source_figure": "fig_7"
    },
    "data_path": "data/2.7/",
    "analytical_tags": [
      "量化",
      "混合精度",
      "生成式AI",
      "片外访存优化",
      "学界"
    ],
    "affiliation_info": {
      "name": "NTHU",
      "name_zh": "国立清华大学",
      "type": "academia",
      "country": "中国台湾",
      "country_code": "CN",
      "logo": "assets/logos/nthu.svg"
    },
    "abstract": "National Tsing Hua University, Hsinchu, Taiwan A 16nm FinFET transformer-based diffusion model processor chip is fabricated for supporting class-conditional DiT-XL/2 and text-to-image PixArt-α with 98ms and 134ms generation time per step with 7.37TOPS and 1477mW at 400MHz. Classiﬁer-free guidance batching reduces external memory access (EMA) for weights by 50%, and weight-reordered quantization brings another 37% reduction. Hybrid microscaling blocking reduces feature- map buffer size by 37%, while approaching ﬂoating-point quality.",
    "metrics_detailed": {
      "technology": "16nm FinFET",
      "die_area": {
        "value": "not explicitly stated",
        "unit": "mm²",
        "note": "chip photo provided in Fig 2.7.7"
      },
      "frequency": {
        "values": [
          {
            "value": "400",
            "unit": "MHz",
            "condition": "peak performance frequency"
          },
          {
            "value": "100",
            "unit": "MHz",
            "condition": "peak energy efficiency frequency"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "1.05",
            "unit": "V",
            "condition": "at 400MHz peak performance"
          },
          {
            "value": "0.66",
            "unit": "V",
            "condition": "at 100MHz peak energy efficiency"
          }
        ]
      },
      "compute_throughput": {
        "values": [
          {
            "value": "7.37",
            "unit": "TOPS",
            "condition": "at 1.05V and 400MHz"
          }
        ]
      },
      "power_consumption": {
        "values": [
          {
            "value": "1477",
            "unit": "mW",
            "condition": "at 400MHz, 1.05V"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "4.99",
            "unit": "TOPS/W",
            "condition": "at 1.05V, 400MHz"
          },
          {
            "value": "11.64",
            "unit": "TOPS/W",
            "condition": "peak efficiency at 0.66V, 100MHz"
          }
        ]
      },
      "generation_time": {
        "values": [
          {
            "value": "98",
            "unit": "ms/step",
            "condition": "DiT-XL/2 class-conditional image synthesis"
          },
          {
            "value": "134",
            "unit": "ms/step",
            "condition": "PixArt-α text-to-image synthesis"
          }
        ]
      },
      "generation_energy": {
        "values": [
          {
            "value": "75",
            "unit": "mJ/step",
            "condition": "DiT-XL/2 at 0.66V, 100MHz"
          },
          {
            "value": "99",
            "unit": "mJ/step",
            "condition": "PixArt-α at 0.66V, 100MHz"
          },
          {
            "value": "121.9",
            "unit": "mJ/step",
            "condition": "DiT-XL/2 system energy including DDR4 access"
          },
          {
            "value": "159.2",
            "unit": "mJ/step",
            "condition": "PixArt-α system energy including DDR4 access"
          }
        ]
      },
      "external_memory_optimization": {
        "values": [
          {
            "value": "50% reduction",
            "unit": "weight external memory access",
            "condition": "via classifier-free guidance batch difference processing"
          },
          {
            "value": "37% reduction",
            "unit": "additional weight EMA",
            "condition": "via weight-reordered quantization"
          },
          {
            "value": "37% reduction",
            "unit": "feature-map buffer size",
            "condition": "via hybrid MX blocking"
          },
          {
            "value": "68-66% reduction",
            "unit": "total EMA",
            "condition": "for DiT-XL/2 and PixArt-α respectively"
          }
        ]
      },
      "performance_gain": {
        "values": [
          {
            "value": "3.90-7.48x faster",
            "unit": "generation time per step",
            "condition": "vs prior diffusion model processors"
          },
          {
            "value": "1.47-3.35",
            "unit": "seconds",
            "condition": "per high-fidelity image with 15-25 diffusion steps"
          }
        ]
      },
      "quality_preservation": {
        "value": "Close to FP32 models without fine-tuning",
        "unit": "image quality",
        "note": "even with 66-68% EMA reduction"
      },
      "comparison": "Memory-efficient transformer-based diffusion model processor achieving fast, realistic image generation with classifier-free guidance support, delivering 3.9-7.5x faster generation than prior processors with high-fidelity output on edge devices.",
      "quantization": "MXINT5, MXINT8, MXINT11 mixed-format quantization with lossless precision preservation"
    },
    "page_images": [
      "images/2.7/page_1.png",
      "images/2.7/page_2.png",
      "images/2.7/page_3.png"
    ]
  },
  {
    "id": "2.8",
    "session": 2,
    "title": "MADiC: A 3nm 7.4TOPS/mm² 17.4TOPS/W Generative Diffusion Accelerator Enabled by Hardware-Compiler Co-Design",
    "title_zh": "MADiC：3nm 7.4TOPS/mm² 17.4TOPS/W生成式扩散模型加速器(硬件-编译器协同设计)",
    "title_annotation": {
      "segments": [
        {
          "text": "MADiC",
          "meaning": "加速器代号",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "3nm",
          "meaning": "3nm工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "7.4TOPS/mm²",
          "meaning": "面积效率7.4TOPS/mm²",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Hardware-Compiler Co-Design",
          "meaning": "硬件-编译器协同设计",
          "color": "#9b59b6",
          "type": "co-design"
        }
      ]
    },
    "challenges": [
      {
        "text": "先进工艺SRAM面积缩放滞后于逻辑",
        "related_idea_idx": 0,
        "text_en": "SRAM area scaling lags behind logic in advanced nodes"
      },
      {
        "text": "跨循环特征图存储导致外部访存高",
        "related_idea_idx": 1,
        "text_en": "Cross-loop feature map storage causes high external memory access"
      },
      {
        "text": "输入加载与缩放串行执行利用率低",
        "related_idea_idx": 2,
        "text_en": "Sequential input loading and resizing execution results in low utilization"
      }
    ],
    "ideas": [
      {
        "text": "编译器驱动L1/L2存储联合面积优化",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Compiler-driven L1/L2 memory joint area optimization"
      },
      {
        "text": "细粒度写覆盖读松弛的L2分配策略",
        "type": "sw",
        "color": "#2ecc71",
        "text_en": "Fine-grained Write-over-Read relaxation L2 allocation strategy"
      },
      {
        "text": "激活感知预加载与并行缩放提升利用率",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Activation-aware preloading and concurrent resizing improve utilization"
      }
    ],
    "affiliation": "MediaTek",
    "authors": "MediaTek",
    "process_node": "3nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "17.4TOPS/W",
    "target_model": "DiCo (Diffusion ConvNet)",
    "application": "图像生成(扩散模型)",
    "innovations": [
      {
        "tag": "硬件-编译器协同设计",
        "type": "co-design"
      },
      {
        "tag": "3nm高密度加速器",
        "type": "system"
      },
      {
        "tag": "多尺度特征复用优化",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "扩散模型",
      "3nm",
      "编译器",
      "协同设计",
      "DiCo",
      "图像生成"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Overview of diffusion model evolution and challenges in area and utilization for efﬁcient deployment.",
        "path": "images/2.8/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture of MADiC. 57 2 exceeds available space. For the DiCo model, enabling input preloading and concurrent resizing reduces resizer time by 41% and input loading time by 45%.",
        "path": "images/2.8/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Design-time L1/L2 memory size optimization for minimizing SRAM cost.",
        "path": "images/2.8/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Cross-loop data storage allocation and Write-over-Read (WoR) relaxation.",
        "path": "images/2.8/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Activation-aware input preloading and concurrent resizing.",
        "path": "images/2.8/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison table.",
        "path": "images/2.8/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and performance summary.",
        "path": "images/2.8/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "3nm",
      "die_area_mm2": "0.338",
      "supply_voltage": "0.575V",
      "sram_kb": "512KB on-chip memory",
      "energy_efficiency": "17.4TOPS/W",
      "target_model": "DiCo (Diffusion ConvNet)",
      "source_figure": "fig_7"
    },
    "supply_voltage": "0.575V",
    "data_path": "data/2.8/",
    "analytical_tags": [
      "生成式AI",
      "可重构",
      "业界"
    ],
    "affiliation_info": {
      "name": "MediaTek",
      "name_zh": "联发科",
      "type": "industry",
      "country": "中国台湾",
      "country_code": "CN",
      "logo": "assets/logos/mediatek.svg"
    },
    "abstract": "This work presents MADiC, a 3nm 0.338mm2 diffusion accelerator for generative image editing on edge devices. MADiC features design-time L1/L2 memory optimization, cross- loop feature map allocation with write-over-read relaxation, and activation-aware input preloading with concurrent resizing. Operating at 0.575V and 546MHz, it delivers 7.4TOPS/mm2 and 17.4TOPS/W when running the Diffusion ConvNet model.",
    "metrics_detailed": {
      "technology": "3nm FinFET",
      "die_area": {
        "value": "0.338",
        "unit": "mm²",
        "note": "mini accelerator for diffusion ConvNets"
      },
      "on_chip_memory": {
        "values": [
          {
            "value": "512",
            "unit": "KB",
            "condition": "total on-chip memory"
          },
          {
            "value": "384",
            "unit": "KB",
            "condition": "L1 activation memory"
          },
          {
            "value": "128",
            "unit": "KB",
            "condition": "L2 memory"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "546",
            "unit": "MHz",
            "condition": "operating frequency"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.575",
            "unit": "V",
            "condition": "nominal supply voltage"
          }
        ]
      },
      "compute_capacity": {
        "values": [
          {
            "value": "2304",
            "unit": "MAC units",
            "condition": "convolution core"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "7.4",
            "unit": "TOPS/mm²",
            "condition": "area efficiency on DiCo model"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "17.4",
            "unit": "TOPS/W",
            "condition": "power efficiency on Diffusion ConvNet model"
          }
        ]
      },
      "generation_energy": {
        "values": [
          {
            "value": "0.011",
            "unit": "J/inference",
            "condition": "DiCo model"
          }
        ]
      },
      "generation_latency": {
        "values": [
          {
            "value": "0.116",
            "unit": "s",
            "condition": "DiCo model inference time"
          }
        ]
      },
      "memory_optimization": {
        "values": [
          {
            "value": "21% improvement",
            "unit": "L2 bandwidth",
            "condition": "optimal FM allocation vs greedy method"
          },
          {
            "value": "15% additional improvement",
            "unit": "L2 bandwidth",
            "condition": "with write-over-read relaxation"
          },
          {
            "value": "11% less area",
            "unit": "memory hierarchy",
            "condition": "vs naive L1:L2=1:4 allocation"
          },
          {
            "value": "27% lower EMA",
            "unit": "external memory access",
            "condition": "vs naive allocation baseline"
          }
        ]
      },
      "computation_efficiency": {
        "values": [
          {
            "value": "41% reduction",
            "unit": "resizer time",
            "condition": "with input preloading and concurrent resizing"
          },
          {
            "value": "45% reduction",
            "unit": "input loading time",
            "condition": "with activation-aware preloading"
          }
        ]
      },
      "quantization_capability": {
        "values": [
          {
            "value": "8b activations and weights",
            "unit": "precision",
            "condition": "maintains high output quality vs FP32"
          }
        ]
      },
      "comparison": "Highly efficient 3nm mini accelerator for edge diffusion model deployment achieving 7.4TOPS/mm² area efficiency and 17.4TOPS/W energy efficiency through hardware-compiler co-optimized memory hierarchy and operator parallelism, enabling low-energy generative AI on mobile devices.",
      "quantization": "8-bit (8b) activations and weights quantization"
    },
    "page_images": [
      "images/2.8/page_1.png",
      "images/2.8/page_2.png",
      "images/2.8/page_3.png"
    ]
  },
  {
    "id": "2.9",
    "session": 2,
    "title": "A 0.24mJ/Frame Quadratic Interpolation 4DGS Processor with Recursive Computation Reuse and Tree-Based Memory Optimization",
    "title_zh": "0.24mJ/帧二次插值4DGS处理器：递归计算复用与树状内存优化",
    "title_annotation": {
      "segments": [
        {
          "text": "0.24mJ/Frame",
          "meaning": "每帧能耗0.24毫焦",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Quadratic Interpolation",
          "meaning": "二次插值优化",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "4DGS",
          "meaning": "4D高斯溅射(动态场景渲染)",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Recursive Computation Reuse",
          "meaning": "递归计算复用",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Tree-Based Memory",
          "meaning": "树状内存优化",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "4DGS预处理阶段存储访问开销巨大",
        "related_idea_idx": 0,
        "text_en": "The pre-processing stage suffers from severe memory access overhead as loading 4DGS parameters accounts for 89.11% of total memory access."
      },
      {
        "text": "不透明度计算存在O(N²)冗余运算",
        "related_idea_idx": 1,
        "text_en": "The opacity computation suffers from O(N²) redundant computations which constitute 59.15% of the rendering computation."
      },
      {
        "text": "像素渲染负载不均导致PE利用率低",
        "related_idea_idx": 2,
        "text_en": "The pixel rendering exhibits highly imbalanced workload resulting in low PE utilization of only 28.1%."
      }
    ],
    "ideas": [
      {
        "text": "自适应二次帧插值替代预处理减62%访存",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Adaptive quadratic frame interpolation (AQFI) replaces memory-intensive pre-processing reducing memory access overhead by 62.1%."
      },
      {
        "text": "融合递归不透明度计算消除冗余运算",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Fused recursive opacity computation (FROC) eliminates redundant computations reducing rendering computation overhead by 59.15%."
      },
      {
        "text": "树形自适应精度并行渲染提升利用率2.6倍",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Tree-based adaptive-precision pixel rendering (TAPR) enables parallel rendering increasing PE utilization by 2.61×."
      }
    ],
    "affiliation": "Tsinghua",
    "authors": "Tsinghua Univ.",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "0.24mJ/frame",
    "target_model": "4DGS",
    "application": "动态3D场景渲染(VR/AR)",
    "innovations": [
      {
        "tag": "二次插值4DGS优化",
        "type": "sw"
      },
      {
        "tag": "递归计算复用",
        "type": "hw-arch"
      },
      {
        "tag": "树状内存访问优化",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "4DGS",
      "高斯溅射",
      "VR",
      "AR",
      "动态渲染",
      "3D"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Illustration of 4DGS rendering process and three main challenges of efﬁcient 4DGS rendering.",
        "path": "images/2.9/fig_1.png"
      },
      {
        "num": 2,
        "caption": "The overall architecture of the 4DGS processor. 59 2 SOTA NeRF processor [18], and 2.42× less than the SOTA 3DGS processor [20].",
        "path": "images/2.9/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Adaptive quadratic frame interpolation (AQFI) unit with quadratic interpolation of neighbor frames.",
        "path": "images/2.9/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Fused recursive opacity computation (FROC) unit recursively reuses redundant computations.",
        "path": "images/2.9/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Tree-based adaptive-precision pixel rendering (TAPR) core with tree- based parallel pixel rendering.",
        "path": "images/2.9/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison with state-of- the-art processors.",
        "path": "images/2.9/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and performance summary.",
        "path": "images/2.9/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "sram_kb": "204KB SRAM",
      "power_mw": "699.2",
      "energy_efficiency": "0.24mJ/frame",
      "target_model": "4DGS",
      "source_figure": "fig_7"
    },
    "data_path": "data/2.9/",
    "analytical_tags": [
      "可重构",
      "视觉/CV",
      "学界"
    ],
    "affiliation_info": {
      "name": "Tsinghua University",
      "name_zh": "清华大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/tsinghua-university.svg"
    },
    "abstract": "4D Gaussian Splatting (4DGS) has widespread applications in ﬁelds such as VR, AR and industrial simulation. However, 4DGS suffers from signiﬁcant memory requirements, redundant computations and low PE utilization. This paper introduces adaptive quadratic interpolation, recursive computation reuse and tree-based parallel rendering to tackle these challenges. The processor in the paper achieves a rendering energy of 0.24mJ/frame and improves energy efﬁciency by 6.11× on the D-Nerf dataset.",
    "metrics_detailed": {
      "technology": "28nm CMOS",
      "die_area": {
        "value": "3.65",
        "unit": "mm²",
        "note": "4D Gaussian Splatting rendering processor"
      },
      "on_chip_memory": {
        "values": [
          {
            "value": "204",
            "unit": "KB",
            "condition": "on-chip SRAM"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "110-500",
            "unit": "MHz",
            "condition": "operating range"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.60-1.0",
            "unit": "V",
            "condition": "operating range"
          }
        ]
      },
      "power_consumption": {
        "values": [
          {
            "value": "63.1-699.2",
            "unit": "mW",
            "condition": "across voltage and frequency range"
          },
          {
            "value": "87.7",
            "unit": "mW",
            "condition": "at 175MHz for real-time rendering"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "1043.6",
            "unit": "fps",
            "condition": "at 500MHz with 699.2mW on D-NeRF dataset"
          },
          {
            "value": "365.3",
            "unit": "fps",
            "condition": "at 175MHz for real-time rendering"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "16.27",
            "unit": "TFLOPS/W",
            "condition": "peak efficiency at 0.65V, 175MHz"
          }
        ]
      },
      "rendering_energy": {
        "values": [
          {
            "value": "0.24",
            "unit": "mJ/frame",
            "condition": "at 175MHz, 87.7mW on D-NeRF"
          },
          {
            "value": "26.4x lower",
            "unit": "energy reduction",
            "condition": "vs SOTA NeRF processor [18]"
          },
          {
            "value": "2.42x lower",
            "unit": "energy reduction",
            "condition": "vs SOTA 3DGS processor [20]"
          }
        ]
      },
      "performance_speedup": {
        "values": [
          {
            "value": "2.80x faster",
            "unit": "speed improvement",
            "condition": "vs SOTA rendering processor at peak throughput"
          },
          {
            "value": "6.23x speedup",
            "unit": "on D-NeRF dataset",
            "condition": "overall performance improvement"
          },
          {
            "value": "6.18x speedup",
            "unit": "on Immersive dataset",
            "condition": "overall performance improvement"
          },
          {
            "value": "6.31x speedup",
            "unit": "on Neu3D dataset",
            "condition": "overall performance improvement"
          }
        ]
      },
      "energy_efficiency_improvement": {
        "values": [
          {
            "value": "6.11x improvement",
            "unit": "energy efficiency",
            "condition": "on D-NeRF dataset"
          },
          {
            "value": "6.04x improvement",
            "unit": "energy efficiency",
            "condition": "on Immersive dataset"
          },
          {
            "value": "6.22x improvement",
            "unit": "energy efficiency",
            "condition": "on Neu3D dataset"
          }
        ]
      },
      "memory_access_optimization": {
        "values": [
          {
            "value": "62.1% reduction",
            "unit": "memory access energy",
            "condition": "via adaptive quadratic frame interpolation"
          },
          {
            "value": "59.8% reduction",
            "unit": "pre-processing time",
            "condition": "via AQFI optimization"
          }
        ]
      },
      "computation_optimization": {
        "values": [
          {
            "value": "59.15% reduction",
            "unit": "rendering computation",
            "condition": "via fused recursive opacity computation"
          },
          {
            "value": "2.14x improvement",
            "unit": "rendering throughput",
            "condition": "via FROC unit"
          }
        ]
      },
      "pe_utilization": {
        "values": [
          {
            "value": "2.61x improvement",
            "unit": "PE utilization increase",
            "condition": "via tree-based adaptive-precision pixel rendering"
          },
          {
            "value": "3.59x improvement",
            "unit": "TAPR throughput improvement",
            "condition": "overall rendering throughput"
          }
        ]
      },
      "comparison": "High-efficiency 4D Gaussian Splatting processor for dynamic scene rendering achieving 2.8x faster performance than SOTA with 26.4x lower energy than NeRF processors, enabling real-time rendering at 365fps with only 87.7mW on mobile/edge VR/AR applications.",
      "quantization": "FP16 and FP8 mixed-precision support"
    },
    "page_images": [
      "images/2.9/page_1.png",
      "images/2.9/page_2.png",
      "images/2.9/page_3.png"
    ]
  },
  {
    "id": "2.10",
    "session": 2,
    "title": "A 1286fps 0.39mJ/Frame Modeling/Rendering Unified 3D GS Processor with Locality-Optimized Computation and Memory",
    "title_zh": "1286fps 0.39mJ/帧建模/渲染统一3D GS处理器：局部性优化计算与内存",
    "title_annotation": {
      "segments": [
        {
          "text": "1286fps",
          "meaning": "每秒1286帧",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Modeling/Rendering Unified",
          "meaning": "建模与渲染统一架构",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "3D GS",
          "meaning": "3D高斯溅射",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Locality-Optimized",
          "meaning": "局部性优化",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "小高斯分布使粗粒度光栅化冗余严重",
        "related_idea_idx": 0,
        "text_en": "Small Gaussians cause severe redundancy in coarse-grained rasterization"
      },
      {
        "text": "Gather步骤产生大量2D中间数据访存",
        "related_idea_idx": 1,
        "text_en": "Gather step generates significant 2D Gaussian intermediate data memory access"
      },
      {
        "text": "建模与渲染异构架构带来额外面积开销",
        "related_idea_idx": 2,
        "text_en": "Heterogeneous architecture for modeling and rendering introduces additional area overhead"
      }
    ],
    "ideas": [
      {
        "text": "动态细粒度渲染引擎减89%冗余计算",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Dynamic Fine-Grained Rendering Engine reduces redundant computations by 89.2%"
      },
      {
        "text": "滑动窗口局部性优化消除Gather访存",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Sliding Window-Based canvas locality optimization eliminates gather step memory access"
      },
      {
        "text": "建模渲染统一可重构架构减40%面积",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Modeling/rendering Unified Reconfigurable Architecture reduces area by 40%"
      }
    ],
    "affiliation": "Tsinghua",
    "authors": "Tsinghua Univ.",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "0.39mJ/frame",
    "target_model": "3DGS (feedforward)",
    "application": "3D高斯溅射建模与渲染",
    "innovations": [
      {
        "tag": "建模/渲染统一架构",
        "type": "hw-arch"
      },
      {
        "tag": "局部性优化内存访问",
        "type": "hw-arch"
      },
      {
        "tag": "自适应细粒度光栅化",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "3DGS",
      "高斯溅射",
      "VR",
      "建模",
      "渲染",
      "统一架构"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Overview of feedforward 3D Gaussian splatting modeling and challenges of traditional 3D GS processor.",
        "path": "images/2.10/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall chip architecture and key features of the proposed modeling/rendering uniﬁed 3D GS processor.",
        "path": "images/2.10/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Locality-aware dynamic ﬁne-grained rendering engine featuring a scanline-based traversal unit for reduced redundant computation.",
        "path": "images/2.10/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Locality-optimized uniﬁed rendering workﬂow adopting sliding window- based canvas and scale-penalized gaussians to reduce EMA.",
        "path": "images/2.10/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Uniﬁed reconﬁgurable architecture for neural modeling and Gaussian splatting rendering via exploitation of dataﬂow similarity.",
        "path": "images/2.10/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and performance comparison table.",
        "path": "images/2.10/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die photo and chip summary.",
        "path": "images/2.10/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "die_area_mm2": "4.76",
      "supply_voltage": "1.01V",
      "sram_kb": "122KB of SRAM",
      "power_mw": "507.0",
      "throughput": "throughput of 1286fps",
      "energy_efficiency": "0.39mJ/frame",
      "target_model": "3DGS (feedforward)",
      "source_figure": "fig_7"
    },
    "supply_voltage": "1.01V",
    "data_path": "data/2.10/",
    "analytical_tags": [
      "可重构",
      "视觉/CV",
      "学界"
    ],
    "affiliation_info": {
      "name": "Tsinghua University",
      "name_zh": "清华大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/tsinghua-university.svg"
    },
    "abstract": "A modeling/rendering uniﬁed 3D GS processor is proposed with: 1) A locality-aware dynamic ﬁne-grained rendering engine for reduced redundant computation. 2) A locality-optimized uniﬁed rendering workﬂow to reduce EMA. 3) A uniﬁed reconﬁgurable architecture for neural modeling and Gaussian rendering with minimal area overhead. It achieves 3.4× higher rendering throughput and 74.1% lower energy per frame than SOTA 3D GS accelerators, and an orders-of-magnitude reduction in modeling latency.",
    "metrics_detailed": {
      "technology": "28nm CMOS",
      "die_area": {
        "value": "4.76",
        "unit": "mm²",
        "note": "unified 3D Gaussian Splatting processor for modeling and rendering"
      },
      "on_chip_memory": {
        "values": [
          {
            "value": "122",
            "unit": "KB",
            "condition": "SRAM for Gaussian parameters, images, features, weights, and output"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "80-680",
            "unit": "MHz",
            "condition": "operating range"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.58-1.01",
            "unit": "V",
            "condition": "operating range"
          }
        ]
      },
      "rendering_throughput": {
        "values": [
          {
            "value": "1286",
            "unit": "fps",
            "condition": "at 680MHz on both optimization-based and feedforward 3D GS models"
          }
        ]
      },
      "rendering_power": {
        "values": [
          {
            "value": "507",
            "unit": "mW",
            "condition": "at 680MHz for rendering"
          }
        ]
      },
      "rendering_energy": {
        "values": [
          {
            "value": "0.15",
            "unit": "mJ/frame",
            "condition": "at 80MHz for efficient operation"
          },
          {
            "value": "0.39",
            "unit": "mJ/frame",
            "condition": "typical per-frame energy"
          }
        ]
      },
      "rendering_efficiency": {
        "values": [
          {
            "value": "11.7x improvement",
            "unit": "throughput over NeRF accelerators",
            "condition": "at peak 680MHz"
          },
          {
            "value": "3.4x improvement",
            "unit": "throughput over 3D GS accelerators",
            "condition": "at peak throughput"
          },
          {
            "value": "74.1% lower",
            "unit": "energy per frame",
            "condition": "vs SOTA rendering accelerator at 80MHz"
          }
        ]
      },
      "modeling_performance": {
        "values": [
          {
            "value": "0.30",
            "unit": "seconds",
            "condition": "feedforward 3D GS modeling inference time"
          },
          {
            "value": "order of magnitude reduction",
            "unit": "latency improvement",
            "condition": "vs optimization-based modeling accelerators"
          }
        ]
      },
      "modeling_power": {
        "values": [
          {
            "value": "1067",
            "unit": "mW",
            "condition": "at 680MHz for modeling mode"
          },
          {
            "value": "0.3%",
            "unit": "of GPU power",
            "condition": "modeling power relative to GPU"
          }
        ]
      },
      "architecture_efficiency": {
        "values": [
          {
            "value": "40.2% reduction",
            "unit": "area overhead",
            "condition": "unified architecture vs heterogeneous"
          },
          {
            "value": "4.04x higher",
            "unit": "throughput improvement",
            "condition": "sparse FP8 vs dense FP16 computation"
          },
          {
            "value": "8.26x better",
            "unit": "energy efficiency",
            "condition": "sparse FP8 vs dense FP16 in modeling"
          }
        ]
      },
      "rendering_optimization": {
        "values": [
          {
            "value": "89.2% reduction",
            "unit": "computational load",
            "condition": "DFGRE with AABB vs 16x16 static array"
          },
          {
            "value": "8.4x improvement",
            "unit": "efficiency",
            "condition": "with AABB boundary detection"
          },
          {
            "value": "58.1% additional reduction",
            "unit": "computation",
            "condition": "adding scanline-based boundary detection"
          },
          {
            "value": "63.6x efficiency improvement",
            "unit": "with SBTU",
            "condition": "vs static coarse-grained approach"
          }
        ]
      },
      "memory_optimization": {
        "values": [
          {
            "value": "42.6% reduction",
            "unit": "external memory access",
            "condition": "on Synthetic NeRF dataset via LOUR"
          },
          {
            "value": "34.1% reduction",
            "unit": "external memory access",
            "condition": "on RE10K dataset via LOUR"
          },
          {
            "value": "5.36",
            "unit": "dB quality recovery",
            "condition": "via SWB canvas and SPG method"
          }
        ]
      },
      "quantization_capability": {
        "values": [
          {
            "value": "8b activations and weights",
            "unit": "precision",
            "condition": "maintains high output quality in rendering"
          },
          {
            "value": "FP16/FP8 reconfigurable",
            "unit": "precision support",
            "condition": "neural multiply-accumulators"
          }
        ]
      },
      "comparison": "Unified 3D Gaussian Splatting processor achieving 11.7x higher throughput than NeRF and 3.4x over conventional 3D GS accelerators, with 74.1% lower energy per frame, supporting both optimization-based and feedforward modeling/rendering with minimal area overhead for mobile deployment.",
      "quantization": "FP16 and FP8 mixed-precision with sparse computation support"
    },
    "page_images": [
      "images/2.10/page_1.png",
      "images/2.10/page_2.png",
      "images/2.10/page_3.png"
    ]
  },
  {
    "id": "10.1",
    "session": 10,
    "title": "A 3nm 400TOPS 1080k DMIPS SoC with Chiplet Support for ASIL D Automotive Cross-Domain Applications",
    "title_zh": "3nm 400TOPS 1080k DMIPS汽车SoC：支持ASIL D跨域应用的芯粒架构",
    "title_annotation": {
      "segments": [
        {
          "text": "3nm",
          "meaning": "3纳米工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "400TOPS",
          "meaning": "400万亿次/秒AI算力",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Chiplet Support",
          "meaning": "芯粒扩展支持",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "ASIL D",
          "meaning": "最高汽车安全完整性等级",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Cross-Domain",
          "meaning": "跨域融合(自动驾驶+座舱)",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "Chiplet互联缺乏功能安全FFI机制",
        "related_idea_idx": 0,
        "text_en": "Chiplet interconnect lacks functional safety FFI mechanism"
      },
      {
        "text": "大规模NPU时钟延迟超出时序窗口",
        "related_idea_idx": 1,
        "text_en": "Large-scale NPU clock latency exceeds timing window"
      },
      {
        "text": "高功耗密度下IR-drop影响可靠性",
        "related_idea_idx": 2,
        "text_en": "High power density IR-drop affects reliability"
      },
      {
        "text": "多功能汽车SoC需精细功耗模式管理",
        "related_idea_idx": 3,
        "text_en": "Multi-functional automotive SoC requires fine-grained power mode management"
      }
    ],
    "ideas": [
      {
        "text": "基于RegionID的UCIe FFI架构",
        "type": "system",
        "color": "#3498db",
        "text_en": "RegionID-based UCIe FFI architecture"
      },
      {
        "text": "分层mCPG时钟分配与统一调谐",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Hierarchical mCPG clock distribution with unified tuning"
      },
      {
        "text": "Ring+Row双模式功率开关降IR-drop",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Ring+Row dual-mode power switch reduces IR-drop"
      },
      {
        "text": "90+电源域精细功率门控管理",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "90+ power domain fine-grained power gating management"
      }
    ],
    "affiliation": "Renesas Electronics",
    "authors": "Renesas Electronics",
    "process_node": "3nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "400TOPS",
    "target_model": "N/A",
    "application": "汽车跨域SoC(SDV)",
    "innovations": [
      {
        "tag": "跨域自动驾驶+座舱融合SoC",
        "type": "system"
      },
      {
        "tag": "ASIL D功能安全架构",
        "type": "hw-arch"
      },
      {
        "tag": "芯粒扩展支持",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "汽车",
      "SoC",
      "3nm",
      "ASIL D",
      "自动驾驶",
      "芯粒"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "What the automotive SoC aims to achieve for SDVs.",
        "path": "images/10.1/fig_1.png"
      },
      {
        "num": 2,
        "caption": "SoC block diagram showing the highly integrated high-performance cores on a single chip.",
        "path": "images/10.1/fig_2.png"
      },
      {
        "num": 3,
        "caption": "ASIL D capable FFI architecture with RegionID for chiplet.",
        "path": "images/10.1/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Clock distribution for the advanced large-scale and high-performance chip enabled by the layer tuning method.",
        "path": "images/10.1/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Automotive power scenarios enabled by multiple power-saving operation modes.",
        "path": "images/10.1/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Hybrid power gating for compensating voltage-drop in a high-power consumption chip with ASIL D capability.",
        "path": "images/10.1/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and speciﬁcation overview with the Shmoo plot result.",
        "path": "images/10.1/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "3nm",
      "energy_efficiency": "400TOPS",
      "throughput": "400TOPS,",
      "target_model": "N/A",
      "source_figure": "fig_7"
    },
    "data_path": "data/10.1/",
    "analytical_tags": [
      "芯粒/Chiplet",
      "业界"
    ],
    "affiliation_info": {
      "name": "Renesas Electronics",
      "name_zh": "瑞萨电子",
      "type": "industry",
      "country": "日本",
      "country_code": "JP",
      "logo": "assets/logos/renesas-electronics.svg"
    },
    "abstract": "This paper presents a 3nm SoC, designed for software deﬁned vehicles, integrating various functions for zone-based computing. The chip includes a 1,080kDMIPS APU, 400TOPS NPU and 51.2GB/s inter-chip bandwidth. Functional safety is ensured by RegionID-based FFI over UCIe. Power efﬁciency is achieved with ﬁne-gating across 90+ power domains with enhanced IR-drop control and ASIL D-compliant DCLS. Hierarchical mCPGs reduce clock latency. The chip supports low-power modes such as Sentry and CPD.",
    "metrics_detailed": {
      "technology": "3nm CMOS",
      "die_area": {
        "value": "1 (single chip)",
        "unit": "chip",
        "note": "chiplet support with 9mm HBI inter-chiplet bandwidth"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.5-1.2",
            "unit": "V",
            "condition": "core operating range"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "2.7",
            "unit": "GHz",
            "condition": "APU operation"
          },
          {
            "value": "1.066",
            "unit": "GHz",
            "condition": "NPU operation"
          }
        ]
      },
      "power": {
        "values": []
      },
      "performance": {
        "values": [
          {
            "value": "1080",
            "unit": "k DMIPS",
            "condition": "APU peak"
          },
          {
            "value": "400",
            "unit": "TOPS",
            "condition": "NPU peak"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "51.2",
            "unit": "GB/s",
            "condition": "inter-chip bandwidth via UCIe"
          }
        ]
      },
      "memory": {
        "values": [
          {
            "value": "90+",
            "unit": "power domains",
            "condition": "fine-grained power gating"
          }
        ]
      },
      "comparison": "ASIL D compliant automotive SoC with RegionID-based FFI over UCIe for zone-based computing",
      "key_features": [
        "Heterogeneous APU+NPU architecture",
        "ASIL D functional safety",
        "Hierarchical mCPG for clock latency control",
        "Hybrid power gating with dual-PSW for IR-drop control"
      ]
    },
    "page_images": [
      "images/10.1/page_1.png",
      "images/10.1/page_2.png",
      "images/10.1/page_3.png"
    ]
  },
  {
    "id": "10.2",
    "session": 10,
    "title": "A Dynamic Performance Augmentation in a 3nm-Plus Mobile CPU",
    "title_zh": "3nm+ 移动CPU动态性能增强技术",
    "title_annotation": {
      "segments": [
        {
          "text": "Dynamic Performance Augmentation",
          "meaning": "动态性能增强(DMPA)",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "3nm-Plus",
          "meaning": "3nm+工艺节点",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Mobile CPU",
          "meaning": "移动端CPU",
          "color": "#3498db",
          "type": "system"
        }
      ]
    },
    "challenges": [
      {
        "text": "高电压提升单核性能受老化预算限制",
        "related_idea_idx": 0,
        "text_en": "High voltage boosting single-core performance is limited by aging budget"
      },
      {
        "text": "性能提升引发CPU热点温度飙升",
        "related_idea_idx": 1,
        "text_en": "Performance boosting causes CPU hotspot temperature spikes"
      },
      {
        "text": "温度传感器受电压缩放影响精度下降",
        "related_idea_idx": 2,
        "text_en": "Temperature sensor accuracy degrades due to voltage scaling effects"
      }
    ],
    "ideas": [
      {
        "text": "数字老化传感器管控升压占空比",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Digital aging sensor manages boosting-duty control"
      },
      {
        "text": "自适应硬件热控制器25ms快速响应",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Adaptive thermal cooler provides 25ms fast response"
      },
      {
        "text": "差分电压温度补偿消除DIBL误差",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Differential-voltage temperature compensation eliminates DIBL error"
      }
    ],
    "affiliation": "MediaTek",
    "authors": "MediaTek",
    "process_node": "3nm+",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "",
    "target_model": "N/A",
    "application": "移动端SoC/游戏",
    "innovations": [
      {
        "tag": "动态性能增强(DMPA)",
        "type": "hw-circuit"
      },
      {
        "tag": "增强占空控制(BDC)",
        "type": "hw-circuit"
      },
      {
        "tag": "硬件自适应电压频率(HAVFS)",
        "type": "hw-circuit"
      }
    ],
    "tags": [
      "CPU",
      "移动端",
      "3nm",
      "性能增强",
      "电压调节",
      "游戏"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Ever-higher single-core performance demands and aging limitations of maximum voltage in 3nm-plus mobile ﬂagship smartphone CPU.",
        "path": "images/10.2/fig_1.png"
      },
      {
        "num": 2,
        "caption": "The DMPA of the CPU with BDC/ATC block diagram and architecture in 3nm-plus SoC.",
        "path": "images/10.2/fig_2.png"
      },
      {
        "num": 3,
        "caption": "The CPU performance boost with CPP efﬁciency and design margin optimization to achieve higher OPP0+.",
        "path": "images/10.2/fig_3.png"
      },
      {
        "num": 4,
        "caption": "The proposed Boosting-Duty Control (BDC) with a digital A-sensor to leverage available aging-budget in CPU.",
        "path": "images/10.2/fig_4.png"
      },
      {
        "num": 5,
        "caption": "The digital T-sensor with proposed Differential-Voltage-based Temperature Compensation (DVTC) achieving fast and accurate temperature sensing in silicon for the CPU.",
        "path": "images/10.2/fig_5.png"
      },
      {
        "num": 6,
        "caption": "The Dynamic Mobile-Performance Augmentation (DMPA) contains the ATC and BDC for the CPU with silicon measurement results.",
        "path": "images/10.2/fig_6.png"
      },
      {
        "num": 7,
        "caption": "The 3nm-plus CPU die-photo with DMPA feature summary and on-phone benchmark demonstration.",
        "path": "images/10.2/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "3nm+",
      "frequency_mhz": "3500",
      "target_model": "N/A",
      "source_figure": "fig_7"
    },
    "frequency_mhz": "3500",
    "data_path": "data/10.2/",
    "analytical_tags": [
      "业界"
    ],
    "affiliation_info": {
      "name": "MediaTek",
      "name_zh": "联发科",
      "type": "industry",
      "country": "中国台湾",
      "country_code": "CN",
      "logo": "assets/logos/mediatek.svg"
    },
    "abstract": "This work presents dynamic mobile-performance augmentation (DMPA), featuring boosting- duty control (BDC) and an adaptive thermal cooler (ATC) to augment CPU maximum performance. The BDC uses an aging sensor (A-sensor) to leverage an aging budget for performance boosting. For thermal, the ATC integrates temperature sensors (T-sensors) across the CPU and works with multiple sensors and a throttler to optimize clock speed effectively cooling hotspots. The DMPA offers a score of 3917 in the GeekBenchv6 single- core benchmark on a ﬂagship smartphone, consuming 0.078% or less total power, while occupying only 0.0122% of the CPU area.",
    "metrics_detailed": {
      "technology": "3nm-plus CMOS",
      "die_area": {
        "value": "24.69",
        "unit": "mm²",
        "note": "multi-core CPU with DMPA"
      },
      "supply_voltage": {
        "values": []
      },
      "frequency": {
        "values": [
          {
            "value": "4.21",
            "unit": "GHz",
            "condition": "HP core base"
          },
          {
            "value": "4.4-4.5",
            "unit": "GHz",
            "condition": "HP core with boost (DMPA)"
          },
          {
            "value": "3.5",
            "unit": "GHz",
            "condition": "3x BP cores"
          },
          {
            "value": "2.7",
            "unit": "GHz",
            "condition": "4x HE cores"
          }
        ]
      },
      "cpu_cores": {
        "value": "8",
        "unit": "cores",
        "note": "1x HP + 3x BP + 4x HE, ARMv9.4"
      },
      "performance": {
        "values": [
          {
            "value": "3917",
            "unit": "GeekBenchv6 single-core",
            "condition": "with DMPA"
          },
          {
            "value": "3762",
            "unit": "GeekBenchv6 single-core",
            "condition": "without DMPA"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "0.078",
            "unit": "% of total CPU power",
            "condition": "DMPA overhead at max"
          }
        ]
      },
      "area": {
        "values": [
          {
            "value": "0.0024",
            "unit": "% of CPU area",
            "condition": "BDC area"
          },
          {
            "value": "0.0098",
            "unit": "% of CPU area",
            "condition": "ATC area"
          }
        ]
      },
      "thermal": {
        "values": [
          {
            "value": "25",
            "unit": "ms",
            "condition": "ATC temperature sensing response time"
          },
          {
            "value": "+2.5/-1.6",
            "unit": "°C",
            "condition": "T-sensor accuracy (-40 to 100°C with DVTC)"
          }
        ]
      },
      "comparison": "4.5% max performance improvement via dynamic mobile performance augmentation with aging budget control",
      "aging_budget": {
        "value": "leveraged for boosting duty time",
        "note": "boosting-duty control (BDC) with aging sensor"
      }
    },
    "page_images": [
      "images/10.2/page_1.png",
      "images/10.2/page_2.png",
      "images/10.2/page_3.png"
    ]
  },
  {
    "id": "10.3",
    "session": 10,
    "title": "A 2nm Clock-Edge Architecture for Processor Clock-Power Reduction",
    "title_zh": "2nm时钟边沿架构：处理器时钟功耗降低",
    "title_annotation": {
      "segments": [
        {
          "text": "2nm",
          "meaning": "2nm GAA工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Clock-Edge Architecture",
          "meaning": "双沿触发时钟架构",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "Clock-Power Reduction",
          "meaning": "时钟功耗降低",
          "color": "#e67e22",
          "type": "hw-circuit"
        }
      ]
    },
    "challenges": [
      {
        "text": "传统单沿触发浪费一半动态时钟功耗",
        "related_idea_idx": 0,
        "text_en": "Conventional single-edge-triggered flip-flops waste half of the dynamic clock power from a microarchitecture perspective"
      },
      {
        "text": "时钟占空比失真严重降低DET性能",
        "related_idea_idx": 1,
        "text_en": "Clock duty-cycle distortion negatively impacts processor performance where the shortest clock-phase delay limits the performance"
      },
      {
        "text": "已有DET触发器缺少复位与DFT功能",
        "related_idea_idx": 2,
        "text_en": "Prior DET FF designs lack reset and design-for-test functionality while maintaining similar timing and low clock power as compared to production-level SET FFs"
      },
      {
        "text": "已有DET时钟门控引入周期间DCD",
        "related_idea_idx": 3,
        "text_en": "The prior-art DET clock-gating circuit induces cycle-to-cycle clock DCD resulting in performance degradation"
      }
    ],
    "ideas": [
      {
        "text": "双沿触发架构半频运行降低时钟功耗",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Dual-edge-triggered FFs enable the processor to operate at half the clock frequency for the same throughput significantly reducing the processor clock power"
      },
      {
        "text": "自适应时钟占空比控制器校正DCD",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "An adaptive clock duty-cycle controller mitigates clock DCD for maximum performance"
      },
      {
        "text": "带复位和DFT功能的低功耗DET触发器",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "A low-clock-power DET FF with reset and DFT capabilities and similar timing as an SET FF"
      },
      {
        "text": "基于XNOR的DET时钟门控最小化DCD",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "The proposed DET CGC with XNOR-logic gate minimizes the cycle-to-cycle clock DCD"
      }
    ],
    "affiliation": "Qualcomm",
    "authors": "Qualcomm",
    "process_node": "2nm GAA",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "30% clock power reduction",
    "target_model": "NPU MXU",
    "application": "处理器时钟功耗优化",
    "innovations": [
      {
        "tag": "双沿触发FF(DET)量产化",
        "type": "hw-circuit"
      },
      {
        "tag": "自适应占空比控制器",
        "type": "hw-circuit"
      },
      {
        "tag": "2nm GAA工艺验证",
        "type": "system"
      }
    ],
    "tags": [
      "时钟",
      "2nm",
      "GAA",
      "DET FF",
      "功耗",
      "NPU"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Conventional (CNV) design and clock-edge architecture (CEA) timing diagrams with a clock-gating circuit (CGC) and test-chip block diagram, containing the adaptive clock duty-cycle controller (DCC) and two NPU MXUs with CNV and CEA designs.",
        "path": "images/10.3/fig_1.png"
      },
      {
        "num": 2,
        "caption": "CEA dual-edge-triggered (DET) ﬂip-ﬂop (FF) and DET CGC circuit schematics. Q CKI CKB CKI CKB D NSHIFT SHIFT NSHIFT SHIFT SIN SIN CKB CKI CKB CKI CKI CLK CKB SHIFT NSHIFT SIN RST RST XNOR ENB ENI CLKIN ENI ENB EN ENB ENI ENI ENB ENB ENI XOR CKB CLKOUT CP CKB Proposed DET FF Input Mux Negative Latch Positive Latch Output Mux Latch #1 Latch #2 Proposed DET CGC CKI CKB nn1 RST RST CKI CKB pn1 RST RST nn2 pn2 clk_in clk_cnv CGC BIST CGC MAC1 MAC16 MAC Array #1 …...",
        "path": "images/10.3/fig_2.png"
      },
      {
        "num": 3,
        "caption": "DCC block diagram, consisting of the duty-cycle monitor (DCM), duty- cycle adjuster (DCA), and DCA adaptive control, and measured normalized CEA MXU throughput (TP) vs.",
        "path": "images/10.3/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Measured MXU minimum VDD (VMIN) for CNV and CEA vs. TP, MXU VMIN distribution for CNV and CEA vs.",
        "path": "images/10.3/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Measured MXU clock power vs. operating condition, MXU total dynamic power vs. workload, and CEA MXU total dynamic power reduction vs.",
        "path": "images/10.3/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measured distributions of CEA MXU total dynamic power reduction vs. operating condition for peak-performance and typical workloads across 40 parts while capturing the ΔVMIN impact for each part.",
        "path": "images/10.3/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Test-chip microphotograph, characteristics, and comparisons of the SET FF vs. the proposed DET FF and the prior-art DET CGC [18] vs.",
        "path": "images/10.3/fig_7.png"
      }
    ],
    "metrics": {
      "supply_voltage": "0.7V",
      "technology": "2nm GAA",
      "energy_efficiency": "30% clock power reduction",
      "target_model": "NPU MXU",
      "source_figure": "fig_7"
    },
    "supply_voltage": "0.7V",
    "data_path": "data/10.3/",
    "analytical_tags": [
      "业界"
    ],
    "affiliation_info": {
      "name": "Qualcomm",
      "name_zh": "高通",
      "type": "industry",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/qualcomm.svg"
    },
    "abstract": "A 2nm clock-edge architecture (CEA) for an NPU matrix-multiplication unit (MXU) features dual-edge-triggered (DET) ﬂip-ﬂops, DET clock-gating circuits, and an adaptive clock duty- cycle controller to achieve iso-performance as a conventional (CNV) design while operating at half the clock frequency. Silicon measurements of the CEA MXU demonstrate ~39-40% lower clock power and a total dynamic power reduction of ~7-15%, depending on the workload, as compared to the CNV MXU at iso-throughput.",
    "metrics_detailed": {
      "technology": "2nm CMOS with GAA",
      "die_area": {
        "value": "test chip integration",
        "unit": "chip",
        "note": "CNV and CEA MXU comparison"
      },
      "architecture": "Clock-Edge Architecture (CEA) with dual-edge-triggered flip-flops",
      "frequency": {
        "values": [
          {
            "value": "half FCLK",
            "unit": "CEA vs CNV",
            "condition": "for iso-throughput"
          }
        ]
      },
      "clock_power": {
        "values": [
          {
            "value": "39-40",
            "unit": "% reduction",
            "condition": "at iso-VDD and iso-TP"
          }
        ]
      },
      "dynamic_power": {
        "values": [
          {
            "value": "9",
            "unit": "% reduction",
            "condition": "peak-performance workload, SVS-turbo"
          },
          {
            "value": "17",
            "unit": "% reduction",
            "condition": "typical workload, SVS-turbo"
          }
        ]
      },
      "dynamic_power_with_vmin": {
        "values": [
          {
            "value": "7-8",
            "unit": "% reduction",
            "condition": "peak-performance with ΔVMIN compensation"
          },
          {
            "value": "16-17",
            "unit": "% reduction",
            "condition": "typical workload with ΔVMIN compensation"
          }
        ]
      },
      "vmin_penalty": {
        "values": [
          {
            "value": "4",
            "unit": "mV higher",
            "condition": "CEA vs CNV at SVS"
          },
          {
            "value": "4",
            "unit": "mV higher",
            "condition": "CEA vs CNV at nominal"
          },
          {
            "value": "9",
            "unit": "mV higher",
            "condition": "CEA vs CNV at turbo"
          }
        ]
      },
      "comparison": "Dual-edge-triggered flip-flops achieve 7-17% dynamic power reduction at iso-throughput",
      "clock_duty_cycle_distortion": {
        "value": "2.6×",
        "unit": "reduction in cycle-to-cycle DCD",
        "condition": "proposed DET CGC vs prior-art"
      }
    },
    "page_images": [
      "images/10.3/page_1.png",
      "images/10.3/page_2.png",
      "images/10.3/page_3.png"
    ]
  },
  {
    "id": "10.4",
    "session": 10,
    "title": "A 0.008mm² 16-to-1600MHz All-Digital Fractional Divider Using AUX-DLL for Background LMS-Based DTC Calibration",
    "title_zh": "0.008mm² 16~1600MHz全数字分频器：基于辅助DLL的后台LMS DTC校准",
    "title_annotation": {
      "segments": [
        {
          "text": "0.008mm²",
          "meaning": "极小面积0.008mm²",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "All-Digital Fractional Divider",
          "meaning": "全数字分数分频器",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "AUX-DLL",
          "meaning": "辅助延迟锁定环",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "LMS-Based DTC Calibration",
          "meaning": "基于LMS算法的DTC校准",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "多PLL时钟生成面积和功耗开销大",
        "related_idea_idx": 0,
        "text_en": "Multiple PLLs increase silicon area, power consumption and system complexity"
      },
      {
        "text": "DTC增益校准受路径失配精度受限",
        "related_idea_idx": 1,
        "text_en": "DTC gain calibration suffers from limited accuracy due to random and systematic mismatches between paths"
      },
      {
        "text": "宽频数字DLL易出现锁定失败问题",
        "related_idea_idx": 2,
        "text_en": "Wide frequency range digital DLL is prone to lock failure problems"
      }
    ],
    "ideas": [
      {
        "text": "开环分频器替代多PLL生成多路时钟",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Open-loop fractional dividers replace multiple PLLs to generate multiple clock frequencies"
      },
      {
        "text": "辅助DLL实现无副本LMS增益校准",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Auxiliary DLL enables replica-free LMS gain calibration"
      },
      {
        "text": "三态PFD防止DLL谐波和卡死锁定",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Three-state PFD prevents DLL harmonic and dead lock conditions"
      }
    ],
    "affiliation": "Broadcom",
    "authors": "Broadcom",
    "process_node": "7nm CMOS",
    "die_area_mm2": "0.008",
    "power_mw": "11.2",
    "energy_efficiency": "",
    "target_model": "N/A",
    "application": "时钟生成(SoC)",
    "innovations": [
      {
        "tag": "辅助DLL后台LMS校准",
        "type": "hw-circuit"
      },
      {
        "tag": "超紧凑0.008mm²分频器",
        "type": "hw-circuit"
      }
    ],
    "tags": [
      "时钟",
      "PLL",
      "分频器",
      "DTC",
      "LMS",
      "校准"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Block diagrams of conventional FDIVs and the proposed FDIV.",
        "path": "images/10.4/fig_1.png"
      },
      {
        "num": 2,
        "caption": "FDIV implementation details. 175 10 DLL and LMS measured results of 550 parts from corner-wafers.",
        "path": "images/10.4/fig_2.png"
      },
      {
        "num": 3,
        "caption": "False-locking prevention technique for wide-range digital DLL.",
        "path": "images/10.4/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Measured phase-noise in integer- and fractional-N modes of operation.",
        "path": "images/10.4/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Measured spurs and integrated jitter across fractional division factor (α) and supply voltage (top), measured IDACG and IDACD codes of 550 parts (bottom).",
        "path": "images/10.4/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Performance summary and comparison with state-of-the art.",
        "path": "images/10.4/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph.",
        "path": "images/10.4/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "7nm CMOS",
      "supply_voltage": "0.9V",
      "die_area_mm2": "0.008",
      "power_mw": "11.2",
      "target_model": "N/A",
      "source_figure": "fig_7"
    },
    "supply_voltage": "0.9V",
    "data_path": "data/10.4/",
    "analytical_tags": [
      "业界"
    ],
    "affiliation_info": {
      "name": "Broadcom",
      "name_zh": "博通",
      "type": "industry",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/broadcom.svg"
    },
    "abstract": "An all-digital high-performance standalone fractional divider (FDIV) is presented. It leverages a robust replica-free least-mean square (LMS)-based digital-to-time converter (DTC) background calibration using a compact auxiliary delay locked loop (AUX-DLL). The proposed FDIV provides a wide output frequency range (16-1600MHz) with very ﬁne frequency resolution (50b) and achieves worst-case integrated jitter performance of 350fsrms, while occupying only 0.008mm2.",
    "metrics_detailed": {
      "technology": "7nm CMOS",
      "die_area": {
        "value": "0.008",
        "unit": "mm²",
        "note": "standalone fractional divider only"
      },
      "frequency": {
        "values": [
          {
            "value": "8-32",
            "unit": "GHz",
            "condition": "input frequency range"
          },
          {
            "value": "16-1600",
            "unit": "MHz",
            "condition": "output frequency range"
          },
          {
            "value": "0.8-1.6",
            "unit": "GHz",
            "condition": "DTC/DLL operating frequency after post-divider"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "10",
            "unit": "mW",
            "condition": "at 1.6GHz, 0.9V supply"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.9",
            "unit": "V",
            "condition": "nominal supply"
          }
        ]
      },
      "jitter": {
        "values": [
          {
            "value": "350",
            "unit": "fs_rms",
            "condition": "worst-case integrated jitter [100kHz-100MHz]"
          },
          {
            "value": "352",
            "unit": "fs_rms",
            "condition": "fractional-N mode"
          },
          {
            "value": "282",
            "unit": "fs_rms",
            "condition": "integer-N mode"
          },
          {
            "value": "0.3",
            "unit": "ps_rms",
            "condition": "with DTC QNC calibration"
          },
          {
            "value": "1.65",
            "unit": "ps_rms",
            "condition": "without DTC QNC"
          }
        ]
      },
      "spurs": {
        "values": [
          {
            "value": "-69",
            "unit": "dBc",
            "condition": "at 0.9GHz output"
          },
          {
            "value": "-50",
            "unit": "dBc",
            "condition": "worst-case (α=2-17)"
          }
        ]
      },
      "frequency_resolution": {
        "value": "50",
        "unit": "bits",
        "note": "very fine resolution"
      },
      "comparison": "5× higher output frequency than prior FDIVs; 4× better jitter; 10× smaller area than aux-PLL approach",
      "calibration": "LMS-based DTC background calibration using compact AUX-DLL, replica-free"
    },
    "page_images": [
      "images/10.4/page_1.png",
      "images/10.4/page_2.png",
      "images/10.4/page_3.png"
    ]
  },
  {
    "id": "10.5",
    "session": 10,
    "title": "Proactive Power Management-Based Supply Regulation with Online Learning for Variation-Tolerant High-Performance Microprocessors",
    "title_zh": "基于在线学习的前瞻式电源管理与供电调节：面向容变高性能微处理器",
    "title_annotation": {
      "segments": [
        {
          "text": "Proactive Power Management",
          "meaning": "前瞻式电源管理",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Online Learning",
          "meaning": "在线机器学习",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Variation-Tolerant",
          "meaning": "容忍工艺/电压/温度变化",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "Supply Regulation",
          "meaning": "供电调节",
          "color": "#e67e22",
          "type": "hw-circuit"
        }
      ]
    },
    "challenges": [
      {
        "text": "PDN阻抗PVT变化导致压降预测不准",
        "related_idea_idx": 0,
        "text_en": "Package-level impedance variations and die-level Process-Voltage-Temperature (PVT) variations cause significant uncertainty of the droop magnitude and frequency due to the deviation of power delivery network (PDN) impedance from the pre-silicon design."
      },
      {
        "text": "时钟节流缓解压降带来严重性能损失",
        "related_idea_idx": 1,
        "text_en": "Clock throttling introduces significant performance penalties, e.g. up to 30% in recent reports, along with unresolved supply undershoot or overshoot causing reliability and signal integrity degradation."
      },
      {
        "text": "功率转换器效率与响应速度难以兼顾",
        "related_idea_idx": 2,
        "text_en": "Integrated power converters face an efficiency-speed trade-off, where large off-chip inductors offer high efficiency but suffer from slow transient response, while small in-package/on-die inductors respond faster at the cost of efficiency loss."
      }
    ],
    "ideas": [
      {
        "text": "在线迁移学习适应PDN与负载变化",
        "type": "sw",
        "color": "#2ecc71",
        "text_en": "An online transfer learning scheme captures PDN and workload variations by fine-tuning the prediction model with an online learning engine (OLE)."
      },
      {
        "text": "神经网络前馈预测实现主动压降调控",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "A workload-aware proactive power management using neural network feedforward prediction achieves near-optimal droop regulation with minimal performance loss."
      },
      {
        "text": "双电感Buck转换器兼顾效率与速度",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "A dual-inductor buck converter employs both off-chip and on-chip inductors to achieve both high efficiency and high speed."
      }
    ],
    "affiliation": "Northwestern University",
    "authors": "Northwestern University",
    "process_node": "Intel 3",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "",
    "target_model": "N/A",
    "application": "微处理器电源管理",
    "innovations": [
      {
        "tag": "ML前瞻式电源管理",
        "type": "sw"
      },
      {
        "tag": "在线学习PDN阻抗适应",
        "type": "co-design"
      },
      {
        "tag": "集成DC-DC转换器",
        "type": "hw-circuit"
      }
    ],
    "tags": [
      "电源管理",
      "ML",
      "在线学习",
      "DC-DC",
      "供电跌落",
      "处理器"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Existing challenges in droop mitigation and key contributions of the proposed regulation framework.",
        "path": "images/10.5/fig_1.png"
      },
      {
        "num": 2,
        "caption": "System-level diagram of the proposed proactive supply regulation scheme with online learning, including the architecture of the Neural Droop Management Unit (NDMU).",
        "path": "images/10.5/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Proposed feedforward control of the DC–DC converter employing dual- switch modulation for rapid droop mitigation.",
        "path": "images/10.5/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Droop prediction variation across digital SoCs and the proposed online transfer learning scheme for adaptive model update.",
        "path": "images/10.5/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Measured performance of the Neural Droop Management Unit (NDMU) and Online Learning Engine (OLE).",
        "path": "images/10.5/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measured regulator efﬁciency and mitigation performance across benchmarks, with comparison to prior works.",
        "path": "images/10.5/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and packaging/bonding conﬁgurations of the fabricated chip.",
        "path": "images/10.5/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "Intel 3",
      "sram_kb": "32KB on-chip memory",
      "target_model": "N/A",
      "source_figure": "fig_7"
    },
    "data_path": "data/10.5/",
    "analytical_tags": [
      "学界"
    ],
    "affiliation_info": {
      "name": "Northwestern University",
      "name_zh": "西北大学",
      "type": "academia",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/northwestern-university.svg"
    },
    "abstract": "A 28nm SoC solution with integrated proactive power management for droop mitigation is demonstrated combining a neural droop management unit, integrated high speed power converter, and an online learning engine to combat the PDN and workload variations. The 28nm test chip integrated with CPU and accelerators achieves 59% worst-case droop reduction, 48× throttling reduction, and >91% regulator peak efﬁciency, reducing performance degradation from prior ﬁxed-model or throttling-only schemes.",
    "metrics_detailed": {
      "technology": "28nm CMOS",
      "die_area": {
        "value": "test chip",
        "unit": "chip",
        "note": "RISC-V CPU + CNN/Transformer accelerators + NDMU/OLE"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.5-1.2",
            "unit": "V",
            "condition": "DC-DC output range"
          },
          {
            "value": "1.8",
            "unit": "V",
            "condition": "IO supply input"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "45-185",
            "unit": "MHz",
            "condition": "chip operating range"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "up to 2.4",
            "unit": "% overhead",
            "condition": "NDMU in high-performance mode"
          },
          {
            "value": "0.64",
            "unit": "% overhead",
            "condition": "NDMU in low-power mode"
          }
        ]
      },
      "regulator_efficiency": {
        "values": [
          {
            "value": "91.7",
            "unit": "% peak",
            "condition": "DC-DC converter at 0.5-1.2V output"
          }
        ]
      },
      "droop_reduction": {
        "values": [
          {
            "value": "79",
            "unit": "mV reduction",
            "condition": "average with online learning over 100K cycles"
          },
          {
            "value": "47-59",
            "unit": "% worst-case magnitude reduction",
            "condition": "across 4 package configurations"
          }
        ]
      },
      "clock_throttling": {
        "values": [
          {
            "value": "48.5×",
            "unit": "reduction in throttling events",
            "condition": "vs prior throttling-only schemes"
          },
          {
            "value": "24% to ~1%",
            "unit": "clock gating cycles reduction",
            "condition": "at lower voltage margins"
          }
        ]
      },
      "performance_loss": {
        "values": [
          {
            "value": "up to 23×",
            "unit": "improvement vs clock-throttling penalty",
            "condition": "reduced from 30% to minimal"
          }
        ]
      },
      "comparison": "Proactive power management with online learning reduces worst-case droop by 59% vs fixed-model schemes"
    },
    "page_images": [
      "images/10.5/page_1.png",
      "images/10.5/page_2.png",
      "images/10.5/page_3.png"
    ]
  },
  {
    "id": "10.6",
    "session": 10,
    "title": "A Hybrid-Bonded 12.1TOPS/mm² 56-Core DNN Processor with 2.5Tb/s/mm² 3D Network on Chip",
    "title_zh": "混合键合12.1TOPS/mm² 56核DNN处理器：2.5Tb/s/mm² 3D片上网络",
    "title_annotation": {
      "segments": [
        {
          "text": "Hybrid-Bonded",
          "meaning": "混合键合3D堆叠",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "12.1TOPS/mm²",
          "meaning": "面积效率12.1TOPS/mm²",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "56-Core",
          "meaning": "56个RISC-V核心",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "3D Network on Chip",
          "meaning": "3D片上网络",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "跨芯片数据搬运成为性能瓶颈",
        "related_idea_idx": 0,
        "text_en": "Cross-die communication can become a critical bottleneck, limiting workload performance"
      },
      {
        "text": "3D堆叠双芯片间时钟偏斜影响时序",
        "related_idea_idx": 1,
        "text_en": "Uncorrelated process variation on the two dies induces clock skew that impacts timing margin"
      },
      {
        "text": "多核DNN负载映射需兼顾延迟与能效",
        "related_idea_idx": 2,
        "text_en": "DNN workload mapping needs to balance latency and energy efficiency across manycore accelerators"
      }
    ],
    "ideas": [
      {
        "text": "14×4×2混合键合3D NoC网络",
        "type": "system",
        "color": "#3498db",
        "text_en": "14×4×2 mesh 3D NoC (M3DNoC) with hybrid-bonded interconnect delivers 2.5Tb/s/mm2 throughput"
      },
      {
        "text": "转发时钟设计配合异步FIFO跨芯片接口",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Forwarded-clock design with credit-based clock-crossing circuit using 8-entry asynchronous FIFO enables full bandwidth across the 3D interface"
      },
      {
        "text": "并行与数据流两种可切换负载映射策略",
        "type": "sw",
        "color": "#2ecc71",
        "text_en": "Conv operations distributed spatially or processed serially by accelerators with concurrent RISC-V and accelerator processing"
      }
    ],
    "affiliation": "Intel",
    "authors": "Intel",
    "process_node": "Intel 3/18A",
    "die_area_mm2": "9",
    "power_mw": "",
    "energy_efficiency": "16.1TOPS/W",
    "target_model": "DNN",
    "application": "DNN加速(3D堆叠)",
    "innovations": [
      {
        "tag": "混合键合3D堆叠DNN处理器",
        "type": "hw-arch"
      },
      {
        "tag": "56核RISC-V+DNN加速器",
        "type": "hw-arch"
      },
      {
        "tag": "3D NoC 2.5Tb/s/mm²",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "3D堆叠",
      "混合键合",
      "RISC-V",
      "NoC",
      "DNN",
      "Intel"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Block diagram of manycore 3D DNN processor and motivation for HBI.",
        "path": "images/10.6/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Mesh 3D network on chip and hybrid-bonded interface. HBI In HBI Out HBI Interface {N,S,E,W,Local,Up/Down} Out Port {N,S,E,W,Local,Up/Down} In Port ready valid data 64 length D C Q N In N Out S In S Out Local In Local Out Up/Down In Up/Down Out E Out E In W Out W In to Core/DNN NoC Router Tile HBI Floorplan (24×23 Pads) 216μm 207μm VCC VSS Data Data Req, Ack, Φ Other Signals Other Signals clk Arbiter FF sel Tail Detect clk clk D C Q D C Q CG ready data valid ready valid data 64 addr D C Q clk FF sel Decode clk clk D C Q D C Q CG ready data valid length Tail Detect HBI Out Interface HBI In Interface ready valid data clk data ack req ΦRX ΦTX ack req data ΦTX 64 data ready valid clk !180° != ΦRX !empty clk wr addr FF FF FF TX Gray Counter rd addr 64 sync.",
        "path": "images/10.6/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Block diagram of DNN accelerator in the top tile.",
        "path": "images/10.6/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Chip measurements and comparison of 2D vs. 3D trafﬁc. 0 0.2 0.4 0.6 0.8 1 1.2 100 200 300 400 500 600 700 800 9001000 Energy per Byte (norm.) Throughput (GB/s) 3D 2D 0 200 400 600 800 1000 1200 1400 0.4 0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 Frequency (MHz) Supply Voltage (V) 7.7 13.7 24.1 27.9 19.3 33.0 Peak TOPS Intel 18A / Intel 3 CMOS, 25°C 2D 3D Intel 18A / Intel 3 CMOS, 25°C 39% 30.7 0 2 4 6 8 10 12 14 16 18 0.4 0.5 0.6 0.7 0.8 0.9 1 1.1 1.2 Dynamic TOPS/W Supply Voltage (V) 10 15 20 25 30 8 16 32 64 128 256 512 1024 Throughput (GB/s) Transfer Size (B) Intel 18A / Intel 3 CMOS, 25°C Intel 18A / Intel 3 CMOS, 25°C 0.9V, 1GHz Random Uniform Core Traffic Nearest-neighbor DMA Traffic im2col .T Input offset Y 16×4×4 k×{h×w} 8b RF Y 16×4×4 k×{h×w} 8b RF Data pointers (X, Y, W) Layer dims.",
        "path": "images/10.6/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Image classiﬁcation measurements for parallel and dataﬂow mappings.",
        "path": "images/10.6/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Comparison tables to hybrid bonded chips and manycore DNN processors. ISSCC22 [12] 7nm 7nm 81 ISSCC22 [13] 25nm 55nm 602.22 ISSCC24 [14] 5nm 6nm 4× ½Reticle Top Process Bottom Process Area, mm2 This Work Intel 18A Intel 3 2.74 Hybrid Bonded Chips HBI 9μm - - HBI 3μm 1.1, 1.2 0.15, 0.3 HBI 9μm - 2.1 Bonding Technology Voltage, V Frequency, GHz HBI 9μm 0.5-1.1 0.280-1.205 - 16 - - 11.04 - 1.4 M* - - 3D Signal Count Peak 3D Bandwidth, Tb/s 3D Signal Density, / mm2 21.5 k 7.0 7.9 k ISSCC24 [14] 5nm, 6nm 4× ½Reticle - Process Area, mm2 Voltage, V This Work Intel 18A, Intel 3 2.74 0.5-1.1 DNN Processors 2.1 256* Frequency, GHz SRAM Capacity, MB 0.280-1.205 5.25 BF16 1307 - Data Precision Peak Perf., TOPS/TFLOPS Comp.",
        "path": "images/10.6/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Top and bottom die photos of 3D stacked DNN processor.",
        "path": "images/10.6/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "Intel 3/18A",
      "sram_kb": "5.25MB SRAM",
      "energy_efficiency": "16.1TOPS/W",
      "throughput": "33.0TOPS",
      "die_area_mm2": "9",
      "target_model": "DNN",
      "source_figure": "fig_7"
    },
    "data_path": "data/10.6/",
    "analytical_tags": [
      "3D堆叠/HBM",
      "业界"
    ],
    "affiliation_info": {
      "name": "Intel",
      "name_zh": "英特尔",
      "type": "industry",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/intel.svg"
    },
    "abstract": "A manycore DNN processor leverages hybrid bonding in a 14×4×2 mesh network on chip to increase 3D bandwidth between cores, accelerators, and SRAM to 2.5Tb/s/mm2. Memory throughput is improved by 39% compared to an equivalent 2D design with the same memory capacity. The 56 16×16 INT8 systolic array accelerators are stacked on top of 56 RISC-V cores to enable a peak AI performance density of 12.1TOPS/mm2. The DNN processor scores a latency of 53ms on the image classiﬁcation benchmark from MLPerf.",
    "metrics_detailed": {
      "technology": "Intel 3 (bottom die) + Intel 18A (top die)",
      "die_area": {
        "value": "9",
        "unit": "mm HBI",
        "note": "hybrid bonding interconnect length"
      },
      "cores": {
        "value": "56 + 56",
        "unit": "tile pairs",
        "note": "56 RISC-V cores (bottom) + 56 DNN accelerators (top)"
      },
      "risc_v_cores": {
        "value": "32-bit RV32",
        "unit": "cores",
        "note": "modified from open-source RTL"
      },
      "dnn_accelerators": {
        "values": [
          {
            "value": "16×16",
            "unit": "INT8 systolic array",
            "condition": "per accelerator tile"
          }
        ]
      },
      "memory": {
        "values": [
          {
            "value": "5.25",
            "unit": "MB SRAM",
            "condition": "distributed across stacked dies"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "1.205",
            "unit": "GHz",
            "condition": "peak performance"
          },
          {
            "value": "280",
            "unit": "MHz",
            "condition": "at peak energy efficiency"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.5-1.1",
            "unit": "V",
            "condition": "operating range"
          }
        ]
      },
      "performance": {
        "values": [
          {
            "value": "33.0",
            "unit": "TOPS",
            "condition": "peak dynamic at 1.1V, 1.205GHz"
          },
          {
            "value": "12.1",
            "unit": "TOPS/mm²",
            "condition": "peak compute density"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "16.1",
            "unit": "TOPS/W",
            "condition": "peak dynamic at 0.5V, 280MHz (excluding leakage)"
          }
        ]
      },
      "noc_throughput": {
        "values": [
          {
            "value": "2.5",
            "unit": "Tb/s/mm²",
            "condition": "3D mesh NoC across HBI"
          }
        ]
      },
      "noc_memory_improvement": {
        "value": "39",
        "unit": "% improvement",
        "condition": "3D NoC vs 2D NoC"
      },
      "inference_latency": {
        "values": [
          {
            "value": "53",
            "unit": "ms",
            "condition": "MLPerf image classification (ResNet-8 CIFAR-10) parallel mapping"
          }
        ]
      },
      "inference_energy": {
        "values": [
          {
            "value": "15.6",
            "unit": "mJ/inference",
            "condition": "at 0.5V, dataflow mapping"
          }
        ]
      },
      "inference_throughput": {
        "values": [
          {
            "value": "27.4",
            "unit": "k inferences/sec",
            "condition": "at 1.1V, dataflow mapping"
          }
        ]
      },
      "comparison": "3D stacking with 9mm HBI enables 39% memory throughput improvement vs equivalent 2D design"
    },
    "page_images": [
      "images/10.6/page_1.png",
      "images/10.6/page_2.png",
      "images/10.6/page_3.png"
    ]
  },
  {
    "id": "10.7",
    "session": 10,
    "title": "A 28nm Mode-Reconfigurable CAM-CIM Hybrid Complete 3-SAT Solver Supporting Conflict-Driven Clause Learning with 100% Solvability",
    "title_zh": "28nm模式可重构CAM-CIM混合完备3-SAT求解器：支持冲突驱动子句学习，100%可解性",
    "title_annotation": {
      "segments": [
        {
          "text": "28nm",
          "meaning": "28nm工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "CAM-CIM Hybrid",
          "meaning": "内容寻址+存内计算混合",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Complete 3-SAT Solver",
          "meaning": "完备3-SAT求解器",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Conflict-Driven Clause Learning",
          "meaning": "冲突驱动子句学习(CDCL)",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "交叉开关映射PE开销达O(n²)效率低",
        "related_idea_idx": 0,
        "text_en": "Crossbar topology mapping incurs O(n²) PE overhead with low efficiency"
      },
      {
        "text": "缺乏冲突学习无法利用公式社区结构",
        "related_idea_idx": 1,
        "text_en": "Lack of conflict-driven clause learning fails to exploit formula community structures"
      },
      {
        "text": "固定宏尺寸难以适配不同规模SAT问题",
        "related_idea_idx": 2,
        "text_en": "Fixed-size macros cannot accommodate varying SAT formula sizes"
      }
    ],
    "ideas": [
      {
        "text": "CAM二进制编码将PE开销降至O(nlogn)",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "CAM binary-encoded format reduces PE overhead from O(n²) to O(nlogn)"
      },
      {
        "text": "CIM宏实时追踪学习子句支持CDCL",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "CIM macro enables real-time tracking of learnt clauses to support CDCL"
      },
      {
        "text": "模式可重构四核架构适配公式规模",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Mode-reconfigurable 4-core architecture accommodates varying F(x) sizes"
      }
    ],
    "affiliation": "Peking University",
    "authors": "Peking University",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "",
    "target_model": "3-SAT",
    "application": "SAT求解/形式验证",
    "innovations": [
      {
        "tag": "CAM-CIM混合SAT架构",
        "type": "hw-arch"
      },
      {
        "tag": "硬件CDCL子句学习",
        "type": "co-design"
      },
      {
        "tag": "100%完备可解性",
        "type": "sw"
      }
    ],
    "tags": [
      "SAT",
      "CAM",
      "CIM",
      "CDCL",
      "形式验证",
      "求解器"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Overview of the K-SAT concept and the challenges of efﬁcient SAT inference in ASIC.",
        "path": "images/10.7/fig_1.png"
      },
      {
        "num": 2,
        "caption": "The overall architecture of the proposed CDCL K-SAT solver and three pivotal features.",
        "path": "images/10.7/fig_2.png"
      },
      {
        "num": 3,
        "caption": "The schematic of CAM-based propagation unit (CAM-PU) and its operation ﬂow.",
        "path": "images/10.7/fig_3.png"
      },
      {
        "num": 4,
        "caption": "CIM-based learning unit (CIM-LU) for conﬂict analysis and learned clause management.",
        "path": "images/10.7/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Mode-reconﬁgurable architecture: the split-mode for thread-level parallelism on small formulas, and the merge-mode for data-level parallelism on large formulas.",
        "path": "images/10.7/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and the comparison with state-of-the-art ASIC K-SAT solvers.",
        "path": "images/10.7/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and performance summary of the proposed solver across different formula sizes.",
        "path": "images/10.7/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "die_area_mm2": "0.65",
      "supply_voltage": "0.95V",
      "target_model": "3-SAT",
      "source_figure": "fig_7"
    },
    "supply_voltage": "0.95V",
    "data_path": "data/10.7/",
    "analytical_tags": [
      "CIM",
      "学界"
    ],
    "affiliation_info": {
      "name": "Peking University",
      "name_zh": "北京大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/peking-university.svg"
    },
    "abstract": "The K-SAT problem is NP-complete and costly on von Neumann machines. Several ASIC solvers have been proposed to mitigate this, but they rely on inefﬁcient crossbar mapping, overlook community structures and lack adaptability to formula size. This work presents an ASIC complete solver with conﬂict-driven clause learning (CDCL), employing a mode- reconﬁgurable CAM–CIM hybrid architecture. Fabricated in 28nm CMOS, it achieves 4.3-to-5.1× speedup and 1.4× energy reduction over a state-of-the-art ASIC complete solver.",
    "metrics_detailed": {
      "technology": "28nm CMOS",
      "die_area": {
        "value": "0.65",
        "unit": "mm²",
        "note": "solver core area"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.65-0.95",
            "unit": "V",
            "condition": "operating range"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "45-185",
            "unit": "MHz",
            "condition": "operating range"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "10.4",
            "unit": "mW",
            "condition": "split mode average @ 185MHz, 0.95V"
          },
          {
            "value": "11.2",
            "unit": "mW",
            "condition": "merge mode average @ 185MHz, 0.95V"
          }
        ]
      },
      "sat_solver_split_mode": {
        "values": [
          {
            "value": "4.0",
            "unit": "ms",
            "condition": "SAT cases average solution time"
          },
          {
            "value": "8.3",
            "unit": "ms",
            "condition": "UNSAT cases average solution time"
          },
          {
            "value": "100",
            "unit": "% solvability",
            "condition": "on 1000 uf/uuf50-218 benchmarks"
          }
        ]
      },
      "sat_solver_merge_mode": {
        "values": [
          {
            "value": "91.8",
            "unit": "ms",
            "condition": "SAT cases average (872 clauses, 200 variables)"
          },
          {
            "value": "846.0",
            "unit": "ms",
            "condition": "UNSAT cases average"
          },
          {
            "value": "100",
            "unit": "% solvability",
            "condition": "on structured formulas (150 SAT, 46 UNSAT)"
          }
        ]
      },
      "speedup_vs_sota": {
        "values": [
          {
            "value": "4.3-5.1×",
            "unit": "speedup",
            "condition": "vs state-of-the-art complete solver"
          }
        ]
      },
      "energy_reduction": {
        "values": [
          {
            "value": "1.4-1.7×",
            "unit": "reduction",
            "condition": "vs SOTA complete solver"
          }
        ]
      },
      "cdcl_speedup": {
        "value": "45×",
        "unit": "speedup",
        "condition": "CDCL vs baseline without CDCL"
      },
      "architecture": "CAM-PU + CIM-LU hybrid with mode-reconfigurable split/merge modes",
      "comparison": "Complete 3-SAT solver with CDCL achieving 4.3-5.1× speedup and 1.4-1.7× energy reduction"
    },
    "page_images": [
      "images/10.7/page_1.png",
      "images/10.7/page_2.png",
      "images/10.7/page_3.png"
    ]
  },
  {
    "id": "10.8",
    "session": 10,
    "title": "COBI: A Degree-of-56 Column-Bipartite Densely Connected Digital Ising Chip with 8b Spin Coefficients",
    "title_zh": "COBI：度数56列二部图密连接数字Ising芯片(8位自旋系数)",
    "title_annotation": {
      "segments": [
        {
          "text": "COBI",
          "meaning": "芯片代号",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Degree-of-56",
          "meaning": "自旋连接度56",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Column-Bipartite",
          "meaning": "列二部图拓扑",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Digital Ising Chip",
          "meaning": "数字Ising计算芯片",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "8b Spin Coefficients",
          "meaning": "8位自旋系数精度",
          "color": "#e67e22",
          "type": "hw-circuit"
        }
      ]
    },
    "challenges": [
      {
        "text": "已有Ising机硬件拓扑度数低映射受限",
        "related_idea_idx": 0,
        "text_en": "Prior CMOS Ising machines suffer from poor problem-mapping capabilities due to fixed and low-degree hardware topologies"
      },
      {
        "text": "低精度系数限制实际优化问题求解",
        "related_idea_idx": 1,
        "text_en": "Limited precision coefficients restrict solving practical optimization problems"
      },
      {
        "text": "复杂拓扑需大量预处理映射开销大",
        "related_idea_idx": 2,
        "text_en": "Complex topologies require computationally intensive pre-processing for problem mapping"
      }
    ],
    "ideas": [
      {
        "text": "列二部图拓扑实现度数56的密集连接",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Column-bipartite topology implements densely connected spins with a degree of 56"
      },
      {
        "text": "嵌入式SRAM存储8位自旋交互系数",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Embedded 8T-SRAM stores 8b spin interaction coefficients"
      },
      {
        "text": "近存储MAC与总线控制器并行列激活",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Near-memory MAC with bus controller enables parallel column activation"
      }
    ],
    "affiliation": "UC Santa Barbara",
    "authors": "UC Santa Barbara",
    "process_node": "65nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "",
    "target_model": "Ising Model",
    "application": "组合优化问题求解",
    "innovations": [
      {
        "tag": "列二部图高连接度Ising拓扑",
        "type": "hw-arch"
      },
      {
        "tag": "8位系数数字Ising芯片",
        "type": "hw-circuit"
      }
    ],
    "tags": [
      "Ising",
      "组合优化",
      "退火",
      "数字芯片",
      "拓扑",
      "求解器"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Introduction to COP problems, prior Ising works, and the fully digital Ising chip (COBI) with reconﬁgurability, dense connectivity, and high precision.",
        "path": "images/10.8/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture of the fabricated 65nm test chip, detailed spin structure, and a single spin layout.",
        "path": "images/10.8/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Sequential activation of spin column: Transmit (Tx) and receive (Rx) operations, coefﬁcient readout, and MAC operation.",
        "path": "images/10.8/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Measurement results of Max-Cut problems with transient Ising Hamiltonians (top-left) and transient spin maps (top-right), and hard Max-Cut problems with transient Ising Hamiltonians (bottom-left) and statistical distributions (bottom- right).",
        "path": "images/10.8/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Mapping (left) and evaluated results (right) of 64-node community detection (top) and 24×24 BPSK MIMO detection (bottom) problems.",
        "path": "images/10.8/fig_5.png"
      },
      {
        "num": 6,
        "caption": "A comparison table with the state-of-the-art CMOS Ising machines.",
        "path": "images/10.8/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and a summary table.",
        "path": "images/10.8/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "65nm",
      "target_model": "Ising Model",
      "source_figure": "fig_7"
    },
    "data_path": "data/10.8/",
    "analytical_tags": [
      "学界"
    ],
    "affiliation_info": {
      "name": "UC Santa Barbara",
      "name_zh": "加州大学圣巴巴拉分校",
      "type": "academia",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/uc-santa-barbara.svg"
    },
    "abstract": "We present a 65nm digital Ising chip with an advanced column-bipartite topology, featuring densely connected spins with a degree of 56 and 8b coefﬁcients for mapping and solving computationally intensive combinatorial optimization problems. A fabricated Ising test chip with 64 spin processing elements with spin coefﬁcients stored in ﬂexible embedded SRAM demonstrates solving practical problems, such as MIMO detection for a wireless network, with a fast solution time (<72ns).",
    "metrics_detailed": {
      "technology": "65nm CMOS",
      "die_area": {
        "value": "test chip",
        "unit": "chip",
        "note": "64 spin processing elements"
      },
      "spin_architecture": {
        "value": "64",
        "unit": "spin PEs",
        "note": "column-bipartite topology"
      },
      "spin_connectivity": {
        "value": "56",
        "unit": "degree",
        "condition": "spins densely connected"
      },
      "spin_coefficient_precision": {
        "value": "8",
        "unit": "bits",
        "note": "J and h coefficients"
      },
      "frequency": {
        "values": [
          {
            "value": "8 clock cycles",
            "unit": "per full spin interaction",
            "condition": "column-sequential activation"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "518",
            "unit": "μW",
            "condition": "at 1.2V, solving hard Max-Cut"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "1.2",
            "unit": "V",
            "condition": "nominal operation"
          }
        ]
      },
      "max_cut_performance": {
        "values": [
          {
            "value": "2 cycles",
            "unit": "to convergence",
            "condition": "easy max-cut problems (ground state)"
          }
        ]
      },
      "max_cut_speedup": {
        "value": "107×",
        "unit": "vs CPU Metropolis",
        "condition": "hard max-cut problems"
      },
      "spin_pe_area": {
        "value": "120.75 × 62.5",
        "unit": "μm²",
        "note": "per spin processing element"
      },
      "mimo_detection": {
        "values": [
          {
            "value": "24×24 BPSK",
            "unit": "MIMO problem",
            "condition": "wireless detection"
          },
          {
            "value": "<72",
            "unit": "ns",
            "condition": "solution time"
          }
        ]
      },
      "community_detection": {
        "values": [
          {
            "value": "64-node",
            "unit": "graph",
            "condition": "bisection and multi-partition detection"
          }
        ]
      },
      "comparison": "Digital Ising chip with degree-56 column-bipartite topology for dense connectivity and high precision",
      "reconfigurability": "Flexible SRAM-based coefficient storage for various optimization problems"
    },
    "page_images": [
      "images/10.8/page_1.png",
      "images/10.8/page_2.png",
      "images/10.8/page_3.png"
    ]
  },
  {
    "id": "10.9",
    "session": 10,
    "title": "SharpSAT: A Heuristic-Learning-Based SAT Accelerator Achieving 0.8μs/16.1μs Solution Time in SAT/UNSAT",
    "title_zh": "SharpSAT：基于启发式学习的SAT加速器(SAT/UNSAT求解时间0.8μs/16.1μs)",
    "title_annotation": {
      "segments": [
        {
          "text": "SharpSAT",
          "meaning": "加速器代号",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Heuristic-Learning-Based",
          "meaning": "基于启发式学习",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "SAT Accelerator",
          "meaning": "SAT问题加速器",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "0.8μs/16.1μs",
          "meaning": "SAT/UNSAT求解时间",
          "color": "#3498db",
          "type": "system"
        }
      ]
    },
    "challenges": [
      {
        "text": "完备求解器搜索空间大收敛速度慢",
        "related_idea_idx": 0,
        "text_en": "Complete solvers require exploring a large search space, often necessitating the traversal of numerous candidate assignments"
      },
      {
        "text": "布尔约束传播BCP速度成为性能瓶颈",
        "related_idea_idx": 1,
        "text_en": "Boolean constraint propagation (BCP) becomes a performance bottleneck"
      },
      {
        "text": "确定性探索策略缺乏搜索多样性",
        "related_idea_idx": 2,
        "text_en": "Deterministic exploration strategy lacks search diversification"
      }
    ],
    "ideas": [
      {
        "text": "前向VarCause构建实现快速子句学习",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Forward VarCause construction implements fast clause learning"
      },
      {
        "text": "双BCP仲裁器并行发射两条传播结果",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Dual-BCP arbiter issues two BCP implications in parallel"
      },
      {
        "text": "PRNG启发式决策器引入随机性搜索",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "PRNG-based heuristic decider introduces randomness in the solution space search"
      }
    ],
    "affiliation": "Tsinghua University",
    "authors": "Tsinghua University",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "",
    "target_model": "SAT/UNSAT",
    "application": "SAT求解/形式验证",
    "innovations": [
      {
        "tag": "启发式学习SAT加速",
        "type": "co-design"
      },
      {
        "tag": "快速子句学习硬件",
        "type": "hw-arch"
      },
      {
        "tag": "双模式搜索引擎",
        "type": "sw"
      }
    ],
    "tags": [
      "SAT",
      "启发式",
      "子句学习",
      "完备求解",
      "形式验证",
      "加速器"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Introduction to the SAT problem and design highlights of proposed clause learning SAT design (SharpSAT).",
        "path": "images/10.9/fig_1.png"
      },
      {
        "num": 2,
        "caption": "The top-level architecture and workﬂow of SharpSAT. 185 10 Acknowledgement: This work is supported by the National Key R&D Program of China (No.",
        "path": "images/10.9/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Proposed clause learner and its workﬂow.",
        "path": "images/10.9/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Design of the proposed dual-BCP unit and PRNG-based heuristic decider.",
        "path": "images/10.9/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Measured solution time, the trend of the number of learning clauses, energy efﬁciency, frequency voltage plot, and comparison with prior ASICs and an HPC CPU.",
        "path": "images/10.9/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Comparison with state-of-the-art ASIC SAT solvers.",
        "path": "images/10.9/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph, summary table, and area/power breakdown.",
        "path": "images/10.9/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "die_area_mm2": "0.78",
      "frequency_mhz": "375",
      "target_model": "SAT/UNSAT",
      "source_figure": "fig_7"
    },
    "frequency_mhz": "375",
    "data_path": "data/10.9/",
    "analytical_tags": [
      "学界"
    ],
    "affiliation_info": {
      "name": "Tsinghua University",
      "name_zh": "清华大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/tsinghua-university.svg"
    },
    "abstract": "We present SharpSAT, a heuristic-learning SAT accelerator that achieves fast solution times of 0.8μs for SAT and 16.1μs for UNSAT cases. Our design integrates: a fast clause learning unit that prunes the search space by deriving constraints from conﬂicts; a dual-BCP unit that accelerates implication propagation; and a heuristic variable decider introducing non- determinism to efﬁciently traverse the solution space. A 28nm prototype demonstrates 21.11×/2.61× (SAT/UNSAT) speedup over prior accelerators.",
    "metrics_detailed": {
      "technology": "28nm CMOS",
      "die_area": {
        "value": "0.78",
        "unit": "mm²",
        "note": "core area for 64 variables, 384 clauses"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.9",
            "unit": "V",
            "condition": "nominal operation"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "375",
            "unit": "MHz",
            "condition": "operating frequency"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "99.1",
            "unit": "mW",
            "condition": "at 375MHz, 0.9V"
          }
        ]
      },
      "sat_solver": {
        "sat_cases": {
          "solution_time": "0.8",
          "unit": "μs",
          "condition": "50 variables, 218 clauses"
        },
        "unsat_cases": {
          "solution_time": "16.1",
          "unit": "μs",
          "condition": "50 variables, 218 clauses"
        }
      },
      "solvability": {
        "value": "100",
        "unit": "%",
        "condition": "on 1000 SAT and 1000 UNSAT 3-SAT cases from SATLIB"
      },
      "speedup_vs_software": {
        "values": [
          {
            "value": "70.67×",
            "unit": "speedup",
            "condition": "SAT cases vs MINISAT"
          },
          {
            "value": "6.17×",
            "unit": "speedup",
            "condition": "UNSAT cases vs MINISAT"
          }
        ]
      },
      "speedup_vs_prior_accelerator": {
        "values": [
          {
            "value": "21.11×",
            "unit": "speedup",
            "condition": "SAT cases vs prior complete solver"
          },
          {
            "value": "2.61×",
            "unit": "speedup",
            "condition": "UNSAT cases vs prior complete solver"
          }
        ]
      },
      "energy_comparison": {
        "value": "1.38×",
        "unit": "higher energy",
        "condition": "SharpSAT vs DPLL baseline (faster convergence compensates)"
      },
      "learned_clauses": {
        "values": [
          {
            "value": "<20",
            "unit": "clauses",
            "condition": "SAT cases before solution"
          },
          {
            "value": "full 384 clause budget",
            "unit": "clauses",
            "condition": "UNSAT cases before reporting UNSAT"
          }
        ]
      },
      "comparison": "Heuristic-learning SAT accelerator achieving 21.11×/2.61× speedup on SAT/UNSAT cases",
      "key_techniques": [
        "Fast clause learning unit",
        "Dual-BCP acceleration",
        "Heuristic PRNG-based variable decider"
      ]
    },
    "page_images": [
      "images/10.9/page_1.png",
      "images/10.9/page_2.png",
      "images/10.9/page_3.png"
    ]
  },
  {
    "id": "10.10",
    "session": 10,
    "title": "PCIM-SAT: A 55nm Probabilistic K-SAT Solver with p-Bit-Based Parallel-Variable Update on a Mixed-Signal CIM Architecture",
    "title_zh": "PCIM-SAT：55nm概率K-SAT求解器(基于p-bit并行变量更新的混合信号CIM架构)",
    "title_annotation": {
      "segments": [
        {
          "text": "55nm",
          "meaning": "55nm工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Probabilistic",
          "meaning": "概率计算",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "K-SAT Solver",
          "meaning": "K-SAT求解器(K≥3)",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "p-Bit",
          "meaning": "概率比特(可控随机翻转)",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "Mixed-Signal CIM",
          "meaning": "混合信号存内计算",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "已有求解器仅支持3-SAT高阶需变量膨胀",
        "related_idea_idx": 0,
        "text_en": "Existing solvers are limited to 3-SAT and require variable inflation for higher-order problems"
      },
      {
        "text": "单变量更新导航效率低收敛缓慢",
        "related_idea_idx": 1,
        "text_en": "Single variable updates result in low navigational efficiency and slow convergence"
      },
      {
        "text": "模拟梯度计算需ADC增加面积和延迟",
        "related_idea_idx": 2,
        "text_en": "Analog gradient computation requires ADCs which increase area and delay"
      }
    ],
    "ideas": [
      {
        "text": "阶次无关混合信号CIM直接映射K-SAT",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Order-invariant mixed-signal IMC architecture directly maps K-SAT problems"
      },
      {
        "text": "p-bit概率采样实现多变量并行更新",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "P-bit probabilistic sampling enables multiple variables parallel update"
      },
      {
        "text": "11T SRAM单周期计算make/break梯度",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "11T SRAM computes make and break-values (gradients) in a single cycle"
      }
    ],
    "affiliation": "UC Santa Barbara",
    "authors": "UC Santa Barbara",
    "process_node": "55nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "",
    "target_model": "K-SAT (K≥3)",
    "application": "SAT求解(概率计算)",
    "innovations": [
      {
        "tag": "概率p-bit并行K-SAT求解",
        "type": "co-design"
      },
      {
        "tag": "混合信号CIM架构",
        "type": "hw-arch"
      },
      {
        "tag": "原生高阶K-SAT支持",
        "type": "sw"
      }
    ],
    "tags": [
      "SAT",
      "概率计算",
      "p-bit",
      "CIM",
      "混合信号",
      "求解器"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Basic concepts of K-SAT; introduction to the new multi-variable update SAT algorithm; challenges with prior SAT solver ASICs and design highlights of our solver architecture.",
        "path": "images/10.10/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Top-level architecture and workﬂow of proposed solver. ❑ \u0001 = \u00021\u0002 ڀ3 \u0002 ڀ5ٿ\u00021 \u0002 ڀ2 ٿ\u00021ڀ\u00024 \u0002 ڀ5 ⇒(\u00021, \u00022, \u00023, \u00024, \u00025) = 1, 1,0, 0,1 \u0001 ❑ \u0004 = −\u00021\u00023\u00025 + \u00021\u00024\u00025 + \u00021\u00023 + \u00023\u00025 + \u00021\u00025 −\u00021\u00022 −\u00021\u00024 −\u00024\u00025 −\u00023 + \u00024 −\u00025 + 1, \u0002\u0006 ∈0,1 ❑∆\u0004\u0006 = \u0004 \u0002\u0006 →1 −\u0002\u0006 −\u0004 \u0002\u0006 ⇒−∆\u0004\u0006 = ∆ \u0006 = \u0006 − \u0006 ❑∆\u0004\u0006 \u0002\u0006 \u0006 \u0002\u0006 \u0002\u0006 \u0006 \u0002\u0006 \u0002\u0006 ∆\u00041 ∆\u00042 ∆\u0004 \u000e −∆\u00041 \u000f \u000e −∆\u00042 \u000f \u000e −∆\u0004 \u000f \u0006 = 0 \u0006 = \u0010\u0006\u0011 ⟶ \u000e −∆\u0004\u0006/\u000f \u0013 \u0006 \u0014 \u0006 \u0014 \u0006 \u000e −∆\u0004\u0006/\u000f 187 10 In summary, PCIM-SAT can natively map arbitrary-order K-SAT problems and accelerate efﬁcient multi/parallel-variable update heuristics.",
        "path": "images/10.10/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Detailed schematic of the mixed-signal in-memory computing fabric and probabilistic bit.",
        "path": "images/10.10/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Measurement results of the probabilistic-bits; schematic of variable update logic and timing diagram of solver. ∈{0,1,2,3,..} ∈{0,1,2,3,..} \u0002 \u0003 Τ \u0005\u0006 −\b\u0006 \u0002 \u0003 Τ \u0005\u0006 −\b\u0006 ∆G=",
        "path": "images/10.10/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Measurement results of PCIM-SAT on different SAT benchmarks and comparison with other solvers. Multi-thread mode implemented for comparison.",
        "path": "images/10.10/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Feature and performance comparison with prior SAT solver ASICs.",
        "path": "images/10.10/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and performance summary.",
        "path": "images/10.10/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "55nm",
      "target_model": "K-SAT (K≥3)",
      "source_figure": "fig_7"
    },
    "data_path": "data/10.10/",
    "analytical_tags": [
      "CIM",
      "学界"
    ],
    "affiliation_info": {
      "name": "UC Santa Barbara",
      "name_zh": "加州大学圣巴巴拉分校",
      "type": "academia",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/uc-santa-barbara.svg"
    },
    "abstract": "University of California, Santa Barbara, CA We present a 55nm mixed-signal K-SAT solver with parallel-variable update algorithm for improved convergence and a compute-in-memory fabric that maps arbitrary-order K-SAT instances without preprocessing. It solves 50-variable 3-SAT (satisﬁable) problems in 5.5ms with 100% solvability at 265nJ. A custom 11T-SRAM crossbar for one-shot analog gradient computation and ADC-less gradient-based sampling with probabilistic-bit circuits enable 4- to-13× speedup over prior ASICs.",
    "metrics_detailed": {
      "technology": "55nm CMOS",
      "memory": {
        "value": "256×128",
        "unit": "11T-SRAM array",
        "note": "bidirectional compute-in-memory fabric"
      },
      "supply_voltage": {
        "values": []
      },
      "frequency": {
        "values": []
      },
      "k_sat_solver": {
        "problem_size": "50 variables, 3-SAT",
        "solution_time": "5.5",
        "unit": "ms",
        "condition": "satisfiable instances, 100% solvability"
      },
      "energy_consumption": {
        "values": [
          {
            "value": "265",
            "unit": "nJ",
            "condition": "per 50-variable 3-SAT solution"
          }
        ]
      },
      "speedup_vs_sota": {
        "values": [
          {
            "value": "4-13×",
            "unit": "speedup",
            "condition": "vs prior ASIC solvers on uniform 3-SAT"
          },
          {
            "value": "8-13×",
            "unit": "speedup",
            "condition": "vs discrete-time incomplete solvers"
          },
          {
            "value": "4-5.6×",
            "unit": "speedup",
            "condition": "vs continuous-time solver in 28nm"
          },
          {
            "value": "3×",
            "unit": "speedup",
            "condition": "vs DPLL-based complete solver in 28nm"
          },
          {
            "value": "84×",
            "unit": "speedup (projected)",
            "condition": "on larger problems (modeled)"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "2-5×",
            "unit": "more efficient",
            "condition": "vs discrete-time solvers on uniform 3-SAT"
          },
          {
            "value": "2-14×",
            "unit": "speedup",
            "condition": "on higher-order K-SAT problems"
          }
        ]
      },
      "multi_thread": {
        "improvement": "1.7×",
        "unit": "convergence improvement",
        "condition": "3-thread pipeline vs single-thread"
      },
      "sram_crossbar": {
        "value": "11T-SRAM",
        "note": "custom design for one-shot make/break-value computation"
      },
      "p_bit": {
        "value": "ADC-less gradient-based sampling",
        "note": "probabilistic-bit circuits enable parallel variable updates"
      },
      "comparison": "Mixed-signal K-SAT solver with parallel-variable update achieves 4-13× speedup over prior ASICs",
      "key_features": [
        "Order-invariant architecture for arbitrary K-SAT",
        "Parallel variable updates in each cycle",
        "Multi-thread pipeline (3 independent solvers)",
        "ADC-less probabilistic-bit sampling"
      ]
    },
    "page_images": [
      "images/10.10/page_1.png",
      "images/10.10/page_2.png",
      "images/10.10/page_3.png"
    ]
  },
  {
    "id": "18.1",
    "session": 18,
    "title": "A 3.19pJ/b Electro-Optical Router with 18ns Setup Frame-Level Routing and 1-to-6 Wavelength-Flexible Link",
    "title_zh": "3.19pJ/b电光路由器：18ns建立帧级路由与1~6波长灵活链路",
    "title_annotation": {
      "segments": [
        {
          "text": "3.19pJ/b",
          "meaning": "能效3.19pJ/bit",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Electro-Optical Router",
          "meaning": "电光路由器",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "18ns Setup",
          "meaning": "18ns路由建立时间",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "Wavelength-Flexible Link",
          "meaning": "波长灵活光链路",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "Interposer全局互连受限于近邻通信",
        "related_idea_idx": 0,
        "text_en": "Global interconnects on interposers are limited to short-reach parallel interfaces between neighboring dies with no routing capability for distant chiplets"
      },
      {
        "text": "有源中介层远距通信时钟同步延迟高",
        "related_idea_idx": 1,
        "text_en": "Active CMOS interposers for distant die communication face global clocking constraints or multiple resynchronization stages leading to high latency"
      },
      {
        "text": "长距离SerDes驱动器复杂且功耗大",
        "related_idea_idx": 2,
        "text_en": "Longer distance wireline techniques require expensive SerDes and drivers with high power consumption"
      }
    ],
    "ideas": [
      {
        "text": "光子中介层微环动态路由实现灵活互连",
        "type": "system",
        "color": "#3498db",
        "text_en": "Photonic interposer using microring dynamic routing achieves flexible interconnection with electro-optical chiplet control"
      },
      {
        "text": "18ns帧级光路由与波长复用低延迟链路",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "18ns frame-level optical routing with wavelength-division multiplexing enables low-latency links"
      },
      {
        "text": "标准单元SerDes与紧凑光驱动器降低开销",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Standard-cell-based SerDes with compact analog optical drivers reduces overhead compared to complex modulators"
      }
    ],
    "affiliation": "CEA-List",
    "authors": "CEA-List",
    "process_node": "28nm FDSOI",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "3.19pJ/b",
    "target_model": "N/A",
    "application": "芯粒光互连",
    "innovations": [
      {
        "tag": "电光动态路由器",
        "type": "hw-arch"
      },
      {
        "tag": "波长灵活光链路",
        "type": "hw-circuit"
      },
      {
        "tag": "光子interposer集成",
        "type": "system"
      }
    ],
    "tags": [
      "光互连",
      "芯粒",
      "路由器",
      "光子",
      "interposer",
      "波长"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Scaling perspectives for 3D-stacking technologies and proposed routed optical links on interposer.",
        "path": "images/18.1/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Rx front-end with routing using resonance shift and dynamic threshold adjustment during preamble.",
        "path": "images/18.1/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Frame decoding with data alignment on end of preamble, and dynamic remapping on 1 to 6 wavelengths.",
        "path": "images/18.1/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Performance measurements up to 4Gbaud showing BER for optical data, optical clock and digital SerDes.",
        "path": "images/18.1/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Tx/Rx cell layout, area and power breakdown, and long-packet routing performance.",
        "path": "images/18.1/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Comparison table. Metric this work ISSCC25 [1] ISSCC24 [2] JSSC21 [3] HotChips25 OFC25[5,6] ISSCC23 [7] VLSI24 [8] ISSCC18 [9] Type Photonic Interposer Active Interposer Active Interposer Active Interposer Photonic Interposer Photonic links Photonic links Photonic link Tech node 28nm 28nm 6nm 65nm 45nm 7nm 45nm 65nm Integration 3D μbump 3D μbump hybrid bnd.",
        "path": "images/18.1/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die photographs with E/O route, looped-back interposer and 8-port ONoC interposer.",
        "path": "images/18.1/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm FDSOI",
      "energy_efficiency": "3.19pJ/b",
      "throughput": "50Gb/s",
      "target_model": "N/A",
      "source_figure": "fig_7"
    },
    "data_path": "data/18.1/",
    "analytical_tags": [
      "芯粒/Chiplet",
      "学界"
    ],
    "affiliation_info": {
      "name": "CEA-List",
      "name_zh": "法国原子能委员会",
      "type": "research_inst",
      "country": "法国",
      "country_code": "FR",
      "logo": "assets/logos/cea-list.svg"
    },
    "abstract": "Global interconnect on interposers between chiplets is currently mostly limited to nearest- neighbor communication. We propose an electro-optical router in 28nm on a photonic interposer to handle queuing and routing between dies and optical link drivers capable of 18ns link setup time for frame-level routing, with 1-to-6 lambda ﬂexible wavelength capacity. Compact analog drivers and standard-cell-based SerDes and clocking achieve 0.007mm2 active area per link and 3.19pJ/b power.",
    "metrics_detailed": {
      "paper_id": "18.1",
      "title": "A 3.19pJ/b Electro-Optical Router with 18ns Setup Frame-Level Routing and 1-to-6 Wavelength-Flexible Link Capacity for Photonic Interposers",
      "technology": "28nm FDSOI",
      "die_area": {
        "value": "4",
        "unit": "mm²",
        "note": "electro-optical chiplet total area"
      },
      "active_area": {
        "value": "0.007",
        "unit": "mm²",
        "note": "per link active area"
      },
      "tx_rx_area": {
        "value": "7427",
        "unit": "μm²",
        "note": "Tx+Rx total active area"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "1.0",
            "unit": "V",
            "condition": "main digital supply"
          },
          {
            "value": "1.0",
            "unit": "V",
            "condition": "quiet Rx supply"
          },
          {
            "value": "2.0",
            "unit": "V",
            "condition": "Tx supply"
          },
          {
            "value": "1.0-1.5",
            "unit": "V",
            "condition": "thermal tuning supply"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "4",
            "unit": "Gbaud",
            "condition": "data rate tested"
          },
          {
            "value": "4.5",
            "unit": "Gbaud",
            "condition": "clock receiver BER limit"
          },
          {
            "value": "7",
            "unit": "Gbaud",
            "condition": "back-to-back electrical SerDes limit"
          }
        ]
      },
      "bit_error_rate": {
        "values": [
          {
            "value": "1e-6",
            "unit": "BER",
            "condition": "up to 4 Gbaud"
          },
          {
            "value": "1e-24",
            "unit": "undetected error rate",
            "condition": "checksum decoding"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "2.09",
            "unit": "pJ/b",
            "condition": "bare TxRx link"
          },
          {
            "value": "0.36",
            "unit": "pJ/b",
            "condition": "SerDes and clock phase generation"
          },
          {
            "value": "0.75",
            "unit": "pJ/b",
            "condition": "digital logic including routing and queuing"
          },
          {
            "value": "3.19",
            "unit": "pJ/b",
            "condition": "overall end-to-end routed transmission"
          }
        ]
      },
      "interposer": {
        "value": "207",
        "unit": "mm²",
        "note": "fully populated 8-port ONoC interposer area"
      },
      "optical_specifications": {
        "wavelengths": {
          "value": "1-6",
          "note": "wavelength-flexible link capacity via microring resonators"
        },
        "reach": {
          "value": "2.5",
          "unit": "cm",
          "note": "reach on interposer"
        },
        "microring_count": {
          "value": "42",
          "note": "6 microring resonators per Rx bank × 7 Rx banks"
        }
      },
      "routing_performance": {
        "setup_time": {
          "value": "18",
          "unit": "ns",
          "note": "frame-level routing setup time"
        },
        "preamble_length": {
          "value": "18",
          "unit": "ns",
          "note": "minimum preamble to tune rings and average power"
        },
        "frame_duration_limit": {
          "value": "50",
          "unit": "ns",
          "note": "target frame duration"
        }
      },
      "memory": {
        "queue_memory": {
          "value": "1024",
          "unit": "words",
          "note": "frame queue in Rx"
        }
      },
      "transimpedance_amplifier": {
        "resistance": {
          "value": "1.8",
          "unit": "kΩ",
          "note": "TIA transimpedance"
        },
        "lowpass_filter": {
          "value": "1",
          "unit": "MΩ",
          "note": "LPF resistance"
        },
        "lowpass_capacitor": {
          "value": "100",
          "unit": "fF",
          "note": "LPF capacitance"
        },
        "averaging_capacitor": {
          "value": "100",
          "unit": "fF",
          "note": "dynamic threshold averaging capacitor"
        }
      },
      "comparison": "Combines flexibility of dynamic routing from active CMOS interposers with improved reach and low latency of optical links. Achieves 2.5cm reach while preserving power efficiency close to state-of-the-art.",
      "notes": "Standard-cell-based SerDes design avoids expensive custom components. Uses microring modulators and filters for wavelength-division multiplexing and dynamic routing."
    },
    "page_images": [
      "images/18.1/page_1.png",
      "images/18.1/page_2.png",
      "images/18.1/page_3.png"
    ]
  },
  {
    "id": "18.2",
    "session": 18,
    "title": "A 22nm 1.87ms/Frame Streaming Multi-Speaker ASR Accelerator Leveraging Contextual-Aware Redundancy Skipping with 2D-Writable Microscaling CIM and Similarity-Aware TCAM",
    "title_zh": "22nm 1.87ms/帧流式多说话人ASR加速器：上下文感知冗余跳过+2D可写微缩放CIM+相似性TCAM",
    "title_annotation": {
      "segments": [
        {
          "text": "22nm",
          "meaning": "22nm工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Multi-Speaker ASR",
          "meaning": "多说话人语音识别",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Contextual-Aware Redundancy Skipping",
          "meaning": "上下文感知冗余跳过",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Microscaling CIM",
          "meaning": "微缩放存内计算",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "TCAM",
          "meaning": "三态内容寻址存储器",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "多人对话中静默和相似块造成计算冗余",
        "related_idea_idx": 0,
        "text_en": "Silent pauses and similar blocks create block-level computation redundancy in multi-speaker dialogue"
      },
      {
        "text": "两遍解码对计算和存储需求差异大",
        "related_idea_idx": 1,
        "text_en": "Two decoding passes introduce distinct requirements for computation and memory"
      },
      {
        "text": "说话人切换和N-best重评分后处理开销大",
        "related_idea_idx": 2,
        "text_en": "Significant post-processing redundancy arises from frequent speaker alternation and repetitive evaluations on N-best rescoring list"
      }
    ],
    "ideas": [
      {
        "text": "上下文感知冗余跳过实现在线稀疏块预测",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Context-aware redundancy skipping (CARS) scheme with online sparse block prediction"
      },
      {
        "text": "2D可写CIM静态页存权重动态页支持转置",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "2D-writable CIM with memory-intensive static pages and computation-intensive dynamic pages"
      },
      {
        "text": "相似度感知TCAM加速说话人搜索与重评分",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Similarity-aware ternary content-addressable memory (TCAM) for rapid search of similar speaker embeddings and N-best semantic results"
      }
    ],
    "affiliation": "Peking University",
    "authors": "Peking University",
    "process_node": "22nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "1.87ms/frame",
    "target_model": "MS-ASR (RNN-T + AED)",
    "application": "流式多说话人语音识别",
    "innovations": [
      {
        "tag": "上下文感知冗余跳过",
        "type": "sw"
      },
      {
        "tag": "2D可写微缩放CIM",
        "type": "hw-arch"
      },
      {
        "tag": "相似性感知TCAM",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "ASR",
      "语音识别",
      "CIM",
      "TCAM",
      "多说话人",
      "流式"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Overview of two-pass ASR model for multi-speaker and the deployment challenges.",
        "path": "images/18.2/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture of the proposed ASR accelerator and three main features. 311 18",
        "path": "images/18.2/fig_2.png"
      },
      {
        "num": 3,
        "caption": "The two-skip-one-trigger scheme and detailed implementation of CARS.",
        "path": "images/18.2/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Static and dynamic page-based 2D writable (STDY-2D) CIM macro supporting microscaling format.",
        "path": "images/18.2/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Speaker-aware approximation search and reuse-aware rescoring with proposed SA-TCAM.",
        "path": "images/18.2/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and performance comparison table.",
        "path": "images/18.2/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and speciﬁcations.",
        "path": "images/18.2/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "22nm",
      "energy_efficiency": "1.87ms/frame",
      "target_model": "MS-ASR (RNN-T + AED)",
      "source_figure": "fig_7"
    },
    "data_path": "data/18.2/",
    "analytical_tags": [
      "CIM",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "Peking University",
      "name_zh": "北京大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/peking-university.svg"
    },
    "abstract": "This paper presents a DCIM-based accelerator for on-device streaming multi-speaker ASR (MS-ASR), featuring: 1) a context-aware redundancy skipping scheme with online sparse block prediction, 2) a 2D-writable CIM with static pages and dynamic pages, 3) a similarity- aware TCAM for rapid search of similar speakers and N-best semantic results. The test chip achieves a system energy efﬁciency of 37.50TFLOPS/W in MXFP8 and shows superior performance on MS-ASR tasks with 1.87-7.51ms/frame and 0.158-1.26mJ/frame efﬁciency.",
    "metrics_detailed": {
      "paper_id": "18.2",
      "title": "A 22nm 1.87ms/Frame Streaming Multi-Speaker ASR Accelerator Leveraging Contextual-Aware Redundancy Skipping with 2D-Writable Microscaling Compute-in-Memory and Similarity-Aware TCAM Design",
      "technology": "22nm CMOS",
      "frequency": {
        "values": [
          {
            "value": "46.4",
            "unit": "MHz",
            "condition": "minimum"
          },
          {
            "value": "582",
            "unit": "MHz",
            "condition": "maximum"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.55",
            "unit": "V",
            "condition": "minimum"
          },
          {
            "value": "1.0",
            "unit": "V",
            "condition": "maximum"
          }
        ]
      },
      "latency": {
        "values": [
          {
            "value": "1.87",
            "unit": "ms/frame",
            "condition": "at 1.0V"
          },
          {
            "value": "7.51",
            "unit": "ms/frame",
            "condition": "at 0.55V"
          }
        ]
      },
      "energy": {
        "values": [
          {
            "value": "0.158",
            "unit": "mJ/frame",
            "condition": "at 1.0V"
          },
          {
            "value": "1.26",
            "unit": "mJ/frame",
            "condition": "at 0.55V"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "37.50",
            "unit": "TFLOPS/W",
            "condition": "system efficiency in MXFP8 format"
          }
        ]
      },
      "performance_improvements": {
        "speedup_clean_speech": {
          "value": "12.9",
          "unit": "x",
          "note": "vs baseline on clean single speaker audio"
        },
        "energy_savings_clean_speech": {
          "value": "13.6",
          "unit": "x",
          "note": "vs baseline on clean single speaker audio"
        },
        "speedup_multisp_speech": {
          "value": "12.2",
          "unit": "x",
          "note": "vs baseline on 3-speaker mixed audio"
        },
        "energy_savings_multisp_speech": {
          "value": "18.21",
          "unit": "x",
          "note": "vs baseline on 3-speaker mixed audio"
        },
        "speedup_vs_prior_asr": {
          "value": "2.39-3.20",
          "unit": "x",
          "note": "compared to prior ASR accelerator [11]"
        },
        "energy_reduction_vs_prior": {
          "value": "1.91-3.84",
          "unit": "x",
          "note": "compared to prior ASR accelerator [11]"
        }
      },
      "comparison_sota": "1.2x better system efficiency than prior work [19]",
      "memory": {
        "rnn_t_model_size": {
          "value": "0.234",
          "unit": "MB",
          "note": "RNN-T pass model size in CIM"
        },
        "joiner_size": {
          "value": "0.23",
          "unit": "MB",
          "note": "lightweight joiner in RNN-T"
        },
        "memory_reduction_static_pages": {
          "value": "65",
          "unit": "%",
          "note": "memory access reduction with 17 static pages for joiner weights"
        },
        "energy_reduction_static_pages": {
          "value": "32",
          "unit": "%",
          "note": "energy consumption reduction with static pages"
        }
      },
      "cim_architecture": {
        "clusters": {
          "value": "3",
          "note": "computing clusters"
        },
        "cim_macros_per_cluster": {
          "value": "5",
          "note": "digital CIM macros per cluster"
        },
        "tcam_banks": {
          "value": "32",
          "note": "SA-TCAM banks"
        },
        "static_pages_per_macro": {
          "value": "17",
          "note": "528×256 each for stationary weights"
        },
        "dynamic_pages_per_macro": {
          "value": "2",
          "note": "64×256 each for 2D update and sparse computation"
        }
      },
      "redundancy_skipping": {
        "mac_reduction": {
          "value": "57-62",
          "unit": "%",
          "note": "MACs reduced by CARS with negligible WER impact"
        },
        "similarity_detection": {
          "value": "92",
          "unit": "%",
          "note": "token-level similarity at deeper transformer layers"
        },
        "memory_transpose_reduction": {
          "value": "72",
          "unit": "%",
          "note": "2D-writable MX-DCIM memory access reduction"
        },
        "energy_savings_two_pass": {
          "value": "43",
          "unit": "%",
          "note": "2D-writable MX-DCIM energy savings for two-pass decoding"
        }
      },
      "tcam_performance": {
        "power_reduction": {
          "value": "53",
          "unit": "%",
          "note": "search power reduction with ASF dynamic deactivation"
        },
        "latency_reduction": {
          "value": "29",
          "unit": "%",
          "note": "latency reduction with ASF dynamic deactivation"
        },
        "rescoring_hit_rate_single": {
          "value": "82",
          "unit": "%",
          "note": "N-best rescoring hit rate on single speaker speech"
        },
        "rescoring_hit_rate_multi": {
          "value": "71",
          "unit": "%",
          "note": "N-best rescoring hit rate on multi-speaker dialogue"
        },
        "latency_reduction_rescoring": {
          "value": "32",
          "unit": "%",
          "note": "overall latency reduction with reuse-aware rescoring"
        }
      },
      "quantization": "MXFP8 format with microscaling (MX)",
      "accuracy": {
        "wer_increase": {
          "value": "<0.1",
          "unit": "%",
          "note": "negligible WER increase from optimizations"
        }
      },
      "notes": "Features context-aware redundancy skipping (CARS), 2D-writable MX-DCIM, and similarity-aware TCAM (SA-TCAM). Reuses inference states for on-chip learning with OCL."
    },
    "page_images": [
      "images/18.2/page_1.png",
      "images/18.2/page_2.png",
      "images/18.2/page_3.png"
    ]
  },
  {
    "id": "18.3",
    "session": 18,
    "title": "SMoLPU: 122.1μJ/Token Sparse MoE-Based Speculative Decoding Language Processing Unit with Computation Reconfiguration",
    "title_zh": "SMoLPU：122.1μJ/Token稀疏MoE投机解码语言处理单元(计算重配置)",
    "title_annotation": {
      "segments": [
        {
          "text": "SMoLPU",
          "meaning": "稀疏MoE语言处理单元",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "122.1μJ/Token",
          "meaning": "每token能耗122.1微焦",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Sparse MoE",
          "meaning": "稀疏混合专家模型",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Speculative Decoding",
          "meaning": "投机解码",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Computation Reconfiguration",
          "meaning": "计算重配置",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "MoE投机解码中被拒绝token冗余取权重",
        "related_idea_idx": 0,
        "text_en": "Redundant weight fetching for rejected tokens in MoE-based speculative decoding"
      },
      {
        "text": "动态INT-FP比例变化导致硬件利用率低",
        "related_idea_idx": 1,
        "text_en": "Dynamically changing INT-FP MAC ratios causing low hardware utilization"
      },
      {
        "text": "可重构加法树支持可变输入尺寸功耗大",
        "related_idea_idx": 2,
        "text_en": "Reconfigurable adder tree supporting variable input size increases power by 3.1×"
      }
    ],
    "ideas": [
      {
        "text": "Token自适应专家精炼消除冗余权重访问",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Token-adaptive Expert Refinement (TaER) eliminates redundant expert fetching and reduces EMA"
      },
      {
        "text": "自适应卸载NPU-CIM核平衡INT-FP利用率",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Adaptive-offload NPU-CIM core (ANC) sustains high utilization under time varying integer to floating-point ratios"
      },
      {
        "text": "双极编码DRAM-LUT-CIM降低加法树开销",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Reconfigurable DRAM-based LUT-CIM (RDL-CIM) using bipolar coded DRAM (BCD) lowers power overhead of reconfigurable adder tree"
      }
    ],
    "affiliation": "KAIST",
    "authors": "KAIST",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "122.1μJ/token",
    "target_model": "MoE-SD LLM",
    "application": "移动端LLM推理",
    "innovations": [
      {
        "tag": "MoE+投机解码协同优化",
        "type": "co-design"
      },
      {
        "tag": "NPU-CIM计算重配置",
        "type": "hw-arch"
      },
      {
        "tag": "稀疏专家冗余消除",
        "type": "sw"
      }
    ],
    "tags": [
      "LLM",
      "MoE",
      "投机解码",
      "CIM",
      "稀疏",
      "移动端"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "MoE-based speculative decoding LLM and its design challenges.",
        "path": "images/18.3/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture. 313 18 two groups per 4 weights, all workloads are fully covered by the RDL-CIM.",
        "path": "images/18.3/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Operation of TaER and implementation of the MMU.",
        "path": "images/18.3/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Operation and implementation of the TSU and ANC.",
        "path": "images/18.3/fig_4.png"
      },
      {
        "num": 5,
        "caption": "The RDL-CIM with BCD and operation ﬂow of the reconﬁgurable LUT.",
        "path": "images/18.3/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and performance comparison table.",
        "path": "images/18.3/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and performance summary.",
        "path": "images/18.3/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "die_area_mm2": "20.25",
      "energy_efficiency": "122.1μJ/token",
      "target_model": "MoE-SD LLM",
      "source_figure": "fig_7"
    },
    "data_path": "data/18.3/",
    "analytical_tags": [
      "CIM",
      "稀疏化",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "KAIST",
      "name_zh": "韩国科学技术院",
      "type": "academia",
      "country": "韩国",
      "country_code": "KR",
      "logo": "assets/logos/kaist.svg"
    },
    "abstract": "SMoLPU is an energy-efﬁcient MoE-based speculative decoding LLM processor with an NPU-CIM core. It has 3 features: 1) Token-adaptive expert reﬁnement removes redundant expert activations and schedules expert load order, achieving 2.3×/4.2× energy efﬁciency improvement in preﬁll/decode; 2) An adaptive-ofﬂoad NPU-CIM core and a top scheduling unit maintain HW utilization under dynamic INT–FP ratios, achieving 3.3× lower latency; 3) A reconﬁgurable DRAM-based LUT-CIM reduces adder tree power/area, while supporting dynamic input size. The LLM processor achieves 43.5% lower energy per parameter than prior SOTA.",
    "metrics_detailed": {
      "paper_id": "18.3",
      "title": "SMoLPU: 122.1μJ/Token Sparse MoE-Based Speculative Decoding Language Processing Unit with Adaptive-Offload NPU-CIM Core",
      "technology": "28nm CMOS",
      "die_area": {
        "value": "20.25",
        "unit": "mm²",
        "note": "total chip area"
      },
      "frequency": {
        "values": [
          {
            "value": "variable",
            "unit": "Hz",
            "note": "dynamic based on workload"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "122.1",
            "unit": "μJ/token",
            "note": "sparse MoE-based speculative decoding LLM inference"
          },
          {
            "value": "7.8",
            "unit": "μJ/token/parameter",
            "note": "per parameter energy"
          }
        ]
      },
      "energy_per_token": {
        "values": [
          {
            "value": "34.7-99.3",
            "unit": "mJ/token",
            "condition": "on MT-bench for 128 input / 64 output tokens"
          }
        ]
      },
      "energy_savings": {
        "values": [
          {
            "value": "42.7-71.1",
            "unit": "%",
            "note": "total energy consumption reduction"
          },
          {
            "value": "43.5",
            "unit": "%",
            "note": "improvement over SOTA per parameter energy for 1024 input / 1 output tokens"
          }
        ]
      },
      "model_parameters": {
        "total_parameters": {
          "value": "15.7",
          "unit": "B",
          "note": "total parameters in model"
        },
        "active_parameters_per_token": {
          "value": "1.4",
          "unit": "B",
          "note": "activated per token in MoE"
        },
        "parameter_activation_ratio": {
          "value": "8.9",
          "unit": "%",
          "note": "fraction of parameters active per token"
        }
      },
      "external_memory_access": {
        "emai_reduction": {
          "value": "11.2",
          "unit": "x",
          "note": "EMA reduction compared to dense models"
        },
        "emai_reduction_prefill": {
          "value": "2.3",
          "unit": "x",
          "note": "energy efficiency improvement in prefill via TaER"
        },
        "emai_reduction_decode": {
          "value": "4.2",
          "unit": "x",
          "note": "energy efficiency improvement in decode via TaER"
        }
      },
      "token_adaptive_expert_refinement": {
        "expert_emai_reduction": {
          "value": "66.3",
          "unit": "%",
          "note": "expert EMA reduction via masking"
        },
        "expert_computation_reduction": {
          "value": "80.0",
          "unit": "%",
          "note": "expert computation energy reduction"
        },
        "psum_emai_reduction": {
          "value": "67.2",
          "unit": "%",
          "note": "PSUM EMA reduction via cache management"
        },
        "latency_overhead": {
          "value": "<3",
          "unit": "%",
          "note": "TaER latency overhead"
        }
      },
      "hardware_utilization": {
        "int_mac_utilization_improvement": {
          "value": "23.1",
          "unit": "%",
          "note": "INT MAC utilization improvement via TSU/ANC"
        },
        "fp_mac_utilization_improvement": {
          "value": "35.2",
          "unit": "%",
          "note": "FP MAC utilization improvement"
        },
        "end_to_end_speedup": {
          "value": "3.3",
          "unit": "x",
          "note": "achieved via adaptive offload scheduling"
        }
      },
      "memory_architecture": {
        "global_memory": {
          "value": "128",
          "unit": "KB",
          "note": "GMEM"
        },
        "psum_memory": {
          "value": "512",
          "unit": "KB",
          "note": "PSMEM for partial sum caching"
        }
      },
      "cim_design": {
        "rdl_cim_power_reduction": {
          "value": "36.8",
          "unit": "%",
          "note": "reconfigurable DRAM-based LUT-CIM power savings"
        },
        "rdl_cim_area_reduction": {
          "value": "26.3",
          "unit": "%",
          "note": "RDL-CIM area reduction"
        },
        "lut_pitch_reduction": {
          "value": "75.7",
          "unit": "%",
          "note": "via bipolar coded DRAM"
        },
        "refresh_power_overhead": {
          "value": "0.13",
          "unit": "%",
          "note": "for RDL-CIM"
        }
      },
      "model_benchmarks": [
        {
          "model": "OLMoE",
          "metric": "34.7-99.3",
          "detail": "mJ/token energy for 128 input / 64 output tokens"
        },
        {
          "model": "DeepSeek-V2",
          "metric": "34.7-99.3",
          "detail": "mJ/token energy for 128 input / 64 output tokens"
        },
        {
          "model": "Qwen3",
          "metric": "34.7-99.3",
          "detail": "mJ/token energy for 128 input / 64 output tokens"
        },
        {
          "model": "1024 input / 1 output tokens",
          "metric": "43.5%",
          "detail": "energy per parameter improvement over SOTA"
        }
      ],
      "accuracy": {
        "fid_loss": {
          "value": "<0.2",
          "unit": "ppl",
          "note": "negligible accuracy loss"
        }
      },
      "comparison": "Highest EMA reduction (11.2x) among prior works. Lowest energy per parameter (43.5% improvement over SOTA [2]).",
      "notes": "Supports MoE-based speculative decoding with INT-FP heterogeneous workloads. Features token-adaptive expert refinement, adaptive-offload NPU-CIM core, and reconfigurable DRAM-based LUT-CIM."
    },
    "page_images": [
      "images/18.3/page_1.png",
      "images/18.3/page_2.png",
      "images/18.3/page_3.png"
    ]
  },
  {
    "id": "18.4",
    "session": 18,
    "title": "SpikeRAM: A 48.1pW/Synapse/Bit Event-Driven Spiking Compute-Near/In-Memory Processor with Neuromorphic On-Chip Learning",
    "title_zh": "SpikeRAM：48.1pW/突触/位事件驱动脉冲近存/存内计算处理器(片上神经形态学习)",
    "title_annotation": {
      "segments": [
        {
          "text": "SpikeRAM",
          "meaning": "脉冲存内计算处理器",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "48.1pW/Synapse/Bit",
          "meaning": "超低功耗48.1pW/突触/位",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Event-Driven Spiking",
          "meaning": "事件驱动脉冲神经网络",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Compute-Near/In-Memory",
          "meaning": "近存/存内计算",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "On-Chip Learning",
          "meaning": "片上学习",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "感存算分离导致数据搬运与帧转换开销大",
        "related_idea_idx": 0,
        "text_en": "Inefficient inference arises from data movement due to the separation of sensing, memory and computing, along with frame conversion and redundant multiply-accumulations"
      },
      {
        "text": "时空在线学习功耗和存储随时间窗深度缩放",
        "related_idea_idx": 1,
        "text_en": "High power and memory overhead in spatial-temporal OCL, which scales with the depth of time-window (TW)"
      },
      {
        "text": "eNVM写耐久有限制约在线学习寿命",
        "related_idea_idx": 2,
        "text_en": "Excessive memory updates during OCL increase energy and hamper lifetimes for eNVMs with limited writing endurance"
      }
    ],
    "ideas": [
      {
        "text": "EVS集成异步近存脉冲计算消除帧转换",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Memory-centric asynchronous near-sensor computing where the SNN core directly processes asynchronous events from on-chip EVS, eliminating frame conversion"
      },
      {
        "text": "e-OTBP单时间窗反向传播降低学习开销",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Eligibility one-time backpropagation (e-OTBP) OCL algorithm trains a multi-layer network through a single TW and eligibility trace (ET), reducing memory requirements by 73.1% at 32 TWs"
      },
      {
        "text": "灰码权重与三值梯度减少存储编程次数",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Ternary gradients with gray-code weights significantly reduce memory programming times by 89.1% and 88.4% on NMNIST and DVS Gesture respectively"
      }
    ],
    "affiliation": "HKUST(GZ)",
    "authors": "HKUST(GZ)",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "48.1pW/synapse/bit",
    "target_model": "SNN (sCNN + sFC)",
    "application": "神经形态事件驱动感知",
    "innovations": [
      {
        "tag": "EVS集成脉冲近存计算",
        "type": "hw-arch"
      },
      {
        "tag": "资格一次反传片上学习",
        "type": "sw"
      },
      {
        "tag": "ReRAM CIM脉冲全连接层",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "SNN",
      "脉冲",
      "神经形态",
      "CIM",
      "片上学习",
      "事件驱动"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Motivation of edge perceptual SoC with high energy efﬁciency, privacy and adaptability (top), challenges (middle), and our solutions in SpikeRAM (bottom).",
        "path": "images/18.4/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Architecture of SpikeRAM system (top), and event-driven convolution workﬂow in EVS-sCNN core (bottom).",
        "path": "images/18.4/fig_2.png"
      },
      {
        "num": 3,
        "caption": "System diagram of sFC-OCL core (top), event ﬁlter, shift-adder with weighed spikes and conﬁgurable neurons (top right), and handshake-based pipeline (bottom).",
        "path": "images/18.4/fig_3.png"
      },
      {
        "num": 4,
        "caption": "e-OTBP on-chip learning algorithm and ternary gradient implementations (top), and gray-code dataﬂow with weight updating and optional learning in MRAM (bottom).",
        "path": "images/18.4/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Event-based signature veriﬁcation system based on SpikeRAM for few- shot on-chip learning (top), and chip measurement results (bottom).",
        "path": "images/18.4/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Comparison with state-of-the-art neuromorphic processors.",
        "path": "images/18.4/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Summary table (top left), voltage characteristics and chip micrograph (top right), and measurement system (bottom).",
        "path": "images/18.4/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "power_mw": "8.28",
      "energy_efficiency": "48.1pW/synapse/bit",
      "target_model": "SNN (sCNN + sFC)",
      "source_figure": "fig_7"
    },
    "data_path": "data/18.4/",
    "analytical_tags": [
      "CIM",
      "学界"
    ],
    "affiliation_info": {
      "name": "HKUST(GZ)",
      "name_zh": "香港科技大学(广州)",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/hkust-gz.svg"
    },
    "abstract": "SpikeRAM is a high efﬁciency (48.1pW/Synapse/Bit) memory-centric neuromorphic system with perception, computing and on-chip learning, achieving 464M synapses and 8.28mW power in real-time processing, while realizing few-shot learning for event-based signature veriﬁcation. The EVS-sCNN core enables asynchronous sensing and feature extraction. The sFC-OCL core enables event-driven inference and learning with the e-OTBP algorithm. Gray- code weights and ternary gradients reduce memory write times by over 86%.",
    "metrics_detailed": {
      "paper_id": "18.4",
      "title": "SpikeRAM: A 48.1pW/Synapse/Bit Event-Driven Spiking Compute-Near/In-Memory Processor with Neuromorphic Sensor Enabling Life-Long On-Chip Learning",
      "technology": "28nm CMOS",
      "power_efficiency": {
        "values": [
          {
            "value": "48.1",
            "unit": "pW/Synapse/Bit",
            "condition": "power density"
          },
          {
            "value": "2.7",
            "unit": "x",
            "condition": "improvement over [2]"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "1.26",
            "unit": "mW",
            "condition": "static power"
          },
          {
            "value": "8.28",
            "unit": "mW",
            "condition": "dynamic power for real-time processing"
          }
        ]
      },
      "system_power": {
        "value": "8.28",
        "unit": "mW",
        "note": "total system power in real-time tasks"
      },
      "network_capacity": {
        "synapses": {
          "value": "464",
          "unit": "M",
          "note": "total number of synapses"
        },
        "neurons": {
          "value": "328",
          "unit": "K",
          "note": "total number of neurons"
        },
        "network_density": {
          "value": "441.9",
          "unit": "Synapse/Byte",
          "note": "improvement of 24.3x over [10]"
        }
      },
      "event_sensor": {
        "event_rate": {
          "value": "3.8",
          "unit": "MEps",
          "note": "maximum event rate from on-chip EVS"
        },
        "dynamic_range": {
          "value": "130.9",
          "unit": "dB",
          "note": "dynamic range of EVS"
        },
        "frequency": {
          "value": "200",
          "unit": "Hz",
          "note": "infrared pen capture frequency for signature verification"
        }
      },
      "cim_architecture": {
        "first_sfc_pe_macros": {
          "value": "8",
          "unit": "CIM macros",
          "note": "with 32KB RAM each"
        },
        "first_sfc_pe_output_neurons": {
          "value": "16",
          "unit": "configurable neurons",
          "note": "per macro"
        },
        "second_sfc_pe_macros": {
          "value": "10",
          "unit": "CIM macros",
          "note": "with 10KB total"
        },
        "second_sfc_pe_output_neurons": {
          "value": "10",
          "unit": "output neurons"
        }
      },
      "neuromorphic_core": {
        "weight_precision": {
          "value": "8",
          "unit": "bits",
          "note": "weight bit width"
        },
        "membrane_potential_precision": {
          "value": "16",
          "unit": "bits",
          "note": "Vmem bit width"
        }
      },
      "sparsity": {
        "input_sparsity_exploitation": {
          "value": "92.4",
          "unit": "%",
          "note": "redundant computations skipped in DVS Gesture"
        }
      },
      "on_chip_learning": {
        "e_otbp_memory_overhead": {
          "value": "4.3",
          "unit": "%",
          "note": "compared to BPTT"
        },
        "e_otbp_computation_overhead": {
          "value": "3.1",
          "unit": "%",
          "note": "compared to BPTT"
        },
        "time_window_reduction": {
          "value": "73.1",
          "unit": "%",
          "note": "memory requirement reduction at 32 TWs"
        }
      },
      "memory_endurance": {
        "programming_time_reduction_nmnist": {
          "value": "89.1",
          "unit": "%",
          "note": "reduction via ternary gradients and gray-code weights"
        },
        "programming_time_reduction_gesture": {
          "value": "88.4",
          "unit": "%",
          "note": "reduction on DVS Gesture"
        },
        "memory_write_reduction": {
          "value": "92.8",
          "unit": "%",
          "note": "maximum devices written reduction across four datasets"
        },
        "total_write_time_reduction": {
          "value": "86.3",
          "unit": "%",
          "note": "per sample average reduction"
        },
        "mram_update_reduction": {
          "value": "10.9",
          "unit": "x",
          "note": "mean update times reduction in DVS Gesture"
        },
        "mram_lifetime_extension": {
          "value": "13.9",
          "unit": "x",
          "note": "during OCL with MRAM chip"
        }
      },
      "model_benchmarks": [
        {
          "model": "NMNIST",
          "metric": "96.4%",
          "detail": "accuracy with 1 OCL epoch"
        },
        {
          "model": "DVS Gesture",
          "metric": "92.9%",
          "detail": "accuracy with 1 OCL epoch"
        },
        {
          "model": "DailyDVS",
          "metric": "90.5%",
          "detail": "accuracy with 1 OCL epoch"
        },
        {
          "model": "Event-based Signature Verification (EHSV)",
          "metric": "94.3%",
          "detail": "authenticity verification accuracy with 2-shot OCL"
        }
      ],
      "convergence": {
        "value": "1",
        "unit": "epoch",
        "note": "rapid convergence to 90-96% accuracy from random initialization"
      },
      "external_memory": {
        "mram_integration": {
          "value": "4",
          "unit": "Mb",
          "note": "40nm MRAM chip for extended learning"
        },
        "parameter_expansion": {
          "value": "5.4",
          "unit": "x",
          "note": "for N-Caltech101 101-class tasks"
        }
      },
      "comparison": "2.7x power density improvement over [2]. 24.3x network density improvement over [10]. Outstanding learning efficiency with comparable energy consumption to on-chip SRAM.",
      "notes": "Features EVS-integrated spiking convolution core with near-memory computing and spiking fully-connected on-chip learning core. Uses eligibility one-time backpropagation (e-OTBP), ternary gradients, and gray-code weights for efficient in-situ training."
    },
    "page_images": [
      "images/18.4/page_1.png",
      "images/18.4/page_2.png",
      "images/18.4/page_3.png"
    ]
  },
  {
    "id": "18.5",
    "session": 18,
    "title": "A 28nm 47.3TFLOPs/W 894mJ/Inference Visual Autoregressive Accelerator with Differential-Amplifier Speculation and MXINT PE",
    "title_zh": "28nm 47.3TFLOPs/W 894mJ/推理视觉自回归加速器：差分放大器投机+MXINT PE",
    "title_annotation": {
      "segments": [
        {
          "text": "28nm",
          "meaning": "28nm工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "47.3TFLOPs/W",
          "meaning": "能效47.3TFLOPs/W",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Visual Autoregressive",
          "meaning": "视觉自回归模型(VAR)",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Differential-Amplifier Speculation",
          "meaning": "差分放大器投机预测",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "MXINT PE",
          "meaning": "微缩放整数处理单元",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "注意力噪声计算冗余且难区分有效元素",
        "related_idea_idx": 0,
        "text_en": "Attention noise computing is unnecessary but the utility of attention scores is difficult to distinguish what can be ignored"
      },
      {
        "text": "图像数据偏斜分布导致全精度硬件冗余",
        "related_idea_idx": 1,
        "text_en": "The highly biased data distribution of image context causes redundancy in full-precision and full-width hardware"
      },
      {
        "text": "自回归逐像素生成迭代多延迟高",
        "related_idea_idx": 2,
        "text_en": "Sequential generation induces numerous iterations with low information entropy due to data correlations"
      }
    ],
    "ideas": [
      {
        "text": "差分注意力放大器投机识别关键token",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "A differential visual attention amplifier (DVAA) efficiently suppresses attention noise and identifies the significant elements using speculative results to selectively skip model computing"
      },
      {
        "text": "分布感知MXINT PE全路径精度自适应优化",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "A full-path optimized MXINT PE considers the data distribution of visual tasks with compression-aware multiplier, combining-like-term adder tree, and exponent partitioning hot-cold accumulator"
      },
      {
        "text": "链式反应并行生成利用空间相关性降低延迟",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "A chain-reaction-like parallel generation (CRPG) technique takes advantage of visual spatial correlations to generate output pixels in parallel"
      }
    ],
    "affiliation": "Tsinghua University",
    "authors": "Tsinghua University",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "47.3TFLOPs/W",
    "target_model": "VAR (Visual Autoregressive)",
    "application": "视觉自回归图像生成",
    "innovations": [
      {
        "tag": "差分视觉注意力放大器",
        "type": "hw-arch"
      },
      {
        "tag": "全路径MXINT PE",
        "type": "hw-arch"
      },
      {
        "tag": "投机跳过模型计算",
        "type": "sw"
      }
    ],
    "tags": [
      "VAR",
      "视觉自回归",
      "注意力",
      "投机",
      "MXINT",
      "图像生成"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Existing VAR models and challenges of deploying VAR models on hardware.",
        "path": "images/18.5/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture of the chip and three special features. 317 18 is subsequently updated.",
        "path": "images/18.5/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Operation of differential visual attention ampliﬁer and optimization of model processing.",
        "path": "images/18.5/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Design of data distribution-aware full path optimized MXINT PE.",
        "path": "images/18.5/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Implementation of chain-reaction-like parallel generation and skewed sort acceleration.",
        "path": "images/18.5/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison table.",
        "path": "images/18.5/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip speciﬁcation and die photo.",
        "path": "images/18.5/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "energy_efficiency": "47.3TFLOPs/W",
      "target_model": "VAR (Visual Autoregressive)",
      "source_figure": "fig_7"
    },
    "data_path": "data/18.5/",
    "analytical_tags": [
      "量化",
      "生成式AI",
      "学界"
    ],
    "affiliation_info": {
      "name": "Tsinghua University",
      "name_zh": "清华大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/tsinghua-university.svg"
    },
    "abstract": "To accelerate Visual Autoregressive (VAR) applications, this work implements a 28nm VAR accelerator achieving 47.3TFLOPs/W and <0.6% FID loss. A differential visual attention ampliﬁer speculates critical tokens for selective execution; a full-path optimized MXINT PE adapts to biased data distribution; and, a chain reaction-like parallel generation exploits spatial correlation. The 5.76mm2 chip runs at 400MHz, accelerating DeiT/ViT VAR by 37.6× with 2.75TFLOPs/mm2 area efﬁciency.",
    "metrics_detailed": {
      "paper_id": "18.5",
      "title": "A 28nm 47.3TFLOPs/W 894mJ/Inference Visual Autoregressive Accelerator with Differential-Amplifier Speculation and Chain-Reaction-Like Parallel Generation",
      "technology": "28nm CMOS",
      "die_area": {
        "value": "5.76",
        "unit": "mm²",
        "note": "total chip area"
      },
      "frequency": {
        "values": [
          {
            "value": "400",
            "unit": "MHz",
            "condition": "peak operating frequency"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "47.3",
            "unit": "TFLOPs/W",
            "condition": "system energy efficiency"
          }
        ]
      },
      "area_efficiency": {
        "value": "2.75",
        "unit": "TFLOPs/mm²",
        "note": "area efficiency"
      },
      "energy_per_inference": {
        "value": "894",
        "unit": "mJ",
        "note": "per inference"
      },
      "inference_latency": {
        "values": [
          {
            "value": "37.6",
            "unit": "x",
            "condition": "acceleration of generation"
          },
          {
            "value": "23.7",
            "unit": "x",
            "condition": "latency reduction from parallel generation alone"
          }
        ]
      },
      "accuracy": {
        "fid_loss": {
          "value": "<0.6",
          "unit": "%",
          "note": "FID loss compared to baseline"
        }
      },
      "architecture": {
        "core_count": {
          "value": "3",
          "unit": "cores",
          "note": "differential amplifier core (DAC), formal acceleration core (FAC), top-K sort core (TSC)"
        },
        "pe_clusters": {
          "value": "4",
          "unit": "clusters",
          "note": "in FAC"
        },
        "pe_pairs_per_cluster": {
          "value": "8",
          "unit": "pairs",
          "note": "for 16 parallel MACs"
        }
      },
      "differential_visual_attention_amplifier": {
        "ratio_improvement": {
          "value": "3.21",
          "unit": "x",
          "note": "RMSTop-64/RMSNon-Top-64 vs non-differential"
        },
        "computation_reduction": {
          "value": "47.2",
          "unit": "%",
          "note": "Top-K mask reduces computations"
        },
        "energy_efficiency_improvement": {
          "value": "1.93",
          "unit": "x",
          "note": "including differential speculation"
        }
      },
      "attention_mechanism": {
        "log_pe_approximation": {
          "value": "shift-and-add",
          "note": "eliminates multipliers for leading-1 approximation"
        },
        "softmax_approximation": {
          "value": "S2Max",
          "note": "base-2 implementation avoiding non-linear operations"
        },
        "pe_utilization_without_conflicts": {
          "value": ">90.1",
          "unit": "%",
          "note": "with conflict rate <49.6%"
        }
      },
      "mxint_pe_optimization": {
        "compression_aware_dadda_multiplier": {
          "value": "1.21",
          "unit": "x",
          "note": "power reduction via triple-mode 4:2 compressor"
        },
        "combining_adder_tree_area": {
          "value": "4.7",
          "unit": "%",
          "note": "area efficiency improvement"
        },
        "fp_accumulator_activity_reduction": {
          "value": "6.85",
          "unit": "x",
          "note": "via exponent partitioning hot-cold accumulator"
        },
        "accumulation_power_reduction": {
          "value": "1.38",
          "unit": "x"
        },
        "dynamic_exponent_interval": {
          "value": ">32",
          "note": "with ring buffer management"
        },
        "exponent_error_bound": {
          "value": "<2^-31",
          "note": "when exponent gap exceeds 32"
        }
      },
      "parallel_generation": {
        "latency_improvement": {
          "value": "23.7",
          "unit": "x",
          "note": "from chain-reaction-like parallel generation"
        },
        "bit_slice_sorting": {
          "value": "early-exit",
          "note": "optimized for large K"
        },
        "skewed_scheduler_improvement": {
          "value": "1.16",
          "unit": "x",
          "note": "latency improvement for Top-K sorting"
        }
      },
      "qkv_operations": {
        "skippable_operations": {
          "value": "entire row/column",
          "note": "when Top-K mask is all zeros"
        },
        "sparse_aware_acceleration": {
          "value": "enabled",
          "note": "via differential allocator"
        }
      },
      "model_benchmarks": [
        {
          "model": "DeiT VAR",
          "metric": "37.6x",
          "detail": "acceleration"
        },
        {
          "model": "ViT VAR",
          "metric": "37.6x",
          "detail": "acceleration"
        },
        {
          "model": "512x512 resolution baseline",
          "metric": "332.8",
          "detail": "seconds per inference (unaccelerated)"
        }
      ],
      "comparison": "Combines model redundancy (attention noise), hardware redundancy (data distribution bias), and data redundancy (spatial correlations) for significant improvements.",
      "notes": "Features differential visual attention amplifier for speculative execution, full-path MXINT PE with data-distribution awareness, and chain-reaction-like parallel generation exploiting spatial correlation in images."
    },
    "page_images": [
      "images/18.5/page_1.png",
      "images/18.5/page_2.png",
      "images/18.5/page_3.png"
    ]
  },
  {
    "id": "30.1",
    "session": 30,
    "title": "A 28nm 127.54TFLOPS/W MXFP6 and 117.42TFLOPS/W MXFP8 Compute-in-Memory Macro with Serial Dual-Bit-Sliding and Harmless Data Mapping",
    "title_zh": "28nm 127.54TFLOPS/W MXFP6 / 117.42TFLOPS/W MXFP8 存内计算宏：串行双位滑动+无害数据映射",
    "title_annotation": {
      "segments": [
        {
          "text": "28nm",
          "meaning": "28nm工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "MXFP6/MXFP8",
          "meaning": "微缩放浮点6/8位格式",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Compute-in-Memory",
          "meaning": "存内计算(CIM)",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Dual-Bit-Sliding",
          "meaning": "双位滑动计算方案",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Harmless Data Mapping",
          "meaning": "无害数据映射(不浪费存储)",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "输入对齐方案算术效率低，浪费计算资源",
        "related_idea_idx": 0,
        "text_en": "Suboptimal arithmetic efficiency in input-alignment schemes due to non-vertical product truncation, which wastes compute resources"
      },
      {
        "text": "可变位宽重配置导致存储容量利用率低",
        "related_idea_idx": 1,
        "text_en": "Memory capacity underutilization during reconfiguration from variable mantissa/exponent bit-widths, as fixed-precision architectures cannot adapt to dynamic data requirements"
      },
      {
        "text": "固定保留位宽限制多样化工作负载适配",
        "related_idea_idx": 2,
        "text_en": "Limited variable PBW support due to hardware/software constraints, restricting flexibility for diverse workloads"
      }
    ],
    "ideas": [
      {
        "text": "串行双位滑动方案消除冗余乘累加操作",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "A serial dual-bit-sliding (SDBS) scheme that enhances FP multiply-accumulate (MAC) computation efficiency by eliminating redundant operations"
      },
      {
        "text": "无损数据映射与分层隐藏位解码器",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "A harmless data mapping (HDM) scheme with a hierarchical hidden-bit decoder for MXFP6/8, which fully utilizes memory capacity by dynamically adjusting to variable bit-widths"
      },
      {
        "text": "双阶段分配实现层级和组级自适应位宽",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "An adjustable-PBW MXFP-MAC circuit via twin-stage allocation, which balances accuracy and efficiency by adaptively scaling precision for different layers/operations"
      }
    ],
    "affiliation": "Southeast University",
    "authors": "Southeast University",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "127.54TFLOPS/W",
    "target_model": "MXFP CNN/Transformer",
    "application": "AI边缘推理(浮点CIM)",
    "innovations": [
      {
        "tag": "串行双位滑动FP-MAC",
        "type": "hw-arch"
      },
      {
        "tag": "无害数据映射MXFP6/8",
        "type": "hw-arch"
      },
      {
        "tag": "自适应保留位宽",
        "type": "co-design"
      }
    ],
    "tags": [
      "CIM",
      "MXFP",
      "浮点",
      "SRAM",
      "存内计算",
      "28nm"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Motivations, design challenges, and solutions of the proposed MXFP- CIM.",
        "path": "images/30.1/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Conﬁguration table, overall structure and dual-bit sliding computation ﬂow. 513 30 preserving near-lossless end-to-end model accuracy.",
        "path": "images/30.1/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Details of SDBS FP-MAC ﬂow, implementations of the DBSU, the product compressor, and the channel-wise adder tree.",
        "path": "images/30.1/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Mapping scheme for MXFP6 and MXFP8 reconﬁguration, hierarchical hidden-bit decoder and layer-group twin-stage allocation scheme.",
        "path": "images/30.1/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Simulated performance of the proposed work.",
        "path": "images/30.1/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison table.",
        "path": "images/30.1/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and chip summary table.",
        "path": "images/30.1/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "energy_efficiency": "127.54TFLOPS/W",
      "throughput": "1TFLOPS",
      "target_model": "MXFP CNN/Transformer",
      "source_figure": "fig_7"
    },
    "data_path": "data/30.1/",
    "analytical_tags": [
      "CIM",
      "混合精度",
      "学界"
    ],
    "affiliation_info": {
      "name": "Southeast University",
      "name_zh": "东南大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/southeast-university.svg"
    },
    "abstract": "Conventional FP-CIMs suffer from ﬁxed preserved bit-width (PBW), limiting their adaptability and efﬁciency. This work proposes the ﬁrst MXFP-CIM macro enabling wide-range adaptive PBW, featuring: (1) A serial dual-bit-sliding scheme; (2) A harmless data mapping scheme with a hierarchical hidden-bit decoder; (3) An adjustable-PBW MXFP-MAC circuit via twin- stage allocation. The 28nm MXFP-CIM macro achieves a peak energy efﬁciency of 127.54TFLOPS/W in the MXFP6/6 mode.",
    "metrics_detailed": {
      "technology": "28nm CMOS",
      "die_area": {
        "value": "54",
        "unit": "kb",
        "note": "CIM macro capacity: 24×18×128b (54kb) MXFP-CIM macro"
      },
      "frequency": {
        "values": [
          {
            "value": "1.2",
            "unit": "ns",
            "condition": "clock cycle at 0.9V"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.55",
            "unit": "V",
            "condition": "peak energy efficiency measurement"
          },
          {
            "value": "0.9",
            "unit": "V",
            "condition": "peak area efficiency measurement"
          }
        ]
      },
      "quantization": "MXFP6 (E2M3) and MXFP8 (E4M3) formats",
      "sram": {
        "value": "54",
        "unit": "kb",
        "note": "6T-SRAM array with 24 banks, 18-row×128-column per bank"
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "127.54",
            "unit": "TFLOPS/W",
            "condition": "MXFP6/6 mode, peak"
          },
          {
            "value": "117.42",
            "unit": "TFLOPS/W",
            "condition": "MXFP8/8 mode at 0.55V"
          },
          {
            "value": "49.53",
            "unit": "TFLOPS/W",
            "condition": "inference mode (LLaMA-3.1 8B)"
          },
          {
            "value": "19.11",
            "unit": "TFLOPS/W",
            "condition": "training mode (ResNet-18)"
          }
        ]
      },
      "compute_density": {
        "values": [
          {
            "value": "4.44",
            "unit": "TFLOPS/mm2",
            "condition": "peak area efficiency at 0.9V"
          }
        ]
      },
      "preserved_bit_width": {
        "values": [
          {
            "value": "3-27",
            "unit": "bits",
            "condition": "adaptive range depending on layer/application"
          }
        ]
      },
      "comparison": "2.8× to 123× improvement in FoM (energy efficiency×normalized area efficiency×memory density) versus prior SRAM-based FP-CIM designs"
    },
    "page_images": [
      "images/30.1/page_1.png",
      "images/30.1/page_2.png",
      "images/30.1/page_3.png"
    ]
  },
  {
    "id": "30.2",
    "session": 30,
    "title": "A 12nm 4Mb 104.56-to-137.75TFLOPS/W Charge-Trap Transistor-Based Computing-in-Memory Macro Using Computation-Skipping and FP-Friendly Scheme",
    "title_zh": "12nm 4Mb 104.56~137.75TFLOPS/W电荷俘获晶体管CIM宏：计算跳过+浮点友好方案",
    "title_annotation": {
      "segments": [
        {
          "text": "12nm 4Mb",
          "meaning": "12nm工艺 4Mb容量",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Charge-Trap Transistor",
          "meaning": "电荷俘获晶体管(CTT)",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "Computing-in-Memory",
          "meaning": "存内计算",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Computation-Skipping",
          "meaning": "计算跳过(跳过零值)",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "FP-Friendly",
          "meaning": "浮点友好方案",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "电荷俘获晶体管阈值偏移小难以实现数字CIM",
        "related_idea_idx": 0,
        "text_en": "CTTs exhibit small VTH shift (70 to 300mV) making it difficult to implement digital or hybrid-domain nvCIM that usually requires large signal ratios"
      },
      {
        "text": "激活后大量零值MAC运算浪费能耗",
        "related_idea_idx": 1,
        "text_en": "After activation and quantization, many negative or small MAC values become zero or negligible and become unnecessary to compute"
      },
      {
        "text": "浮点预对齐和存储开销导致硬件成本高",
        "related_idea_idx": 2,
        "text_en": "Processing high-precision floating-point format data in nvCIM incurs considerable hardware costs including dedicated circuits for pre-alignment and additional storage room for aligned mantissa"
      }
    ],
    "ideas": [
      {
        "text": "差分增益CTT阵列支持模拟与数字MAC",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "High-density differential-gain CTT computing array capable of supporting both analog and digital MAC with small area overhead"
      },
      {
        "text": "符号幅度预测模拟通路跳过无效运算",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Highly energy-efficient sign-and-magnitude predictable analog data-path to skip unnecessary partial MAC operations"
      },
      {
        "text": "LUT-FP4预处理降低浮点对齐硬件开销",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "LUT-FP4 pre-processing for on-chip pre-alignment to reduce PA- and storage-cost for INT4/8 and FP4 digital data-path"
      }
    ],
    "affiliation": "TSMC",
    "authors": "TSMC",
    "process_node": "12nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "137.75TFLOPS/W",
    "target_model": "CNN/Transformer",
    "application": "非易失存内计算",
    "innovations": [
      {
        "tag": "CTT高密度非易失CIM",
        "type": "hw-circuit"
      },
      {
        "tag": "零值计算跳过",
        "type": "sw"
      },
      {
        "tag": "浮点友好存内计算",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "CIM",
      "CTT",
      "非易失",
      "12nm",
      "浮点",
      "TSMC"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Challenges and the presented 12nm 4Mb hybrid-domain CTT nvCIM macro.",
        "path": "images/30.2/fig_1.png"
      },
      {
        "num": 2,
        "caption": "CTT MAC array organization and its operational waveforms for the APDC ﬂow. 515 30 Compared to previous nvCIM works (Fig.",
        "path": "images/30.2/fig_2.png"
      },
      {
        "num": 3,
        "caption": "The structure of SMP-AD and its computing ﬂow for analog prediction.",
        "path": "images/30.2/fig_3.png"
      },
      {
        "num": 4,
        "caption": "The structure of INT/FP4-DD and its computing ﬂow with LUT-FP4 pre- processing.",
        "path": "images/30.2/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Measurement results of the fabricated 12nm CTT nvCIM macro.",
        "path": "images/30.2/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Comparison to previous nvCIM works.",
        "path": "images/30.2/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph, position chart and chip performance summary table.",
        "path": "images/30.2/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "12nm",
      "supply_voltage": "0.8V",
      "energy_efficiency": "137.75TFLOPS/W",
      "throughput": "3.2GB/S",
      "target_model": "CNN/Transformer",
      "source_figure": "fig_7"
    },
    "supply_voltage": "0.8V",
    "data_path": "data/30.2/",
    "analytical_tags": [
      "CIM",
      "业界"
    ],
    "affiliation_info": {
      "name": "TSMC",
      "name_zh": "台积电",
      "type": "industry",
      "country": "中国台湾",
      "country_code": "CN",
      "logo": "assets/logos/tsmc.svg"
    },
    "abstract": "Previous non-volatile CIM (nvCIM) macros suffer from low storage density, unnecessary multiply-and-accumulate (MAC) operations, and large hardware cost for ﬂoating point computations. A 4Mb CTT nvCIM macro, fabricated in 12nm CMOS, supports INT/FP4 MAC operations with the analog-predict-digital-compute scheme for power saving, achieving an energy-efﬁciency of 137.75TFLOPS/W and >40 times improved density FoM (storage density×computing density).",
    "metrics_detailed": {
      "technology": "12nm CMOS",
      "die_area": {
        "value": "4",
        "unit": "Mb",
        "note": "CTT nvCIM macro with 16 256kb-banks (Bank0-15)"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.8",
            "unit": "V",
            "condition": "measurement condition"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "1.25",
            "unit": "ns",
            "condition": "access time (TAC) for AP phase"
          },
          {
            "value": "1.34",
            "unit": "ns",
            "condition": "access time for one DC cycle"
          },
          {
            "value": "36",
            "unit": "ns",
            "condition": "TAC for FP4IN-FP4W-18bOUT at 0.8V"
          }
        ]
      },
      "quantization": "INT4/8 and FP4 precision; INT16-to-24 precision for output",
      "sram": {
        "value": "4",
        "unit": "Mb",
        "note": "Charge-trap transistor (CTT) based non-volatile memory"
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "137.75",
            "unit": "TFLOPS/W",
            "condition": "peak for ResNet-18 processing"
          },
          {
            "value": "104.56",
            "unit": "TFLOPS/W",
            "condition": "average for ResNet-18"
          }
        ]
      },
      "compute_density": {
        "values": [
          {
            "value": "2.61-3.64",
            "unit": "TFLOPS/mm2",
            "condition": "range depending on configuration"
          }
        ]
      },
      "storage_density": {
        "value": "1.33",
        "unit": "Mb/mm2",
        "note": "key advantage of CTT-based approach"
      },
      "comparison": "44.49× improvement in FoM1 (Storage Density×Compute Density) over prior INT8 nvCIM designs; 14.62× improvement in FoM2 (Storage Density×Energy Efficiency×Compute Density)",
      "model_benchmarks": [
        {
          "model": "ResNet-18",
          "metric": "104.56-137.75 TFLOPS/W",
          "detail": "energy efficiency with INT/FP4 MAC"
        }
      ]
    },
    "page_images": [
      "images/30.2/page_1.png",
      "images/30.2/page_2.png",
      "images/30.2/page_3.png"
    ]
  },
  {
    "id": "30.3",
    "session": 30,
    "title": "A 22nm 96Mb 50.6-to-90.2TFLOPS/W Non-Linear MLC ReRAM CIM Macro with High-Retention for Mamba/Transformer/CNN",
    "title_zh": "22nm 96Mb 50.6~90.2TFLOPS/W非线性MLC ReRAM CIM宏：高保持力 支持Mamba/Transformer/CNN",
    "title_annotation": {
      "segments": [
        {
          "text": "22nm 96Mb",
          "meaning": "22nm工艺 96Mb大容量",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Non-Linear MLC ReRAM",
          "meaning": "非线性多级单元ReRAM",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "CIM Macro",
          "meaning": "存内计算宏单元",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "High-Retention",
          "meaning": "高数据保持力",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "Mamba/Transformer/CNN",
          "meaning": "支持多种模型架构",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "SLC/MLC模式间精度、能耗与面积权衡困难",
        "related_idea_idx": 0,
        "text_en": "Navigating the trade-offs among SLC, NL-MLC, L-MLC modes with respect to inference accuracy, energy consumption, and area efficiency over device lifespan"
      },
      {
        "text": "GeLU/SiLU激活函数导致输入稀疏性低",
        "related_idea_idx": 1,
        "text_en": "Mitigating the high in-memory-compute (IMC) energy consumption associated with low input sparsity in conventional activation formats, an issue exacerbated by the increasingly adoption of activation functions such as GeLU and SiLU in the modern models"
      },
      {
        "text": "非线性MLC器件精确低功耗读出困难",
        "related_idea_idx": 2,
        "text_en": "Achieving accurate and energy-efficient readout, which is particularly difficult for NL-MLC devices"
      }
    ],
    "ideas": [
      {
        "text": "DTCO可重构计算模式融合NL-MLC/SLC",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "A DTCO reconfigurable compute mode that balances inference accuracy and energy efficiency by flexibly combining NL-MLC, L-MLC, and SLC configurations within the macro"
      },
      {
        "text": "输入稀疏增强混合格式提升位稀疏性",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "An Input-Sparsity-Enhanced Hybrid Format (ISE-HF) that combines conventional 2C with the proposed Sign-Reversed (SR) representation to increase input sparsity"
      },
      {
        "text": "单自参考双位ADC实现低功耗MLC读出",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "A Single-Self-Reference Dual-bit (S2R-Db) ADC that enables accurate two-bit readout while optimizing energy and area overhead for NL-MLC readout"
      }
    ],
    "affiliation": "NTHU",
    "authors": "NTHU",
    "process_node": "22nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "90.2TFLOPS/W",
    "target_model": "Mamba/Transformer/CNN",
    "application": "AI边缘推理(ReRAM CIM)",
    "innovations": [
      {
        "tag": "DTCO可重构NL-MLC ReRAM",
        "type": "co-design"
      },
      {
        "tag": "高保持力多模型支持",
        "type": "hw-circuit"
      },
      {
        "tag": "能效优化读出电路",
        "type": "hw-circuit"
      }
    ],
    "tags": [
      "ReRAM",
      "CIM",
      "MLC",
      "Mamba",
      "非易失",
      "22nm"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Advantages of Non-Linear MLC, challenges and proposed High-Retention Multi-Mode ReRAM CIM macro.",
        "path": "images/30.3/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Accumulation number breakdown of recent models and proposed DTCO reconﬁgurable compute mode with TNLCM and DMDC. 517 30",
        "path": "images/30.3/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Flow chart and illustrations of proposed ISE-HF.",
        "path": "images/30.3/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Illustration and waveform of proposed S2R-Db ADC.",
        "path": "images/30.3/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Simulated performance of proposed schemes.",
        "path": "images/30.3/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Simulated inference accuracy over years, measured shmoo plot and comparison table of recent ReRAM CIM macros.",
        "path": "images/30.3/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and chip performance summary.",
        "path": "images/30.3/fig_7.png"
      }
    ],
    "metrics": {
      "energy_efficiency": "90.2TFLOPS/W",
      "throughput": "14.74TOPS",
      "technology": "22nm",
      "target_model": "Mamba/Transformer/CNN",
      "source_figure": "fig_7"
    },
    "data_path": "data/30.3/",
    "analytical_tags": [
      "CIM",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "NTHU",
      "name_zh": "国立清华大学",
      "type": "academia",
      "country": "中国台湾",
      "country_code": "CN",
      "logo": "assets/logos/nthu.svg"
    },
    "abstract": "We present a DTCO-designed high-retention multi-mode ReRAM nvCIM macro supporting linear MLC (L-MLC), non-linear MLC (NL-MLC), and SLC modes for Mamba, Transformer, and CNN workloads, addressing key challenges in inference accuracy, energy, and readout robustness. The proposed macro incorporates: 1) a reconﬁgurable compute mode for accuracy/efﬁciency tradeoff, 2) ISE-HF encoding to enhance input sparsity and save energy, 3) an S2R-Db ADC that enables high-yield, low-power NL-MLC readout. The design achieves 50.6-to-90.2TFLOPS/W (BF16) with ImageNet accuracy loss that is 79.17% lower than L- MLC after 10 years of retention.",
    "metrics_detailed": {
      "technology": "22nm CMOS",
      "die_area": {
        "value": "96",
        "unit": "Mb",
        "note": "ReRAM CIM macro capacity with multi-mode operation"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.8",
            "unit": "V",
            "condition": "measurement condition for shmoo"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "5.0",
            "unit": "ns",
            "condition": "cycle time at 0.8V"
          }
        ]
      },
      "quantization": "BF16 format with multi-precision modes (SLC, L-MLC, NL-MLC)",
      "memory_modes": {
        "values": [
          {
            "value": "SLC",
            "description": "single-level cell for high retention"
          },
          {
            "value": "L-MLC",
            "description": "linear multi-level cell for balanced operation"
          },
          {
            "value": "NL-MLC",
            "description": "non-linear multi-level cell for high density"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "50.6-90.2",
            "unit": "TFLOPS/W",
            "condition": "range across different modes and conditions"
          }
        ]
      },
      "retention": {
        "value": "10",
        "unit": "years",
        "note": "measured device retention time"
      },
      "accuracy_preservation": {
        "value": "79.17%",
        "unit": "improvement",
        "condition": "vs L-MLC at 10 years retention, TinyViM-S (Mamba) with BF16"
      },
      "comparison": "High-retention multi-mode ReRAM CIM addressing Mamba, Transformer, and CNN workloads with improved accuracy retention over pure L-MLC approach",
      "model_benchmarks": [
        {
          "model": "TinyViM-S (Mamba)",
          "metric": "79.17% higher accuracy vs L-MLC",
          "detail": "at 10 years retention with BF16 precision"
        },
        {
          "model": "ImageNet inference",
          "metric": "near-lossless accuracy",
          "detail": "with ISE-HF and S2R-Db ADC schemes"
        }
      ]
    },
    "page_images": [
      "images/30.3/page_1.png",
      "images/30.3/page_2.png",
      "images/30.3/page_3.png"
    ]
  },
  {
    "id": "30.4",
    "session": 30,
    "title": "A 28nm 106.85TOPS/W and 77.68TFLOPS/W CIM Macro with Stage-Wise-Enabled Lossless Compressors Based on Transition-Counting Lines",
    "title_zh": "28nm 106.85TOPS/W 77.68TFLOPS/W CIM宏：基于跳变计数线的分级无损压缩器",
    "title_annotation": {
      "segments": [
        {
          "text": "28nm",
          "meaning": "28nm工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "106.85TOPS/W",
          "meaning": "整数能效106.85TOPS/W",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "CIM Macro",
          "meaning": "存内计算宏单元",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Transition-Counting Lines",
          "meaning": "跳变计数线(TCL)",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "Lossless Compressors",
          "meaning": "无损压缩器",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "8位并行CIM布线拥塞与面积开销权衡",
        "related_idea_idx": 0,
        "text_en": "8b bit-parallel CIM suffers from routing congestion with a tradeoff between throughput and area overhead"
      },
      {
        "text": "二补码符号位处理需额外面积或周期",
        "related_idea_idx": 1,
        "text_en": "Handling sign bits for 2's-complementary MAC demands large extra area or additional cycles"
      },
      {
        "text": "中间结果引起高扇入加法器无效翻转功耗大",
        "related_idea_idx": 2,
        "text_en": "Intermediates induce unnecessary toggling in high-fan-in adders resulting in power inefficiency"
      }
    ],
    "ideas": [
      {
        "text": "跳变计数线实现无损稀疏自适应列压缩",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Lossless digital local compressors based on transition-counting-lines (TCLs) realizing sparsity-adaptive and area-efficient bit-column addition"
      },
      {
        "text": "总线TCL嵌入符号位扩展仅增2.95%面积",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "A bus TCL embedding sign-bit extension for signed 2's-complementary MAC incurring only 2.95% extra area"
      },
      {
        "text": "共享10相发生器分阶段使能避免无效翻转",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "A shared local 10-phase generator enabling TCLs and adder trees to operate in a stage-wise manner avoiding unnecessary toggling"
      }
    ],
    "affiliation": "Xidian University",
    "authors": "Xidian University",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "106.85TOPS/W",
    "target_model": "INT8/FP CNN",
    "application": "数字位并行存内计算",
    "innovations": [
      {
        "tag": "跳变计数线无损压缩",
        "type": "hw-circuit"
      },
      {
        "tag": "总线TCL符号扩展",
        "type": "hw-circuit"
      },
      {
        "tag": "分级流水计算",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "CIM",
      "SRAM",
      "位并行",
      "无损压缩",
      "TCL",
      "28nm"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Challenges of bit-parallel CIM macro and the proposed solution.",
        "path": "images/30.4/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture of the proposed TCL-based digital-SRAM CIM macro. 519 30 and 0.9V supply voltages, respectively, with 90% input sparsity and 10% toggle rate, while the weight sparsity is 50%.",
        "path": "images/30.4/fig_2.png"
      },
      {
        "num": 3,
        "caption": "The structures and workﬂows of the TCL and the 10-phase generator.",
        "path": "images/30.4/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Embedded sign-bit extension in bus TCL-14 and the enabling-circuit structure for Combine Adder and In-Block Adder Tree.",
        "path": "images/30.4/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Simulated MAC computing cell performance and measured energy efﬁciencies of the proposed CIM macro.",
        "path": "images/30.4/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison table.",
        "path": "images/30.4/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and summary of key performance metrics.",
        "path": "images/30.4/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "supply_voltage": "0.9V",
      "energy_efficiency": "106.85TOPS/W",
      "target_model": "INT8/FP CNN",
      "source_figure": "fig_7"
    },
    "supply_voltage": "0.9V",
    "data_path": "data/30.4/",
    "analytical_tags": [
      "CIM",
      "位串行",
      "学界"
    ],
    "affiliation_info": {
      "name": "Xidian University",
      "name_zh": "西安电子科技大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/xidian-university.svg"
    },
    "abstract": "This paper proposes a bit-parallel digital CIM macro featuring a lossless compressor based on transition-counting-lines (TCLs) for bit-column addition. The bus TCL incorporates sign- bit extension to support signed 2’s-complement MAC operations with minimal area overhead. A stage-wise enabling circuit prevents unnecessary toggling of adders, improving energy efﬁciency by 42%. Leveraging these techniques, the proposed CIM macro, which is fabricated in 28nm CMOS, achieves 106.85TOPS/W for INT8 operations and 77.68TFLOPS/W for BF16 operations.",
    "metrics_detailed": {
      "technology": "28nm CMOS",
      "die_area": {
        "value": "32",
        "unit": "kb",
        "note": "CIM macro capacity"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.55",
            "unit": "V",
            "condition": "minimum operating voltage for BF16"
          },
          {
            "value": "0.9",
            "unit": "V",
            "condition": "maximum area efficiency measurement"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "4.1",
            "unit": "ns",
            "condition": "access time for BF16 at 0.9V"
          }
        ]
      },
      "quantization": "INT8 and BF16 MAC operations",
      "energy_efficiency": {
        "values": [
          {
            "value": "106.85",
            "unit": "TOPS/W",
            "condition": "INT8 mode, peak"
          },
          {
            "value": "77.68",
            "unit": "TFLOPS/W",
            "condition": "BF16 mode at 0.55V and 0.9V with 90% input sparsity and 10% toggle rate"
          }
        ]
      },
      "compute_density": {
        "values": [
          {
            "value": "1.24",
            "unit": "TFLOPS/mm2",
            "condition": "BF16 mode at 0.9V"
          }
        ]
      },
      "comparison": "1.25 to 2.88× improvement in FoM1 (output precision×TOPS/W×TOPS/mm2) and 2.20 to 19.9× improvement in FoM2 (TFLOPS/W×TFLOPS/mm2) versus prior signed CIM macros",
      "model_benchmarks": [
        {
          "model": "ViT-B @ImageNetV2",
          "metric": "81.05%",
          "detail": "inference accuracy in BF16 mode"
        },
        {
          "model": "ResNet50 @ImageNetV2",
          "metric": "81.19%",
          "detail": "inference accuracy in BF16 mode"
        }
      ],
      "key_features": {
        "tcl_based_compression": "lossless digital local compressors based on transition-counting-lines",
        "sign_extension": "2.95% extra area for sign-bit extension",
        "stage_wise_enabling": "42% energy efficiency improvement via stage-wise enabling"
      }
    },
    "page_images": [
      "images/30.4/page_1.png",
      "images/30.4/page_2.png",
      "images/30.4/page_3.png"
    ]
  },
  {
    "id": "30.5",
    "session": 30,
    "title": "A 16nm 72kb 120.5TFLOPS/W Versatile-Format Dual-Representation Gain-Cell CIM Macro for General Purpose AI",
    "title_zh": "16nm 72kb 120.5TFLOPS/W多格式双表示增益单元CIM宏：面向通用AI",
    "title_annotation": {
      "segments": [
        {
          "text": "16nm 72kb",
          "meaning": "16nm工艺 72kb容量",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Versatile-Format",
          "meaning": "多格式(MX-LNS-FP-INT)",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Dual-Representation",
          "meaning": "双表示(2补码+符号幅度)",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Gain-Cell CIM",
          "meaning": "增益单元存内计算",
          "color": "#e67e22",
          "type": "hw-circuit"
        }
      ]
    },
    "challenges": [
      {
        "text": "二补码与符号幅度表示的面积功耗权衡",
        "related_idea_idx": 0,
        "text_en": "2C versus SM area-power trade-off where 2C representation suffers from high toggle rates due to low bit-wise sparsity near negative zero whereas SM increases hardware area overhead"
      },
      {
        "text": "固定MX块大小无法适配不同输入分布",
        "related_idea_idx": 1,
        "text_en": "Fixed MX block size using a single MX block-size (k) constrains the energy-accuracy trade-off as it cannot adapt to different input distributions"
      },
      {
        "text": "对数数制CIM硬件开销大且跨格式复用难",
        "related_idea_idx": 2,
        "text_en": "LNS area overhead where supporting LNS in CIM requires replacing MAC operations with additions and look-up table (LUT) accesses increasing area overhead and reducing area utilization since hardware cannot be shared across formats"
      }
    ],
    "ideas": [
      {
        "text": "极性转移权重稀疏增强器统一2C/SM计算",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Compact in-situ weight sparsity booster (CiWSB) with polarity-shift weight control (PSWC) transfers weight polarity to inputs to overcome the area-energy trade-off between 2C and SM and enables reconfigurable 2C-SM computation in CIM macros with minimal area overhead"
      },
      {
        "text": "输入分布感知MX量化器自适应选择块大小",
        "type": "sw",
        "color": "#2ecc71",
        "text_en": "Input distribution-aware MX quantizer (IDA-MXQ) adaptively selects the optimal MX block-size k based on input distributions improving both energy efficiency and accuracy"
      },
      {
        "text": "多格式自适应计算单元跨LNS/FP/INT复用",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Multi-format adaptive computing cell (MFA-CC) with delta exponent subtractor and LUT support shares hardware across LNS FP and INT modes"
      }
    ],
    "affiliation": "NTHU",
    "authors": "NTHU",
    "process_node": "16nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "120.5TFLOPS/W",
    "target_model": "General AI (LLM/FFT/CNN)",
    "application": "通用AI存内计算",
    "innovations": [
      {
        "tag": "多格式MX-LNS-FP-INT CIM",
        "type": "hw-arch"
      },
      {
        "tag": "双表示增益单元",
        "type": "hw-circuit"
      },
      {
        "tag": "极性偏移权重控制",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "CIM",
      "增益单元",
      "多格式",
      "LNS",
      "浮点",
      "16nm"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "The proposed VF-DR GC-CIM and challenges of designing a general purposed CIM macro.",
        "path": "images/30.5/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Proposed CiWSB with SGU, PSWC, and CiWSB function ﬂow. 521 30 MX-LNS-FP-INT formats and providing support for LNS.",
        "path": "images/30.5/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Proposed IDA-MXQ structure and its operation.",
        "path": "images/30.5/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Proposed MFA-CC structure and operation for versatile-format MAC support.",
        "path": "images/30.5/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Simulated performance of proposed schemes.",
        "path": "images/30.5/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison table.",
        "path": "images/30.5/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and chip performance summary table.",
        "path": "images/30.5/fig_7.png"
      }
    ],
    "metrics": {
      "energy_efficiency": "120.5TFLOPS/W",
      "technology": "16nm",
      "target_model": "General AI (LLM/FFT/CNN)",
      "source_figure": "fig_7"
    },
    "data_path": "data/30.5/",
    "analytical_tags": [
      "CIM",
      "混合精度",
      "学界"
    ],
    "affiliation_info": {
      "name": "NTHU",
      "name_zh": "国立清华大学",
      "type": "academia",
      "country": "中国台湾",
      "country_code": "CN",
      "logo": "assets/logos/nthu.svg"
    },
    "abstract": "Diverse AI workloads require ﬂexible data representations and numerical formats. In this work, we present a reconﬁgurable 2’s-complement and sign-magnitude scheme integrated within a versatile-format CIM macro supporting MX, LNS, FP, and INT for MAC operations. Implemented in a 16nm 72kb gain-cell array, the macro achieves record energy efﬁciency (120.5TFLOPS/W) and throughput density (3.18 TOPS/mm2) in MXINT8 mode.",
    "metrics_detailed": {
      "technology": "16nm CMOS",
      "die_area": {
        "value": "72",
        "unit": "kb",
        "note": "gain-cell array based CIM macro"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.8",
            "unit": "V",
            "condition": "shmoo measurement condition"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "1.2",
            "unit": "ns",
            "condition": "access time for MXINT8-MAC at 0.8V"
          }
        ]
      },
      "quantization": "MXINT8, MXFP8, LNS8, BF16, and INT8 formats",
      "energy_efficiency": {
        "values": [
          {
            "value": "120.5",
            "unit": "TFLOPS/W",
            "condition": "MXINT8 mode"
          },
          {
            "value": "98.1",
            "unit": "TFLOPS/W",
            "condition": "LNS8 mode"
          },
          {
            "value": "50.4",
            "unit": "TFLOPS/W",
            "condition": "BF16 mode"
          },
          {
            "value": "138.5",
            "unit": "TFLOPS/W",
            "condition": "INT8 mode"
          }
        ]
      },
      "compute_density": {
        "values": [
          {
            "value": "3.18",
            "unit": "TOPS/mm2",
            "condition": "MXINT8 and INT8 modes"
          },
          {
            "value": "1.59",
            "unit": "TOPS/mm2",
            "condition": "BF16 mode"
          }
        ]
      },
      "data_representations": [
        "2's complement (2C) format",
        "sign-magnitude (SM) format",
        "sign-reversed (SR) format"
      ],
      "comparison": "1.7 to 2.3× improvement in FoM1 across representative AI workloads; supports multiple numerical formats (MX-LNS-FP-INT) with dual-representation capability",
      "model_benchmarks": [
        {
          "model": "ResNet-20 @CIFAR-100",
          "metric": "<0.01%",
          "detail": "inference accuracy loss with product alignment and full output precision"
        },
        {
          "model": "MobileViT @ImageNet-1K",
          "metric": "<0.01%",
          "detail": "inference accuracy loss"
        }
      ]
    },
    "page_images": [
      "images/30.5/page_1.png",
      "images/30.5/page_2.png",
      "images/30.5/page_3.png"
    ]
  },
  {
    "id": "30.6",
    "session": 30,
    "title": "A 16Mb 166.8TOPS/W Near-Memory Phase-Domain-Computing Ferroelectric NAND Flash for Approximate Nearest Neighbor Search on Edge Devices",
    "title_zh": "16Mb 166.8TOPS/W近存相域计算铁电NAND闪存：边缘设备近似最近邻搜索",
    "title_annotation": {
      "segments": [
        {
          "text": "16Mb",
          "meaning": "16Mb存储容量",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Near-Memory Phase-Domain-Computing",
          "meaning": "近存相域计算",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Ferroelectric NAND Flash",
          "meaning": "铁电NAND闪存(FeNAND)",
          "color": "#e67e22",
          "type": "hw-circuit"
        },
        {
          "text": "Approximate Nearest Neighbor Search",
          "meaning": "近似最近邻搜索(ANNS)",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "NAND小单元间距限制近存计算单元面积和功耗",
        "related_idea_idx": 0,
        "text_en": "The small cell pitch and highly parallel readout scheme in NAND impose tight constraints on the area and power budgets for the NMC units"
      },
      {
        "text": "位线大电容导致读出能量延迟积过高",
        "related_idea_idx": 1,
        "text_en": "The large bit-line capacitance results in a large energy-delay product (EDP) for readout"
      },
      {
        "text": "无法支持多比特有符号稀疏向量搜索",
        "related_idea_idx": 2,
        "text_en": "ANNS workloads incorporate diverse vector types with various bit-widths, sign formats, and sparsity, whereas prior efforts have focused mainly on binary, unsigned, and dense vector search operations"
      }
    ],
    "ideas": [
      {
        "text": "相位域计算单元紧邻BEOL FeNAND阵列",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "A near-memory phase-domain-computing (NM-PDC) FeNAND that integrates highly energy- and area-efficiency PDC units near the BEOL FeNAND array"
      },
      {
        "text": "充放电交织感知与自动极性切换放大器",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "A charge-discharge interleaving (CDI) sensing scheme with an auto-polarity-switching sense amplifier (APS-SA)"
      },
      {
        "text": "多比特符号感知PDC与稀疏感知输入处理",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Multi-bit and sign-aware phase-domain computing units (MS-PDCUs) and sparsity-aware input vector processing unit (SA-IVPU)"
      }
    ],
    "affiliation": "IMECAS",
    "authors": "IMECAS",
    "process_node": "",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "166.8TOPS/W",
    "target_model": "ANNS (Vector Search)",
    "application": "边缘向量搜索",
    "innovations": [
      {
        "tag": "近存相域计算FeNAND",
        "type": "hw-arch"
      },
      {
        "tag": "充放电交替读出",
        "type": "hw-circuit"
      },
      {
        "tag": "图基ANNS加速",
        "type": "sw"
      }
    ],
    "tags": [
      "FeNAND",
      "近存计算",
      "ANNS",
      "向量搜索",
      "铁电",
      "边缘"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Challenges for developing NMC NAND for ANNS and the presented 16Mb HZO-based NM-PDC FeNAND.",
        "path": "images/30.6/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Structure of the NM-PDC FeNAND, the computing ﬂow for ANNS, and vector dimension optimization.",
        "path": "images/30.6/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Structure and operation of the APS-SA with CDI-sensing scheme for FeNAND readout.",
        "path": "images/30.6/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Structure and operation of the NM-PDC Units, including SA-IPVU, MS- PDCU, and the SDCU.",
        "path": "images/30.6/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Measurement results of the fabricated NM-PDC FeNAND chip.",
        "path": "images/30.6/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Comparison with previous works on phase domain MAC units and IMC",
        "path": "images/30.6/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and chip performance summary.",
        "path": "images/30.6/fig_7.png"
      }
    ],
    "metrics": {
      "energy_efficiency": "166.8TOPS/W",
      "throughput": "471.0GOPS",
      "target_model": "ANNS (Vector Search)",
      "source_figure": "fig_7"
    },
    "data_path": "data/30.6/",
    "analytical_tags": [
      "CIM",
      "学界"
    ],
    "affiliation_info": {
      "name": "IMECAS",
      "name_zh": "中科院微电子所",
      "type": "research_inst",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/imecas.svg"
    },
    "abstract": "Previous near-memory computing (NMC) or in-memory-computing (IMC) NANDs suffers from limited IO width, large energy-delay-product, and an inability to support diverse vector formats. This work presents a fabricated 16Mb near-memory phase-domain-computing (NM-PDC) FeNAND chip can compute the 512 similarity distances between 256-dimensional 4b vectors in a single search operation, achieving 166.8TOPS/W energy efﬁciency and a 12.8× reduction in end-to-end search latency.",
    "metrics_detailed": {
      "technology": "180nm logic process with BEOL ferroelectric capacitors",
      "die_area": {
        "value": "16",
        "unit": "Mb",
        "note": "FeNAND cell array with 128×2048 ferroelectric NAND chains (FNCs)"
      },
      "frequency": {
        "values": [
          {
            "value": "27",
            "unit": "MHz",
            "condition": "at peak energy efficiency 166.8 TOPS/W"
          },
          {
            "value": "36",
            "unit": "MHz",
            "condition": "at peak throughput 471.0 GOPS"
          }
        ]
      },
      "quantization": "4b input vector (IV[3:0]) and 4b stored vectors (SV[3:0]) in sign-magnitude format",
      "sram": {
        "value": "16",
        "unit": "Mb",
        "note": "FeNAND storage capacity"
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "166.8",
            "unit": "TOPS/W",
            "condition": "peak for VMM operations at 27MHz"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "471.0",
            "unit": "GOPS",
            "condition": "peak throughput at 36MHz"
          }
        ]
      },
      "vector_dimensions": {
        "value": "256",
        "unit": "dimensions",
        "note": "using truncated SVD reduction from original dataset"
      },
      "anns_performance": {
        "value": "12.8",
        "unit": "× reduction",
        "detail": "end-to-end search latency with SA-IVPU; recall rates: 92.1% (k=100), 91.9% (k=10) on 20NewsGroup dataset"
      },
      "memory_window": {
        "value": ">0.45",
        "unit": "V",
        "condition": "maintained after 10^9 P/E cycles"
      },
      "comparison": "1.29× improvement in energy efficiency vs prior phase-domain computing; 2.56× improvement in FoM (Capacity×IV-precision×SV-precision×Signal Margin×EF)",
      "key_innovation": "Near-memory phase-domain computing with charge-discharge interleaving sensing scheme for ANNS on edge devices"
    },
    "page_images": [
      "images/30.6/page_1.png",
      "images/30.6/page_2.png",
      "images/30.6/page_3.png"
    ]
  },
  {
    "id": "30.7",
    "session": 30,
    "title": "A 1.2GHz 12.77GB/s/mm² 3D Two-DRAM-One-Logic Process-Near-Memory Chip for Edge LLM Applications",
    "title_zh": "1.2GHz 12.77GB/s/mm² 3D两层DRAM+一层逻辑近存芯片：边缘LLM应用",
    "title_annotation": {
      "segments": [
        {
          "text": "1.2GHz",
          "meaning": "1.2GHz工作频率",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "3D Two-DRAM-One-Logic",
          "meaning": "3D堆叠两层DRAM一层逻辑",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Process-Near-Memory",
          "meaning": "近存处理(PNM)",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Edge LLM",
          "meaning": "边缘端大语言模型",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "边缘LLM小批量推理受限于内存带宽瓶颈",
        "related_idea_idx": 0,
        "text_en": "Edge LLM small batch inference is limited by memory bandwidth bottleneck"
      },
      {
        "text": "DRAM工艺内集成计算逻辑能力受限",
        "related_idea_idx": 1,
        "text_en": "Computing logic capability is constrained when integrated within DRAM die due to DRAM process limitations"
      },
      {
        "text": "近存计算芯片难以兼容现有主机平台",
        "related_idea_idx": 2,
        "text_en": "Processing-near-memory chips are difficult to integrate with existing edge platforms"
      }
    ],
    "ideas": [
      {
        "text": "3D混合键合与mini-TSV实现高带宽密度互连",
        "type": "system",
        "color": "#3498db",
        "text_en": "3D HB + mini-TSV integration enables high-bandwidth density interconnect achieving 12.77GB/s/mm2 bandwidth density"
      },
      {
        "text": "逻辑与DRAM分离的两层DRAM一层逻辑架构",
        "type": "system",
        "color": "#3498db",
        "text_en": "Logic and DRAM decoupling architecture with two DRAM dies stacked with one logic die providing 1GB on-chip DRAM capacity"
      },
      {
        "text": "DDR4兼容接口与DMA辅助近存数据通路",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "DDR4-protocol-compatible interface with DMA-assisted near-memory datapath for flexible system integration"
      }
    ],
    "affiliation": "Fudan University",
    "authors": "Fudan University",
    "process_node": "28nm CMOS",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "12.77GB/s/mm²",
    "target_model": "LLM (Edge)",
    "application": "边缘LLM推理(PNM)",
    "innovations": [
      {
        "tag": "3D 2-DRAM-1-Logic堆叠",
        "type": "hw-arch"
      },
      {
        "tag": "混合键合+mini-TSV互连",
        "type": "hw-arch"
      },
      {
        "tag": "1GB片上DRAM容量",
        "type": "system"
      }
    ],
    "tags": [
      "PNM",
      "3D堆叠",
      "DRAM",
      "LLM",
      "边缘",
      "混合键合"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Client-side LLM application challenges and the presented 3D integrated near-DRAM computing design.",
        "path": "images/30.7/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall design architecture and the extended DDR4 command list. 525 30 show that the 3D near-memory architecture substantially reduces memory latency, beneﬁting latency-sensitive edge LLM workloads.",
        "path": "images/30.7/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Datapath and access timing for 3D DRAM, and dataﬂow and performance test for GEMM.",
        "path": "images/30.7/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Measurement system architecture and 3D DRAM measurement results.",
        "path": "images/30.7/fig_4.png"
      },
      {
        "num": 5,
        "caption": "D integration details, area and power breakdown, and design measurements.",
        "path": "images/30.7/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Comparison with prior works.",
        "path": "images/30.7/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrographs and design speciﬁcations.",
        "path": "images/30.7/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm CMOS",
      "frequency_mhz": "1200",
      "energy_efficiency": "12.77GB/s/mm²",
      "throughput": "1.2TFLOPS",
      "target_model": "LLM (Edge)",
      "source_figure": "fig_7"
    },
    "frequency_mhz": "1200",
    "data_path": "data/30.7/",
    "analytical_tags": [
      "3D堆叠/HBM",
      "片外访存优化",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "Fudan University",
      "name_zh": "复旦大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/fudan-university.svg"
    },
    "abstract": "A high-bandwidth-density (12.77GB/s/mm2) high-memory-density (99.4Mb/mm2) low- energy-consumption (0.67pJ/b) 3D PNM design that operates at 1.2GHz is presented. The design adopts a two-DRAM-one-logic architecture that enables near-DRAM computing through a high-density 3D integration path, reducing memory-access latency by up to 93% and GEMM execution time by up to 98%, demonstrating strong potential for edge-LLM workloads.",
    "metrics_detailed": {
      "technology": "Process-near-memory design with DRAM and logic stack",
      "memory_capacity": {
        "value": "1",
        "unit": "GB",
        "note": "on-chip DRAM capacity from two stacked DRAM dies"
      },
      "memory_density": {
        "value": "99.4",
        "unit": "Mb/mm2",
        "note": "DRAM memory density"
      },
      "frequency": {
        "value": "1.2",
        "unit": "GHz",
        "condition": "compute frequency on 28nm logic die"
      },
      "bandwidth": {
        "values": [
          {
            "value": "12.77",
            "unit": "GB/s/mm2",
            "condition": "bandwidth density via 3D HB + mini-TSV interconnect"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "1.2",
            "unit": "V",
            "condition": "measurement condition at 526Mbps"
          }
        ]
      },
      "dram_performance": {
        "values": [
          {
            "value": "526",
            "unit": "Mbps",
            "condition": "data rate at 1.2V"
          }
        ]
      },
      "energy_efficiency": {
        "value": "0.67",
        "unit": "pJ/b",
        "note": "memory energy efficiency, 9% of GDDR6 and 28% of HBM3E"
      },
      "memory_latency": {
        "values": [
          {
            "value": "3.21",
            "unit": "ns",
            "condition": "write latency for consecutive access"
          },
          {
            "value": "3.24",
            "unit": "ns",
            "condition": "read latency for consecutive access"
          },
          {
            "value": "45.12",
            "unit": "ns",
            "condition": "write latency for random access"
          },
          {
            "value": "50.01",
            "unit": "ns",
            "condition": "read latency for random access"
          }
        ]
      },
      "latency_reduction": {
        "values": [
          {
            "value": "90%",
            "unit": "reduction",
            "condition": "write latency vs scaled LPDDR4"
          },
          {
            "value": "93%",
            "unit": "reduction",
            "condition": "read latency vs scaled LPDDR4"
          }
        ]
      },
      "gemm_performance": {
        "values": [
          {
            "value": "86%",
            "unit": "execution time reduction",
            "condition": "128×128×128 GEMM vs Intel i7-13700F"
          },
          {
            "value": "98%",
            "unit": "execution time reduction",
            "condition": "when scaled to 8-chip DIMM with 8GB DRAM"
          }
        ]
      },
      "comparison": "FoM 7.33× higher than prior 3D PNM design; 5.13× higher than active-interposer design",
      "key_features": {
        "interconnect": "HB pitch=3μm, TSV pitch=5μm",
        "yield": "0.58% additional failure rate after 3D integration"
      }
    },
    "page_images": [
      "images/30.7/page_1.png",
      "images/30.7/page_2.png",
      "images/30.7/page_3.png"
    ]
  },
  {
    "id": "30.8",
    "session": 30,
    "title": "A 16nm 1Mb 1-to-8b-Configurable 444.21TOPS/W Fully Digital SRAM Compute-In-Memory Macro for Hybrid SNN-CNN Models",
    "title_zh": "16nm 1Mb 1~8b可配置444.21TOPS/W全数字SRAM存内计算宏：混合SNN-CNN模型",
    "title_annotation": {
      "segments": [
        {
          "text": "16nm 1Mb",
          "meaning": "16nm工艺 1Mb容量",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "1-to-8b-Configurable",
          "meaning": "1~8位精度可配置",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "444.21TOPS/W",
          "meaning": "能效444.21TOPS/W(SNN模式)",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Fully Digital SRAM CIM",
          "meaning": "全数字SRAM存内计算",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Hybrid SNN-CNN",
          "meaning": "混合脉冲-卷积神经网络",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "SNN与CNN双模式支持带来额外硬件开销",
        "related_idea_idx": 0,
        "text_en": "Extra hardware overhead for supporting both SNN and CNN modes"
      },
      {
        "text": "部分和存储与权重更新之间的面积能耗权衡",
        "related_idea_idx": 1,
        "text_en": "Area-energy trade-off between partial sum (PSUM) storage and weight (W) update"
      },
      {
        "text": "单一膜电位动态模型限制SNN模型灵活性",
        "related_idea_idx": 2,
        "text_en": "Single MPDB function limiting flexibility for diverse SNN models"
      }
    ],
    "ideas": [
      {
        "text": "SNN-CNN共享MAC电路的紧凑可重构架构",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Compact fully-digital SNN-CNN reconfigurable computing (CFD-SC-RC) architecture that shares SNN-CNN MAC circuit"
      },
      {
        "text": "部分和存储与权重复用优化数据映射方案",
        "type": "sw",
        "color": "#2ecc71",
        "text_en": "PSUM storage–weight reuse optimized data mapping (PS-WR-ODM) scheme"
      },
      {
        "text": "支持IF/LIF/IQIF多模式数字膜电位单元",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Digital multi-membrane potential dynamics behavior unit (DM-MPDBU) supporting IF/LIF/IQIF modes"
      }
    ],
    "affiliation": "NTHU",
    "authors": "NTHU",
    "process_node": "16nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "444.21TOPS/W",
    "target_model": "SNN-CNN Hybrid",
    "application": "混合SNN-CNN边缘AI",
    "innovations": [
      {
        "tag": "SNN-CNN可重构全数字CIM",
        "type": "hw-arch"
      },
      {
        "tag": "部分和-权重复用数据映射",
        "type": "hw-arch"
      },
      {
        "tag": "自适应模型精度选择",
        "type": "co-design"
      }
    ],
    "tags": [
      "CIM",
      "SRAM",
      "SNN",
      "CNN",
      "混合模型",
      "16nm"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Motivation and challenges for hybrid SNN-CNN SRAM-CIM.",
        "path": "images/30.8/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Structure of proposed SRAM-DCIM macro and CFD-SC-RC operation. 527 30 [7] H. Fujiwara et al., “A 3nm, 32.5TOPS/W, 55.0TOPS/mm2 and 3.78Mb/mm2 Fully- Digital Compute-in-Memory Macro Supporting INT12 × INT12 with a Parallel-MAC Architecture and Foundry 6T-SRAM Bit Cell,” ISSCC, pp.",
        "path": "images/30.8/fig_2.png"
      },
      {
        "num": 3,
        "caption": "CMDM-LCC and DM-MPDBU structure and operation.",
        "path": "images/30.8/fig_3.png"
      },
      {
        "num": 4,
        "caption": "PS-WR-ODM operational concept.",
        "path": "images/30.8/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Simulated performance of proposed schemes.",
        "path": "images/30.8/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and position chart.",
        "path": "images/30.8/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die micrograph and performance summary table.",
        "path": "images/30.8/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "16nm",
      "sram_kb": "2kb SRAM",
      "energy_efficiency": "444.21TOPS/W",
      "target_model": "SNN-CNN Hybrid",
      "source_figure": "fig_7"
    },
    "data_path": "data/30.8/",
    "analytical_tags": [
      "CIM",
      "视觉/CV",
      "学界"
    ],
    "affiliation_info": {
      "name": "NTHU",
      "name_zh": "国立清华大学",
      "type": "academia",
      "country": "中国台湾",
      "country_code": "CN",
      "logo": "assets/logos/nthu.svg"
    },
    "abstract": "We present a silicon-veriﬁed fully digital SRAM-CIM macro that supports multi-bit hybrid SNN-CNN processing. Key innovations include: (1) a compact CFD-SC-RC architecture that shares SNN-CNN MAC hardware to minimize area and energy overhead while enabling adaptive model and precision selection; and (2) a PS-WR-ODM scheme that balances partial- sum storage and weight-update energy. Fabricated in 16nm FinFET CMOS, the test chip achieves 444.21TOPS/W (1bIN-8bW-14bOUT, SNN) and 62.84TOPS/W (8bIN-8bW- 22bOUT, CNN).",
    "metrics_detailed": {
      "technology": "16nm FinFET CMOS",
      "die_area": {
        "value": "1",
        "unit": "Mb",
        "note": "SRAM-DCIM macro with 16 64kb banks"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.8",
            "unit": "V",
            "condition": "measurement condition"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "1.3",
            "unit": "ns",
            "condition": "MAC latency (TMAC) at 0.8V with 8bIN-8bW-22bOUT"
          }
        ]
      },
      "quantization": {
        "snn_mode": "1b input, 8b weight, 14b output",
        "cnn_mode": "8b input, 8b weight, 22b output"
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "444.21",
            "unit": "TOPS/W",
            "condition": "SNN mode with 1bIN-8bW-14bOUT"
          },
          {
            "value": "62.84",
            "unit": "TOPS/W",
            "condition": "CNN mode with 8bIN-8bW-22bOUT"
          }
        ]
      },
      "membrane_potential_modes": [
        {
          "name": "IF",
          "description": "integrate-and-fire mode for simple spike generation"
        },
        {
          "name": "LIF",
          "description": "leaky integrate-and-fire mode with leakage dynamics"
        },
        {
          "name": "IQIF",
          "description": "integer quadratic integrate-and-fire mode with nonlinear integration"
        }
      ],
      "comparison": "8.2× improvement in FoM3 (IN precision×W precision×energy efficiency) over prior works; first silicon-verified fully digital SRAM-CIM macro supporting multi-bit hybrid SNN-CNN",
      "key_features": {
        "architecture_reduction": "33% macro area reduction vs prior hybrid SNN-CNN CIM design",
        "energy_improvement": "2.31× energy efficiency improvement",
        "fom2_improvement": "5.48× FoM2 (inference accuracy×energy efficiency/(area×latency)) over baseline designs"
      }
    },
    "page_images": [
      "images/30.8/page_1.png",
      "images/30.8/page_2.png",
      "images/30.8/page_3.png"
    ]
  },
  {
    "id": "30.9",
    "session": 30,
    "title": "A 147TOPS/W 250TOPS/mm² Fully Synthesizable Digital Compute-in-Memory Accelerator Supporting INT8×INT8 in Intel 18A",
    "title_zh": "147TOPS/W 250TOPS/mm²全可综合数字存内计算加速器：Intel 18A工艺INT8×INT8",
    "title_annotation": {
      "segments": [
        {
          "text": "147TOPS/W 250TOPS/mm²",
          "meaning": "能效147TOPS/W 面积效率250TOPS/mm²",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Fully Synthesizable",
          "meaning": "全可综合(标准单元)",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Digital Compute-in-Memory",
          "meaning": "数字存内计算",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Intel 18A",
          "meaning": "Intel 18A先进工艺",
          "color": "#3498db",
          "type": "system"
        }
      ]
    },
    "challenges": [
      {
        "text": "零点量化扩展至9比特增加面积与功耗",
        "related_idea_idx": 0,
        "text_en": "Zero-point expansion to 9b increases area and power"
      },
      {
        "text": "Booth编码器开销限制低位宽下功耗收益",
        "related_idea_idx": 1,
        "text_en": "Booth encoder overhead limits power savings for low data bit widths"
      },
      {
        "text": "CIM中权重存储面积占比过大",
        "related_idea_idx": 2,
        "text_en": "Weight storage area occupies excessive proportion in CiM"
      }
    ],
    "ideas": [
      {
        "text": "无符号转有符号映射将9b乘法降至8b",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Unsigned-to-signed mapping reduces 9b multiplication to 8b"
      },
      {
        "text": "权重驻留Booth编码复用摊销编码器开销",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Stationary weight Booth encoding amortizes encoder overhead through reuse"
      },
      {
        "text": "高密度可中断12T多比特锁存器存储单元",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "High-density interruptible 12T multibit latch bitcell for storage"
      }
    ],
    "affiliation": "Intel",
    "authors": "Intel",
    "process_node": "Intel 18A",
    "die_area_mm2": "0.0856",
    "power_mw": "6.1",
    "energy_efficiency": "147TOPS/W",
    "target_model": "INT8 DNN",
    "application": "全可综合AI加速器",
    "innovations": [
      {
        "tag": "全可综合数字CIM",
        "type": "hw-arch"
      },
      {
        "tag": "Booth编码静态权重",
        "type": "hw-circuit"
      },
      {
        "tag": "Intel 18A工艺验证",
        "type": "system"
      }
    ],
    "tags": [
      "CIM",
      "可综合",
      "Intel 18A",
      "Booth",
      "INT8",
      "数字"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "DCiM accelerator organization supporting zero-point quantized 8b unsigned/ signed activation and weights.",
        "path": "images/30.9/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Radix-4 Booth encoded weights, interruptible 12T multibit latch storage with static 2:1 multiplexor read, S-bit compute, and modiﬁed Booth encoder.",
        "path": "images/30.9/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Intrinsic zero-point compute with unsigned-signed mapping within the DCiM dataﬂow.",
        "path": "images/30.9/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Area/power breakdown and weight storage area savings.",
        "path": "images/30.9/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Frequency, power, and energy efﬁciency measurements in Intel 18A technology.",
        "path": "images/30.9/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Power, performance, area summary, and comparison to prior work.",
        "path": "images/30.9/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Packaged Intel 18A test-chip photograph, die dimensions, and performance summary table.",
        "path": "images/30.9/fig_7.png"
      }
    ],
    "metrics": {
      "die_area_mm2": "0.0856",
      "supply_voltage": "1.1V",
      "frequency_mhz": "2620",
      "power_mw": "6.1",
      "energy_efficiency": "147TOPS/W",
      "throughput": "21.5TOPS,",
      "technology": "Intel 18A",
      "target_model": "INT8 DNN",
      "source_figure": "fig_7"
    },
    "supply_voltage": "1.1V",
    "frequency_mhz": "2620",
    "data_path": "data/30.9/",
    "analytical_tags": [
      "CIM",
      "业界"
    ],
    "affiliation_info": {
      "name": "Intel",
      "name_zh": "英特尔",
      "type": "industry",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/intel.svg"
    },
    "abstract": "A fully synthesizable DCiM on-die accelerator with 128 input channels, 32 output channels, and 2 weight sets, supporting zero-point-quantized INT8×INT8 computation, is fabricated in Intel 18A technology and occupies 0.0856mm2. The DCiM accelerator operates at 2.62GHz for a supply voltage of 1.1V, and 25°C, achieving a peak area-efﬁciency of 250TOPS/mm2. Robust operation of DCiM is maintained down to 400mV, 25°C, where it delivers a peak energy-efﬁciency of 147TOPS/W at 25% input activity, with a power consumption of 6.1mW.",
    "metrics_detailed": {
      "technology": "Intel 18A FinFET (GAA)",
      "die_area": {
        "value": "0.0856",
        "unit": "mm2",
        "note": "DCiM accelerator with 128 input channels, 32 output channels, 2 weight sets"
      },
      "frequency": {
        "values": [
          {
            "value": "2.62",
            "unit": "GHz",
            "condition": "at 1.1V and 25°C, maximum supply voltage"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "1.1",
            "unit": "V",
            "condition": "nominal operating voltage"
          },
          {
            "value": "0.4",
            "unit": "V",
            "condition": "minimum operating voltage at 25°C"
          }
        ]
      },
      "quantization": "INT8×INT8 with zero-point quantization",
      "throughput": {
        "values": [
          {
            "value": "21.5",
            "unit": "TOPS",
            "condition": "peak at 2.62GHz and 1.1V"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "147",
            "unit": "TOPS/W",
            "condition": "peak at 400mV, 25°C with 25% input activity and 50% weight sparsity"
          },
          {
            "value": "254",
            "unit": "TOPS/W",
            "condition": "at 400mV with 10% input activity"
          },
          {
            "value": "1.23",
            "unit": "W",
            "condition": "power consumption at peak throughput"
          },
          {
            "value": "6.1",
            "unit": "mW",
            "condition": "power consumption at 400mV, 25% input activity"
          },
          {
            "value": "3.5",
            "unit": "mW",
            "condition": "power consumption at 400mV, 10% input activity"
          }
        ]
      },
      "compute_density": {
        "values": [
          {
            "value": "250",
            "unit": "TOPS/mm2",
            "condition": "peak area efficiency at 1.1V and 25°C"
          }
        ]
      },
      "zero_point_quantization": {
        "unsigned_to_signed_mapping": "20% power reduction and 17% area reduction vs naive 9b×9b approach",
        "booth_encoding": "28% reduction in compute power via radix-4 Booth encoding of stationary weights"
      },
      "memory_optimization": {
        "weight_storage": "20% reduction via high-density multibit latch (12T) with 95.5% insertion ratio",
        "double_buffering": "allows concurrent weight update and compute with 32-cycle write window"
      },
      "comparison": "Best-in-class area efficiency (TOPS/mm2) and energy efficiency (TOPS/W) among recent state-of-the-art digital CIM designs",
      "key_features": {
        "synthesizable": "fully synthesizable design using Intel 18A standard cell library",
        "scalability": "voltage scalable from 1.1V down to 400mV",
        "portability": "enables technology node portability across foundries"
      }
    },
    "page_images": [
      "images/30.9/page_1.png",
      "images/30.9/page_2.png",
      "images/30.9/page_3.png"
    ]
  },
  {
    "id": "31.1",
    "session": 31,
    "title": "A 14.08-to-135.69Token/s ReRAM-on-Logic Stacked Outlier-Free Large-Language-Model Accelerator with Adaptive Parallel Speculative Decoding",
    "title_zh": "14.08~135.69Token/s ReRAM-on-Logic堆叠无异常值LLM加速器：自适应并行投机解码",
    "title_annotation": {
      "segments": [
        {
          "text": "ReRAM-on-Logic",
          "meaning": "将ReRAM直接堆叠在逻辑芯片上",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Outlier-Free",
          "meaning": "消除激活异常值",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "LLM Accelerator",
          "meaning": "大语言模型加速器",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Adaptive Parallel Speculative Decoding",
          "meaning": "自适应并行投机解码",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "FWHT旋转阵列面积开销大难以部署",
        "related_idea_idx": 0,
        "text_en": "Deep FWHT array required by varied dimensions in TLM occupies nearly 4.37× the area of a 4K INT8 MAC array, incurring heavy area overheads"
      },
      {
        "text": "边缘片上存储不足导致DLM频繁访存",
        "related_idea_idx": 1,
        "text_en": "Limited on-chip memory capacity in edge accelerators fails to buffer all DLM weights, forcing frequent EMA where constrained external bandwidth further exacerbates latency overheads"
      },
      {
        "text": "长草稿长度下投机解码拒绝率过高",
        "related_idea_idx": 2,
        "text_en": "At long DL, over 90% of draft tokens decoded from DLM are rejected by TLM, whose latency overhead outweighs the latency savings from reduced TLM EMA"
      }
    ],
    "ideas": [
      {
        "text": "分解FWHT局部旋转单元消除激活异常值",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Local rotation unit (LRU) that approximates global rotation by decomposing the deep FWHT into overlapped upper and lower low-cost 6-depth FWHTs removes activation outliers"
      },
      {
        "text": "ReRAM堆叠近存处理与块向量量化",
        "type": "system",
        "color": "#3498db",
        "text_en": "ReRAM-stacked process-near-memory (RS-PNM) architecture with blockwise vector quantization (BVQ) algorithm clusters DLM weights into block-level codebooks stored in high-density ReRAM"
      },
      {
        "text": "自适应并行投机解码与乱序调度器",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Adaptive parallel SD (APSD) scheme combines the low rejection ratio of short DL and the high accepted token yield of long DL with workload-decoupled out-of-order scheduler"
      }
    ],
    "affiliation": "HKUST",
    "authors": "HKUST",
    "process_node": "55nm",
    "die_area_mm2": "25",
    "power_mw": "",
    "energy_efficiency": "14.08-135.69 token/s",
    "target_model": "LLaMA-7B",
    "application": "LLM推理",
    "innovations": [
      {
        "tag": "ReRAM-on-Logic 3D堆叠",
        "type": "hw-arch"
      },
      {
        "tag": "自适应并行投机解码",
        "type": "sw"
      },
      {
        "tag": "分解FWHT无异常值量化",
        "type": "sw"
      }
    ],
    "tags": [
      "LLM",
      "ReRAM",
      "CIM",
      "3D堆叠",
      "投机解码",
      "量化"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Challenges raised by target and draft large language model (LLM) in speculative decoding (SD) and proposed solutions.",
        "path": "images/31.1/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture and three main features of the LLM accelerator with bumping-based ReRAM die on logic wafer face-to-face stacking technology.",
        "path": "images/31.1/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Local rotation unit (LRU) with proposed decomposed Fast Walsh- Hadamard Transform (FWHT) for outlier-free low-bit target LLM quantization.",
        "path": "images/31.1/fig_3.png"
      },
      {
        "num": 4,
        "caption": "ReRAM-stacked processing-near-memory (RS-PNM) architecture with blockwise vector quantization (BVQ) to avoid draft LLM external memory access (EMA).",
        "path": "images/31.1/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Adaptive parallel speculative decoding (APSD) with workload-decoupled out-of-order scheduler (WDOS) to achieve intra-chip parallel draft-and-verify with high resource utilization.",
        "path": "images/31.1/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison with state-of-the-art LLM accelerators.",
        "path": "images/31.1/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Die photos, speciﬁcations, 4-chip system, SEM/TEM images of the ReRAM-on-logic stacking interface/ReRAM chip, and ReRAM resistance distribution curve.",
        "path": "images/31.1/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "55nm",
      "sram_kb": "3.43MB SRAM",
      "power_mw": "49.54",
      "energy_efficiency": "14.08-135.69 token/s",
      "throughput": "2.33TOPS",
      "die_area_mm2": "25",
      "target_model": "LLaMA-7B",
      "source_figure": "fig_7"
    },
    "data_path": "data/31.1/",
    "analytical_tags": [
      "CIM",
      "3D堆叠/HBM",
      "量化",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "HKUST",
      "name_zh": "香港科技大学",
      "type": "academia",
      "country": "中国香港",
      "country_code": "CN",
      "logo": "assets/logos/hkust.svg"
    },
    "abstract": "This work presents a 55nm speculative decoding-based LLM accelerator with bumping- based face-to-face ReRAM-on-logic stacking technology. It features a local rotation unit for outlier-free low-bit quantization, a stacking-aware PNM architecture co-designed with blockwise vector quantization to reduce weight EMA overheads, and an adaptive parallel speculative decoding scheme with out-of-order scheduler for high resource and bandwidth utilization. Our chip achieves 14.08-to-135.69token/s and 4.46-to-7.17× speedup over vanilla speculative decoding.",
    "metrics_detailed": {
      "paper_id": "31.1",
      "title": "A 14.08-to-135.69Token/s ReRAM-on-Logic Stacked Outlier-Free Large-Language-Model Accelerator with Block-Clustered Weight-Compression and Adaptive Parallel-Speculative-Decoding",
      "technology": "55nm",
      "die_area": {
        "value": "logic die + 4 ReRAM dies",
        "unit": "mm²",
        "note": "stacked ReRAM-on-logic configuration"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.89-1.40",
            "unit": "V",
            "condition": "logic die"
          },
          {
            "value": "1.1",
            "unit": "V",
            "condition": "ReRAM die"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "63.5-285",
            "unit": "MHz",
            "condition": "logic die"
          },
          {
            "value": "100",
            "unit": "MHz",
            "condition": "ReRAM die"
          }
        ]
      },
      "memory": {
        "sram": {
          "value": "3.43",
          "unit": "MB",
          "note": "total on-chip SRAM: 64KB ISA buffer, 1MB weight buffer, 2MB global token buffer"
        },
        "reram": {
          "value": "8",
          "unit": "MB",
          "condition": "single chip",
          "note": "25.6GB/s bandwidth at 100MHz"
        },
        "reram_scaled": {
          "value": "32",
          "unit": "MB",
          "condition": "4-chip system",
          "note": "102.4GB/s total bandwidth"
        }
      },
      "peak_performance": {
        "value": "2.33",
        "unit": "TOPS",
        "condition": "at 285MHz, 1.40V"
      },
      "power": {
        "values": [
          {
            "value": "49.54",
            "unit": "mW",
            "condition": "per ReRAM die at 100MHz, 1.1V"
          }
        ]
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "123.41",
            "unit": "mJ/token",
            "condition": "LLaMA2-7B, MT-Bench, includes EMA"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "17.82",
            "unit": "tokens/s",
            "condition": "LLaMA2-7B decoding, high throughput point"
          },
          {
            "value": "14.08-135.69",
            "unit": "tokens/s",
            "condition": "range across different settings"
          }
        ]
      },
      "speedup": {
        "values": [
          {
            "value": "4.46-7.17",
            "unit": "x",
            "condition": "vs BF16 speculative decoding baseline"
          }
        ]
      },
      "energy_savings": {
        "values": [
          {
            "value": "3.74-4.85",
            "unit": "x",
            "condition": "vs BF16 speculative decoding baseline"
          },
          {
            "value": "32.6",
            "unit": "%",
            "condition": "system-level vs SOTA on LLaMA2-7B"
          }
        ]
      },
      "quantization": "W4A8 with local rotation unit for outlier elimination",
      "key_features": [
        "Local Rotation Unit (LRU) for outlier-free low-bit quantization",
        "ReRAM-stacked process-near-memory (RS-PNM) with blockwise vector quantization (BVQ)",
        "Adaptive parallel speculative decoding (APSD) with out-of-order scheduler",
        "3.82-3.93x speedup over vanilla speculative decoding"
      ],
      "model_benchmarks": [
        {
          "model": "LLaMA2-7B",
          "metric": "17.82 tokens/s",
          "dataset": "MT-Bench"
        }
      ]
    },
    "page_images": [
      "images/31.1/page_1.png",
      "images/31.1/page_2.png",
      "images/31.1/page_3.png"
    ]
  },
  {
    "id": "31.2",
    "session": 31,
    "title": "Revolver: Low-Bit GenAI Accelerator for Distilled-Model and CoT with Phase-Aware-Quantization and Mixed-Precision MAC",
    "title_zh": "Revolver：低位GenAI加速器(蒸馏模型+CoT)：阶段感知量化+混合精度MAC",
    "title_annotation": {
      "segments": [
        {
          "text": "Revolver",
          "meaning": "加速器代号",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Low-Bit GenAI",
          "meaning": "低位宽生成式AI",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Distilled-Model and CoT",
          "meaning": "蒸馏模型与思维链推理",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Phase-Aware-Quantization",
          "meaning": "阶段感知量化",
          "color": "#9b59b6",
          "type": "co-design"
        },
        {
          "text": "Mixed-Precision MAC",
          "meaning": "混合精度乘累加",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "多阶段精度需双份权重存储开销大",
        "related_idea_idx": 0,
        "text_en": "Multi-phase precision requires storing both high precision (HP) and low precision (LP) weights creating capacity overhead for duplicated weights"
      },
      {
        "text": "非2幂通道旋转需矩阵乘开销高",
        "related_idea_idx": 1,
        "text_en": "Non-Power-of-Two (PoT) channel sizes preclude direct fast-Hadamard-transform (FHT) and inflate compute/energy for separate rotation units"
      },
      {
        "text": "非对称组量化反量化FP逻辑面积大",
        "related_idea_idx": 2,
        "text_en": "Asymmetric + group quantization demands per-group FP logic to handle the scale factor (SF) and zero point (ZP) where its utilization in a bit-scalable MAC architecture drops"
      }
    ],
    "ideas": [
      {
        "text": "阶段感知精度选择与残差编码压缩权重",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Phase-aware Precision Selection (PAPS) with Multi-precision Residual Encoding (MPRE) for memory-efficient multi-precision support"
      },
      {
        "text": "局部旋转谐波对齐置换降低旋转开销",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Local Rotation with Harmonic Aligned Permutation (LR-HAP) for low-cost rotation unit design and SF precision reduction"
      },
      {
        "text": "切片整数反量化单元实现高效去量化",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Sliced Integer-based Dequantization Unit (SIDU) for efficient integer-based dequantization"
      }
    ],
    "affiliation": "KAIST",
    "authors": "KAIST",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "",
    "target_model": "LLM + Diffusion",
    "application": "生成式AI边缘推理",
    "innovations": [
      {
        "tag": "阶段感知量化(PAQ)",
        "type": "co-design"
      },
      {
        "tag": "混合精度MAC引擎",
        "type": "hw-arch"
      },
      {
        "tag": "蒸馏模型+CoT支持",
        "type": "sw"
      }
    ],
    "tags": [
      "GenAI",
      "量化",
      "CoT",
      "蒸馏",
      "混合精度",
      "LLM"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "GenAI model for edge and hardware challenges.",
        "path": "images/31.2/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall chip architecture of proposed Revolver. 535 31 without over-width datapaths.",
        "path": "images/31.2/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Concept of PAPS and MPRE with MP-Loader.",
        "path": "images/31.2/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Concept and implementation of LR-HAP and PUB.",
        "path": "images/31.2/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Details of quantization method and the SIDU.",
        "path": "images/31.2/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison table.",
        "path": "images/31.2/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and performance summary.",
        "path": "images/31.2/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "die_area_mm2": "20.25",
      "energy_efficiency": "13.73TOPS/W",
      "throughput": "32Gb/s",
      "target_model": "LLM + Diffusion",
      "source_figure": "fig_7"
    },
    "data_path": "data/31.2/",
    "analytical_tags": [
      "量化",
      "蒸馏/剪枝",
      "混合精度",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "KAIST",
      "name_zh": "韩国科学技术院",
      "type": "academia",
      "country": "韩国",
      "country_code": "KR",
      "logo": "assets/logos/kaist.svg"
    },
    "abstract": "Revolver is a low-bit GenAI accelerator that enables reasoning and multi-turn chat on edge devices under tight memory and power budgets. It introduces Phase-Aware Precision Selection (PAPS) with Multi-Precision Residual Encoding (MPRE) for memory-efﬁcient multi-phase execution, Local Rotation with Harmonic-Aligned Permutation (LR-HAP) for low-cost rotation, and a Sliced Integer-based Dequantization Unit (SIDU) for efﬁcient dequantization, achieving 3.99× energy savings and 2.10× speedup.",
    "metrics_detailed": {
      "paper_id": "31.2",
      "title": "Revolver: Low-Bit GenAI Accelerator for Distilled-Model and CoT with Phase-Aware-Quantization and Rotation-Based Integer-Scaled Group Quantization",
      "technology": "28nm CMOS",
      "die_area": {
        "value": "20.25",
        "unit": "mm²"
      },
      "supply_voltage": {
        "note": "standard CMOS operation"
      },
      "frequency": {
        "note": "implementation in 28nm process"
      },
      "memory": {
        "global_memory": {
          "value": "1.28",
          "unit": "MB"
        },
        "weight_buffer": {
          "value": "52",
          "unit": "KB",
          "note": "Multi-Precision Loader for dual-precision weights"
        }
      },
      "peak_performance": {
        "value": "13.73",
        "unit": "TOPS/W",
        "condition": "with LR-HAP and SIDU"
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "13.73",
            "unit": "TOPS/W",
            "condition": "peak efficiency"
          }
        ]
      },
      "speedup": {
        "values": [
          {
            "value": "2.46-3.99",
            "unit": "x",
            "condition": "LLMs with PAPS + LR-HAP"
          },
          {
            "value": "1.72-2.10",
            "unit": "x",
            "condition": "speedup on reasoning tasks with CoT"
          },
          {
            "value": "2.48-3.47",
            "unit": "x",
            "condition": "diffusion models"
          }
        ]
      },
      "energy_savings": {
        "values": [
          {
            "value": "50.4",
            "unit": "%",
            "condition": "overall system energy with PAPS + MPRE"
          },
          {
            "value": "52.4",
            "unit": "%",
            "condition": "weight EMA reduction"
          },
          {
            "value": "1.88-2.07",
            "unit": "x",
            "condition": "vs previous transformer accelerators"
          },
          {
            "value": "1.76-2.36",
            "unit": "x",
            "condition": "lower energy on LLM prefill and DM vs prior GenAI"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "1.68-2.05",
            "unit": "x",
            "condition": "faster LLM decoding vs prior GenAI processors"
          }
        ]
      },
      "quantization": "Mixed precision: W4A4, W4A8, W8A4, W8A8 with phase-aware precision selection",
      "weight_precision": "3-bit in decode stage",
      "hardware_features": [
        "Phase-Aware Precision Selection (PAPS) with Multi-Precision Residual Encoding (MPRE)",
        "Local Rotation with Harmonic Aligned Permutation (LR-HAP)",
        "Paired Unit-FHT Block (PUB)",
        "Sliced Integer-based Dequantization Unit (SIDU)"
      ],
      "rotation_optimization": {
        "power_reduction": "59.4%",
        "area_reduction": "60.8%"
      },
      "key_metrics": {
        "scale_factor_precision": "INT8 with LR-HAP",
        "sfpu_power_reduction": "45.1%",
        "sfpu_area_reduction": "43.1%",
        "agc_efficiency_improvement": "66.7%"
      }
    },
    "page_images": [
      "images/31.2/page_1.png",
      "images/31.2/page_2.png",
      "images/31.2/page_3.png"
    ]
  },
  {
    "id": "31.3",
    "session": 31,
    "title": "A 51.6μJ/Token Subspace-Rotation-Based Dual-Quantized Large-Language-Model Accelerator with Fused INT Pipeline",
    "title_zh": "51.6μJ/Token子空间旋转双量化LLM加速器：融合INT流水线",
    "title_annotation": {
      "segments": [
        {
          "text": "51.6μJ/Token",
          "meaning": "每token能耗51.6微焦",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Subspace-Rotation",
          "meaning": "子空间旋转(消除异常值)",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Dual-Quantized",
          "meaning": "权重+激活双量化",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Fused INT Pipeline",
          "meaning": "融合整数流水线",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "旋转算子占用PE阵列导致性能下降",
        "related_idea_idx": 0,
        "text_en": "The rotation operator occupying PE arrays leads to 40.1% performance degradation compared to the ideal case"
      },
      {
        "text": "组缩放和激活函数频繁中断INT流水",
        "related_idea_idx": 1,
        "text_en": "Group-wise scaling and embedded activation functions frequently interrupt the INT computation path requiring INT2FP conversions"
      },
      {
        "text": "位串行MAC利用率低能效不足",
        "related_idea_idx": 2,
        "text_en": "Bit-serial MAC units achieve only 40.3% PE utilization and 0.91× energy efficiency compared to conventional MAC units"
      }
    ],
    "ideas": [
      {
        "text": "子空间Hadamard变换独立于PE实现旋转",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Subspace Hadamard-Quantization transformation realizes the rotation operator outside the PE array with 59.7% area reduction and 62.3% power reduction"
      },
      {
        "text": "融合缩放-激活单元统一INT数据通路",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Fused Scale-Activation unit unifies group-scaling and element-wise activations in the INT domain reducing energy by 59.9% for scaling and 61.5% for activation functions"
      },
      {
        "text": "重排位切片LUT引擎提升精度可扩展能效",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Rearranged Bit-Slice LUT engine improves energy efficiency by up to 2.28× over conventional MAC units with theoretical precision scalability"
      }
    ],
    "affiliation": "Southeast University",
    "authors": "Southeast University",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "51.6μJ/token",
    "target_model": "LLaMA-7B/13B",
    "application": "LLM双量化推理",
    "innovations": [
      {
        "tag": "子空间旋转量化",
        "type": "sw"
      },
      {
        "tag": "融合INT端到端流水线",
        "type": "hw-arch"
      },
      {
        "tag": "双量化(权重+激活)加速",
        "type": "co-design"
      }
    ],
    "tags": [
      "LLM",
      "量化",
      "旋转",
      "INT",
      "流水线",
      "Hadamard"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Rotation-based dual-quantized LLM inference and three main challenges.",
        "path": "images/31.3/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture of the LLM accelerator. 537 31 the-art (SOTA) works focus on conventional transformer models or quantization deployment [11-14], our chip accelerates rotation-based dual-quantized LLMs with negligible accuracy loss (e.g., 0.56 at LLaMA2-7B), achieving 32.6% system-level energy savings compared to the SOTA on LLaMA2-7B [11].",
        "path": "images/31.3/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Subspace Hadamard quantization for rotation and its hardware details. Figure 31.3.4: Fused scale-activation for INT data path and its implementation.",
        "path": "images/31.3/fig_3.png"
      },
      {
        "num": 5,
        "caption": "Rearranged bit-slice LUT computation for precision ﬂexible PE.",
        "path": "images/31.3/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison with the state-of-the-art accelerators.",
        "path": "images/31.3/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip summary and detailed performance sheet.",
        "path": "images/31.3/fig_7.png"
      }
    ],
    "metrics": {
      "energy_efficiency": "51.6μJ/token",
      "technology": "28nm",
      "target_model": "LLaMA-7B/13B",
      "source_figure": "fig_7"
    },
    "data_path": "data/31.3/",
    "analytical_tags": [
      "量化",
      "LUT计算",
      "位串行",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "Southeast University",
      "name_zh": "东南大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/southeast-university.svg"
    },
    "abstract": "A 51.6μJ/token accelerator for rotation-based dual-quantized LLMs is presented. A subspace-rotation method with parallel Hadamard transposer reduces on-chip rotation power by 62.3% and area by 59.7%. A fused scale-activation unit lowers energy by 61.5% vs. the naive FP design. Rearranged bit-slice LUT computation achieves 2.28× better energy efﬁciency compared to a direct bit-parallel MAC implementation, while supporting ﬂexible bit-width. The chip reduces per-token energy by 32.6% over SOTA under an equal accuracy constraint.",
    "metrics_detailed": {
      "paper_id": "31.3",
      "title": "A 51.6μJ/Token Subspace-Rotation-Based Dual-Quantized Large-Language-Model Accelerator with Fused Scale-Activation INT Datapath and Rearranged Bit-Slice LUT Computation",
      "technology": "not specified (inferred 28nm from comparison context)",
      "energy_per_token": {
        "values": [
          {
            "value": "51.6",
            "unit": "μJ/token",
            "condition": "LLaMA2-7B, 1024 tokens"
          },
          {
            "value": "267.1",
            "unit": "μJ/token",
            "condition": "LLaMA3-8B best case"
          }
        ]
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.6-1.0",
            "unit": "V"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "up to 450",
            "unit": "MHz"
          }
        ]
      },
      "latency": {
        "values": [
          {
            "value": "2628",
            "unit": "ms",
            "condition": "LLaMA3-8B at best performance point, 1024 tokens"
          },
          {
            "value": "621",
            "unit": "ms",
            "condition": "at best efficiency point, 1024 tokens"
          }
        ]
      },
      "peak_performance": {
        "value": "118.6",
        "unit": "TOPS/W",
        "condition": "A4W4KV4 at 1.0V, LLaMA2-13B"
      },
      "energy_efficiency": {
        "values": [
          {
            "value": "118.6",
            "unit": "TOPS/W",
            "condition": "A4W4KV4, 1.0V, LLaMA2-13B"
          }
        ]
      },
      "energy_savings": {
        "values": [
          {
            "value": "32.6",
            "unit": "%",
            "condition": "system-level vs SOTA on LLaMA2-7B under equal accuracy"
          }
        ]
      },
      "component_speedup": {
        "values": [
          {
            "value": "1.41",
            "unit": "x",
            "condition": "SHQ contribution vs 4b baseline"
          },
          {
            "value": "1.92",
            "unit": "x",
            "condition": "FSA contribution"
          },
          {
            "value": "3.17",
            "unit": "x",
            "condition": "RBLUT contribution"
          }
        ]
      },
      "shq_rotation": {
        "area_reduction": "59.7%",
        "power_reduction": "62.3%",
        "operation_reduction_mha": "33.14%",
        "operation_reduction_ffn": "47.06%",
        "speedup": "1.74x"
      },
      "fsa_scale_activation": {
        "group_scaling_power_reduction": "59.9%",
        "activation_power_reduction": "61.5%"
      },
      "rblut_bit_slice": {
        "w2_energy_improvement": "1.75x",
        "w2_vs_parallel_improvement": "2.28x"
      },
      "quantization": "Rotation-based dual-quantized: W4A4, W4A8, W8A4, W8A8 with flexible bit-width",
      "accuracy": {
        "note": "0.56 perplexity loss at LLaMA2-7B, negligible accuracy loss"
      },
      "key_features": [
        "Subspace Hadamard Quantization (SHQ) for rotation",
        "Fused Scale-Activation (FSA) unit in INT domain",
        "Rearranged Bit-Slice LUT (RBLUT) engine",
        "Table size reduction: 66.7% with canonical patterns"
      ]
    },
    "page_images": [
      "images/31.3/page_1.png",
      "images/31.3/page_2.png",
      "images/31.3/page_3.png"
    ]
  },
  {
    "id": "31.4",
    "session": 31,
    "title": "VARSA: A Visual Autoregressive Generation Accelerator Using Performance-Scalable Multi-Precision PE-LUT and Sparse Attention",
    "title_zh": "VARSA：视觉自回归生成加速器(性能可扩展多精度PE-LUT+稀疏注意力)",
    "title_annotation": {
      "segments": [
        {
          "text": "VARSA",
          "meaning": "加速器代号",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Visual Autoregressive",
          "meaning": "视觉自回归生成",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Multi-Precision PE-LUT",
          "meaning": "多精度处理单元查找表",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "Sparse Attention",
          "meaning": "稀疏注意力",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "VAR逐步插值导致计算量急剧增长",
        "related_idea_idx": 0,
        "text_en": "VAR interpolation block expands patch number leading to increased computational operations with 171× operation-count increase"
      },
      {
        "text": "激活数据动态范围宽精度需求多变",
        "related_idea_idx": 1,
        "text_en": "Activation data requires wide value range with 190× spatial and 238× temporal variations leading to wide data-precision requirement"
      },
      {
        "text": "注意力KV缓存访存开销占比超60%",
        "related_idea_idx": 2,
        "text_en": "KV cache stores all previous patches causing attention layers to dominate memory cost by >60%"
      }
    ],
    "ideas": [
      {
        "text": "性能可扩展混合PE-LUT核适配计算需求",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Performance-scalable hybrid PE-LUT core with configurable performance to accommodate increased performance demand"
      },
      {
        "text": "运行时分布感知多精度并行处理",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Multi-precision parallel processing with runtime distribution-aware precision management for wide range of activation data"
      },
      {
        "text": "基于网格相似性的注意力图压缩方案",
        "type": "sw",
        "color": "#2ecc71",
        "text_en": "Attention map compression leveraging inter-grid similarity to reduce KV cache access"
      }
    ],
    "affiliation": "Peking University",
    "authors": "Peking University",
    "process_node": "22nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "",
    "target_model": "VAR (Visual Autoregressive)",
    "application": "视觉自回归图像生成",
    "innovations": [
      {
        "tag": "性能可扩展多精度PE-LUT",
        "type": "hw-arch"
      },
      {
        "tag": "稀疏注意力加速",
        "type": "sw"
      },
      {
        "tag": "VAR专用数据流",
        "type": "hw-arch"
      }
    ],
    "tags": [
      "VAR",
      "视觉自回归",
      "LUT",
      "稀疏",
      "注意力",
      "图像生成"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Architecture and deployment challenges of visual autoregressive model. Figure 31.4.2: Overall chip architecture of VARSA.",
        "path": "images/31.4/fig_1.png"
      },
      {
        "num": 3,
        "caption": "Performance-scalable hybrid PE-LUT core with efﬁcient dual-function LUTs.",
        "path": "images/31.4/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Multi-precision parallel processing and efﬁcient multi-precision LUTs.",
        "path": "images/31.4/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Inter-grid similarity in attention map and our compression scheme.",
        "path": "images/31.4/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison table.",
        "path": "images/31.4/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip photograph and more speciﬁcations.",
        "path": "images/31.4/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "22nm",
      "energy_efficiency": "33.45TOPS/W",
      "throughput": "0.435TOPS",
      "target_model": "VAR (Visual Autoregressive)",
      "source_figure": "fig_7"
    },
    "data_path": "data/31.4/",
    "analytical_tags": [
      "LUT计算",
      "稀疏化",
      "生成式AI",
      "学界"
    ],
    "affiliation_info": {
      "name": "Peking University",
      "name_zh": "北京大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/peking-university.svg"
    },
    "abstract": "This paper presents VARSA, a 22nm visual autoregressive accelerator for efﬁcient text-to- image generation, featuring: 1) a performance-scalable hybrid PE-LUT core; 2) multi-precision parallel processing with runtime precision management; 3) attention map compression leveraging inter-grid similarity. The innovations enable VARSA to achieve 503mJ/inference for 512×512 image generation, which is 2.7-to-8.9× better than prior diffusion-based SOTA accelerators.",
    "metrics_detailed": {
      "paper_id": "31.4",
      "title": "VARSA: A Visual Autoregressive Generation Accelerator Using Performance-Scalable Multi-Precision PE-LUT and Grid-Similarity Attention Compression",
      "technology": "22nm",
      "die_area": {
        "note": "chip photo shown in Fig. 31.4.7"
      },
      "target_application": "512×512 text-to-image generation",
      "supply_voltage": {
        "note": "standard 22nm CMOS operation"
      },
      "frequency": {
        "note": "variable based on precision and workload"
      },
      "peak_performance": {
        "values": [
          {
            "value": "0.435-6.96",
            "unit": "TOPS",
            "condition": "performance scaling range"
          }
        ]
      },
      "peak_energy_efficiency": {
        "value": "33.45",
        "unit": "TOPS/W",
        "condition": "W4A4"
      },
      "average_energy_efficiency": {
        "value": "18.38",
        "unit": "TOPS/W",
        "condition": "mixed precision"
      },
      "energy_per_inference": {
        "values": [
          {
            "value": "503",
            "unit": "mJ",
            "condition": "512×512 image generation including EMA"
          },
          {
            "value": "290.5",
            "unit": "mJ",
            "condition": "EMA-excluded efficiency vs [16]"
          }
        ]
      },
      "latency": {
        "values": [
          {
            "value": "1.92",
            "unit": "s",
            "condition": "512×512 image generation including EMA"
          }
        ]
      },
      "comparative_improvements": {
        "vs_diffusion_sota": {
          "energy": "2.7-8.9x",
          "latency": "3.8x",
          "references": "vs [16] and [17]"
        },
        "vs_ar_llm": {
          "energy_efficiency": "1.8x",
          "reference": "vs [19]"
        }
      },
      "speedup": {
        "values": [
          {
            "value": "2.3",
            "unit": "x",
            "condition": "overall speedup vs FP16 baseline"
          }
        ]
      },
      "energy_reduction": {
        "values": [
          {
            "value": "1.4",
            "unit": "x",
            "condition": "PE-LUT performance-scaling contribution"
          },
          {
            "value": "2.5",
            "unit": "x",
            "condition": "mixed-precision processing contribution"
          },
          {
            "value": "1.6",
            "unit": "x",
            "condition": "attention compression contribution"
          }
        ]
      },
      "quantization": "W4A4, W4A8, W4A12 with multi-precision support",
      "attention_compression": {
        "memory_savings": "40.5%",
        "compute_savings": "20.4%"
      },
      "pe_lut_design": {
        "dual_function_lut": "INT4×INT4 multiply or 128b data storage",
        "power_reduction_address_aware": "48.2%",
        "power_reduction_clock_gating": "38.8%-33.7%"
      },
      "multi_precision_tiles": {
        "tile_size": "16×8 elements",
        "precision_levels": 3,
        "precision_types": [
          "INT4",
          "INT8",
          "INT12"
        ]
      },
      "key_features": [
        "Performance-scalable PE-LUT core with 16x computational scaling",
        "Multi-precision parallel processing with runtime distribution-aware precision",
        "Attention map compression with inter-grid similarity exploitation",
        "Pattern-based compression: top-k sparsity and linear regression for diagonal patterns"
      ],
      "comparison_vs_baseline_fp16": {
        "energy_reduction": "2.3x",
        "mixed_precision_quality": "negligible FID degradation"
      }
    },
    "page_images": [
      "images/31.4/page_1.png",
      "images/31.4/page_2.png",
      "images/31.4/page_3.png"
    ]
  },
  {
    "id": "31.5",
    "session": 31,
    "title": "SoulMate: A 9.8mW Mobile Intelligence System-on-Chip with Mixed-Rank Architecture for On-Device LLM Personalization",
    "title_zh": "SoulMate：9.8mW移动智能SoC(混合秩架构实现设备端LLM个性化)",
    "title_annotation": {
      "segments": [
        {
          "text": "SoulMate",
          "meaning": "移动AI伴侣芯片",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "9.8mW",
          "meaning": "超低功耗9.8毫瓦",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Mixed-Rank Architecture",
          "meaning": "混合秩架构",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "On-Device LLM Personalization",
          "meaning": "设备端LLM个性化",
          "color": "#9b59b6",
          "type": "co-design"
        }
      ]
    },
    "challenges": [
      {
        "text": "RAG增强上下文使预填充延迟超标",
        "related_idea_idx": 0,
        "text_en": "RAG-augmented context makes prefill latency exceed standards"
      },
      {
        "text": "用户反馈微调中冗余梯度计算耗能高",
        "related_idea_idx": 1,
        "text_en": "Redundant gradient computation in user feedback fine-tuning consumes high energy"
      },
      {
        "text": "MXFP格式位稀疏性低计算功耗占比大",
        "related_idea_idx": 2,
        "text_en": "MXFP format's low bit sparsity causes high computation power consumption ratio"
      }
    ],
    "ideas": [
      {
        "text": "混合秩Token处理按重要性分配计算量",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Mixed-rank token processing allocates computation according to token importance"
      },
      {
        "text": "相似性感知序列处理跳过冗余梯度",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Similarity-aware sequence processing skips redundant gradients"
      },
      {
        "text": "布尔原语MX张量核降低浮点MAC功耗",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Boolean-primitive MX tensor core reduces floating-point MAC power"
      }
    ],
    "affiliation": "KAIST",
    "authors": "KAIST",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "9.8",
    "energy_efficiency": "9.8mW",
    "target_model": "LLaMA3.2-1B",
    "application": "移动端LLM个性化",
    "innovations": [
      {
        "tag": "混合秩推理/微调架构",
        "type": "hw-arch"
      },
      {
        "tag": "设备端RAG+LoRA个性化",
        "type": "co-design"
      },
      {
        "tag": "超低功耗移动LLM SoC",
        "type": "system"
      }
    ],
    "tags": [
      "LLM",
      "移动端",
      "个性化",
      "LoRA",
      "RAG",
      "低功耗"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Proposed mobile intelligence system and its design challenges.",
        "path": "images/31.5/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture. 541 31 [12-14]. Also, integrating SMU, MRNE, and BPMX reduces UA energy by 82.9%.",
        "path": "images/31.5/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Mixed-rank token processing with TMU and MRNE for UI latency reduction.",
        "path": "images/31.5/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Similarity-aware sequence processing with SMU for UA energy reduction.",
        "path": "images/31.5/fig_4.png"
      },
      {
        "num": 5,
        "caption": "BPMX tensor core for peak power reduction.",
        "path": "images/31.5/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison table.",
        "path": "images/31.5/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip photograph and performance summary.",
        "path": "images/31.5/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "die_area_mm2": "20.25",
      "sram_kb": "3.9MB \nof on-chip SRAM",
      "power_mw": "9.8",
      "energy_efficiency": "9.8mW",
      "throughput": "2.2TFLOPS",
      "target_model": "LLaMA3.2-1B",
      "source_figure": "fig_7"
    },
    "data_path": "data/31.5/",
    "analytical_tags": [
      "片外访存优化",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "KAIST",
      "name_zh": "韩国科学技术院",
      "type": "academia",
      "country": "韩国",
      "country_code": "KR",
      "logo": "assets/logos/kaist.svg"
    },
    "abstract": "This work presents SoulMate, a fully on-device mobile intelligence system-on-chip, integrating retrieval-augmented generation (RAG) and ﬁne tuning of a personal LLM. SoulMate is fabricated in 28nm CMOS with a novel mixed-rank token processing and similarity-aware sequence processing architecture. It demonstrates real-time user interaction consumining only 9.8-to-180.5mW power, and state-of-the-art energy efﬁciency, such as 26.3μJ/token for inference and 56.8μJ/token for ﬁne-tuning.",
    "metrics_detailed": {
      "paper_id": "31.5",
      "title": "SoulMate: A 9.8mW Mobile Intelligence System-on-Chip with Mixed-Rank Architecture for On-Device LLM Personalization",
      "technology": "28nm CMOS",
      "die_area": {
        "value": "20.25",
        "unit": "mm²"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.58-0.82",
            "unit": "V",
            "condition": "operating range"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "25",
            "unit": "MHz",
            "condition": "peak energy efficiency point"
          },
          {
            "value": "250",
            "unit": "MHz",
            "condition": "peak performance point"
          }
        ]
      },
      "peak_performance": {
        "value": "2.2",
        "unit": "TFLOPS",
        "condition": "at 250MHz, 0.82V"
      },
      "memory": {
        "on_chip_sram": {
          "value": "3.9",
          "unit": "MB"
        },
        "weight_buffer": {
          "value": "512",
          "unit": "KB",
          "note": "per MRNE"
        },
        "token_buffer": {
          "value": "64",
          "unit": "KB",
          "note": "per MRNE"
        },
        "output_buffer": {
          "value": "128",
          "unit": "KB",
          "note": "per MRNE"
        },
        "dialogue_database": {
          "value": "32",
          "unit": "MB",
          "condition": "off-chip for RAG"
        },
        "replay_buffer": {
          "value": "4",
          "unit": "MB",
          "condition": "off-chip for fine-tuning"
        }
      },
      "power": {
        "values": [
          {
            "value": "9.8",
            "unit": "mW",
            "condition": "peak energy efficiency point at 25MHz, 0.58V"
          },
          {
            "value": "180.5",
            "unit": "mW",
            "condition": "peak performance point"
          }
        ]
      },
      "energy_efficiency": {
        "inference": {
          "value": "26.3",
          "unit": "μJ/token",
          "condition": "LLaMA3.2-1B inference (UI)"
        },
        "fine_tuning": {
          "value": "56.8",
          "unit": "μJ/token",
          "condition": "LoRA-based fine-tuning (UA)"
        }
      },
      "latency": {
        "values": [
          {
            "value": "216.4",
            "unit": "ms",
            "condition": "time-to-first-token (TTFT) for UI"
          },
          {
            "value": "622.9",
            "unit": "ms",
            "condition": "UA latency"
          }
        ]
      },
      "ui_speedup": {
        "values": [
          {
            "value": "75.0-82.5",
            "unit": "%",
            "condition": "latency reduction from mixed-rank processing"
          }
        ]
      },
      "ua_improvements": {
        "energy_reduction": "61.7-76.2%",
        "latency_reduction": "70.7%"
      },
      "bpmx_core": {
        "peak_power_reduction": "66.1%",
        "area_overhead": "3.4%",
        "multiplier_power_reduction": "85.1%",
        "adder_power_reduction": "84.1%"
      },
      "quantization": "MXFP format: MXFP6 input, MXFP4 weight, MXFP8 gradient",
      "key_metrics": {
        "ui_energy_reduction_from_mixed_rank": "69.7-71.4%",
        "peak_rank_speedup": "3x halving operations"
      },
      "model": "LLaMA3.2-1B",
      "system_features": [
        "Mixed-rank token processing with Token Management Unit (TMU)",
        "Mixed-rank Neural Engine (MRNE) supporting token-wise weight ranks",
        "Similarity-aware sequence processing with Sequence Management Unit (SMU)",
        "Boolean-Primitive MX (BPMX) tensor core for FP MAC power reduction",
        "RAG integration: retrieval from 32MB dialogue history database",
        "On-device training: LoRA-based fine-tuning with user feedback"
      ],
      "context_length": "~1K tokens",
      "comparative_notes": "Only LLM/transformer processor with both inference and on-chip training support"
    },
    "page_images": [
      "images/31.5/page_1.png",
      "images/31.5/page_2.png",
      "images/31.5/page_3.png"
    ]
  },
  {
    "id": "31.6",
    "session": 31,
    "title": "Tri-Oracle: A 17.78μJ/Token Vision-Language Model Accelerator with Token-Attention-Weight Redundancy Prediction",
    "title_zh": "Tri-Oracle：17.78μJ/Token视觉语言模型加速器(Token-注意力-权重三重冗余预测)",
    "title_annotation": {
      "segments": [
        {
          "text": "Tri-Oracle",
          "meaning": "三重预言(三层冗余预测)",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "17.78μJ/Token",
          "meaning": "每token能耗17.78微焦",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Vision-Language Model",
          "meaning": "视觉语言模型(VLM)",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Token-Attention-Weight Redundancy",
          "meaning": "Token/注意力/权重三层冗余",
          "color": "#9b59b6",
          "type": "co-design"
        }
      ]
    },
    "challenges": [
      {
        "text": "高分辨率图像导致VLM令牌数量爆炸",
        "related_idea_idx": 0,
        "text_en": "High-resolution images cause exponential increase in VLM token count and computational load"
      },
      {
        "text": "注意力头冗余且GQA负载不均衡",
        "related_idea_idx": 1,
        "text_en": "Attention head redundancy with Streaming Heads accounting for 50-75% of all heads and GQA causing group-wise load imbalance"
      },
      {
        "text": "门控FFN产生大量近零值浪费计算",
        "related_idea_idx": 2,
        "text_en": "Gated FFN operations produce 70-90% near-zero or small near-zero values making corresponding weights redundant"
      }
    ],
    "ideas": [
      {
        "text": "基于符号位相似度的运行时令牌合并",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Runtime token merging based on sign-bit similarity estimation using XNOR gates and popcount modules"
      },
      {
        "text": "注意力头类型预测与集群负载均衡",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Attention head type prediction with Head Max & Intensity Unit and workload balancing across clusters"
      },
      {
        "text": "离群符号位近零值预测跳过FFN计算",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "SNZV-related weight prediction using Strip-wise SNZV Computation Unit to skip FFN computations and reduce external memory access"
      }
    ],
    "affiliation": "KAIST",
    "authors": "KAIST",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "17.78μJ/token",
    "target_model": "VLM (ViT + LLM)",
    "application": "视觉语言模型推理",
    "innovations": [
      {
        "tag": "三重冗余预测(Token/Attn/Weight)",
        "type": "co-design"
      },
      {
        "tag": "自适应注意力头负载均衡",
        "type": "hw-arch"
      },
      {
        "tag": "门控FFN权重跳过",
        "type": "sw"
      }
    ],
    "tags": [
      "VLM",
      "视觉语言",
      "冗余预测",
      "注意力",
      "GQA",
      "多模态"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Redundancies in Vision-Language Models (VLMs) and proposed solutions for efﬁcient on-device VLMs.",
        "path": "images/31.6/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture of Tri-Oracle. 543 31",
        "path": "images/31.6/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Details of the Token Merging Unit (TMU) for token-level redundancy.",
        "path": "images/31.6/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Details of the Attention Head Prediction Unit (AHPU) and workload balancing, for attention-level redundancy.",
        "path": "images/31.6/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Details of the Strip-wise SNZV Computation Unit (SSCU) for weight-level redundancy.",
        "path": "images/31.6/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and performance comparison table.",
        "path": "images/31.6/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip photograph and performance summary.",
        "path": "images/31.6/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "supply_voltage": "1.1V",
      "frequency_mhz": "580",
      "energy_efficiency": "17.78μJ/token",
      "target_model": "VLM (ViT + LLM)",
      "source_figure": "fig_7"
    },
    "supply_voltage": "1.1V",
    "frequency_mhz": "580",
    "data_path": "data/31.6/",
    "analytical_tags": [
      "稀疏化",
      "LLM/NLP",
      "视觉/CV",
      "学界"
    ],
    "affiliation_info": {
      "name": "KAIST",
      "name_zh": "韩国科学技术院",
      "type": "academia",
      "country": "韩国",
      "country_code": "KR",
      "logo": "assets/logos/kaist.svg"
    },
    "abstract": "This paper presents Tri-Oracle, a VLM accelerator exploiting token, attention, and weight redundancies. A Token Merging Unit (TMU) merges 68% of redundant tokens. An Attention Head Prediction Unit (AHPU) predicts streaming heads and skips them, reducing attention latency by 44% and balancing load. A Strip-wise SNZV Computation Unit (SSCU) predicts near-zero values, cutting FFN latency by 45% and EMA by 57%. Fabricated in 28nm CMOS, Tri-Oracle achieves 17.78μJ/token and 1.19 to 3.99TOPS/mm2 without ﬁne tuning.",
    "metrics_detailed": {
      "paper_id": "31.6",
      "title": "Tri-Oracle: A 17.78μJ/Token Vision-Language Model Accelerator with Token-Attention-Weight Redundancy Prediction",
      "technology": "28nm CMOS",
      "energy_per_token": {
        "value": "17.78",
        "unit": "μJ/token",
        "condition": "off-the-shelf without fine-tuning"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.75-1.1",
            "unit": "V"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "up to 580",
            "unit": "MHz"
          }
        ]
      },
      "area_efficiency": {
        "value": "1.19-3.99",
        "unit": "TOPS/mm²"
      },
      "energy_reduction": {
        "values": [
          {
            "value": "0.36-0.55",
            "unit": "x",
            "condition": "computation energy reduction vs baseline"
          },
          {
            "value": "0.53-0.67",
            "unit": "x",
            "condition": "EMA energy reduction vs baseline"
          }
        ]
      },
      "token_merging": {
        "reduction_ratio": "68%",
        "layer_latency_reduction": "67%",
        "area_overhead": "5.14%"
      },
      "attention_optimization": {
        "attention_latency_reduction": "44%",
        "from_head_prediction": "44%",
        "with_load_balancing": "19.2% additional improvement",
        "utilization_improvement": "24.6%",
        "area_overhead": "<1%"
      },
      "ffn_weight_prediction": {
        "gated_ffn_latency_reduction": "45%",
        "ema_reduction": "57%",
        "area_overhead": "2.3%"
      },
      "redundancy_exploitation": {
        "token_level": "68% reduction, 86% of tokens from high-res images are similar",
        "attention_level": "44% latency reduction, streaming heads account for 50-75% of heads",
        "weight_level": "45% FFN latency reduction, 70-90% near-zero values in gated FFN"
      },
      "models_evaluated": [
        {
          "model": "TinyLLaVA-v1",
          "task": "vision questioning"
        },
        {
          "model": "LLaVA-1.5",
          "task": "reasoning"
        }
      ],
      "comparison_vs_sota": {
        "energy_efficiency": "17.78 μJ/token",
        "area_overhead": "single-digit area overhead",
        "training_requirement": "off-the-shelf, no fine-tuning required",
        "vs_finetuned_methods": "comparable to methods requiring fine-tuning"
      },
      "key_components": [
        "Token Merging Unit (TMU): sign-bit similarity estimation",
        "Attention Head Prediction Unit (AHPU): head type classification",
        "Strip-wise SNZV Computation Unit (SSCU): near-zero value prediction",
        "Sign Magnitude-Similarity Estimation Unit (SMSE): shared across components"
      ],
      "sign_bit_operations": {
        "tmu_similarity": "XNOR gates with popcount for cosine similarity",
        "sscu_outlier_detection": "3-sigma criterion in RMSNorm for efficient outlier detection"
      },
      "memory_optimization": {
        "ssb_storage_reduction": "91%",
        "ssb_data_migration_reduction": "51%",
        "architectural_note": "Semantic Address Translator for physical address mapping"
      },
      "quantization": "Not explicitly quantization-specific, but inherent in redundancy prediction",
      "architectural_notes": "Off-the-shelf methodology requiring only minimal hardware support without specialized training"
    },
    "page_images": [
      "images/31.6/page_1.png",
      "images/31.6/page_2.png",
      "images/31.6/page_3.png"
    ]
  },
  {
    "id": "31.7",
    "session": 31,
    "title": "LUT-SSM: A 99.3TFLOPS/W LUT-Based State-Space Model Accelerator Using Energy-Efficient Element-Wise Layer Fusion",
    "title_zh": "LUT-SSM：99.3TFLOPS/W基于LUT的状态空间模型加速器(高效逐元素层融合)",
    "title_annotation": {
      "segments": [
        {
          "text": "LUT-SSM",
          "meaning": "基于查找表的SSM加速器",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "99.3TFLOPS/W",
          "meaning": "能效99.3TFLOPS/W",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "LUT-Based",
          "meaning": "查找表计算(替代乘法)",
          "color": "#e74c3c",
          "type": "hw-arch"
        },
        {
          "text": "State-Space Model",
          "meaning": "状态空间模型(Mamba等)",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "Element-Wise Layer Fusion",
          "meaning": "逐元素层融合",
          "color": "#e74c3c",
          "type": "hw-arch"
        }
      ]
    },
    "challenges": [
      {
        "text": "多对一LUT架构面积冗余写入低效",
        "related_idea_idx": 0,
        "text_en": "Many-to-one LUT architecture causes redundant area and costly write operations"
      },
      {
        "text": "SSM隐状态更新需顺序FP逐元素操作",
        "related_idea_idx": 1,
        "text_en": "SSM hidden-state update requires sequential FP-FP element-wise operations"
      },
      {
        "text": "列式量化引入额外缩放乘法开销",
        "related_idea_idx": 2,
        "text_en": "Column-wise quantization introduces extra scaling multiplication overhead"
      }
    ],
    "ideas": [
      {
        "text": "多对多LUT-ACC架构实现空间LUT复用",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Many-to-many LUT-ACC architecture enables spatial LUT reuse"
      },
      {
        "text": "基于LUT的逐元素层融合减少数据搬移",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "LUT-based element-wise layer fusion reduces data movement"
      },
      {
        "text": "缩放反映LUT生成器支持列式量化",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Scale-reflected LUT generator supports column-wise quantization"
      }
    ],
    "affiliation": "KAIST",
    "authors": "KAIST",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "99.3TFLOPS/W",
    "target_model": "Mamba/Samba/Hymba",
    "application": "SSM/Mamba模型推理",
    "innovations": [
      {
        "tag": "一对一LUT-ACC架构",
        "type": "hw-arch"
      },
      {
        "tag": "逐元素层融合",
        "type": "hw-arch"
      },
      {
        "tag": "列量化缩放支持",
        "type": "sw"
      }
    ],
    "tags": [
      "SSM",
      "Mamba",
      "LUT",
      "状态空间",
      "层融合",
      "能效"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Motivation and challenges in designing a state-space model (SSM) accelerator with weight-only quantization.",
        "path": "images/31.7/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture of the LUT-SSM with many-to-many LUT-based PEs (MM-LPEs) supporting INT–FP matrix multiplication.",
        "path": "images/31.7/fig_2.png"
      },
      {
        "num": 3,
        "caption": "LUT reuse scheme of MM-LPE, and LUT stationary dataﬂows for different weight shapes in the SSM block.",
        "path": "images/31.7/fig_3.png"
      },
      {
        "num": 4,
        "caption": "LUT-based layer fusion and reusable elementwise multiplications for two FP–FP operation types in the MM-LPE.",
        "path": "images/31.7/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Implementation details of the scale-reﬂected LUT generator to support LUT-friendly column-wise quantization, and mixed-precision evaluation.",
        "path": "images/31.7/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results and comparison table.",
        "path": "images/31.7/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and performance summary of LUT-SSM, including a comparison with previous Mamba accelerators.",
        "path": "images/31.7/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "energy_efficiency": "99.3TFLOPS/W",
      "target_model": "Mamba/Samba/Hymba",
      "source_figure": "fig_7"
    },
    "data_path": "data/31.7/",
    "analytical_tags": [
      "LUT计算",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "KAIST",
      "name_zh": "韩国科学技术院",
      "type": "academia",
      "country": "韩国",
      "country_code": "KR",
      "logo": "assets/logos/kaist.svg"
    },
    "abstract": "State-space models (SSMs) and weight-only quantization alleviate huge external memory access with a minimal accuracy degradation. To support both efﬁciently, we propose LUT- SSM, a LUT-based SSM accelerator with a many-to-many LUT-ACC and an element-wise (EW) layer fusion. LUT-SSM efﬁciently supports INT-FP GEMM and sequential EW operations in the SSM blocks. Fabricated in 28nm FD-SOI, LUT-SSM achieves 99.3TFLOPS/W peak efﬁciency and 96.1TFLOPS/W on Mamba 1.4B, improving energy efﬁciency by 1.28× over recent designs.",
    "metrics_detailed": {
      "paper_id": "31.7",
      "title": "LUT-SSM: A 99.3TFLOPS/W LUT-Based State-Space Model Accelerator Using Energy-Efficient Element-Wise Layer Fusion and LUT-Friendly Weight-Only Quantization",
      "technology": "28nm FD-SOI",
      "die_area": {
        "value": "16.0",
        "unit": "mm²"
      },
      "supply_voltage": {
        "value": "1.0",
        "unit": "V"
      },
      "frequency": {
        "value": "200",
        "unit": "MHz"
      },
      "power": {
        "values": [
          {
            "value": "54.46",
            "unit": "mW",
            "condition": "at 1.0V, 200MHz"
          }
        ]
      },
      "peak_energy_efficiency": {
        "value": "99.3",
        "unit": "TFLOPS/W",
        "condition": "peak efficiency"
      },
      "model_efficiency": {
        "value": "96.1",
        "unit": "TFLOPS/W",
        "condition": "Mamba-1.4B with 4-bit quantization"
      },
      "latency": {
        "values": [
          {
            "value": "0.55",
            "unit": "s/token",
            "condition": "Mamba model inference"
          }
        ]
      },
      "comparative_improvements": {
        "vs_a100": "faster than NVIDIA A100 for Mamba models",
        "vs_prior_designs": {
          "energy_efficiency_vs_design_10": "3.92x",
          "energy_efficiency_vs_design_11": "1.28x",
          "energy_efficiency_vs_design_12": "1.12x"
        }
      },
      "quantization": "Weight-only quantization (W3-W4 mixed-precision), FP16 activations, INT weights",
      "precision_modes": [
        "W3/W4 mixed-precision quantization",
        "Layer-wise mixed-precision support"
      ],
      "mm_lpe_optimization": {
        "power_reduction": "72.3%",
        "area_reduction": "62.8%",
        "core_energy_reduction": "28.5%",
        "vs_many_to_one": "comparison baseline"
      },
      "dataflow_optimization": {
        "soli_energy_improvement": "42%",
        "losi_energy_improvement": "18%",
        "note": "weight shape-aware LUT-stationary dataflows"
      },
      "ew_layer_fusion": {
        "on_chip_energy_reduction": "40%",
        "ema_reduction": "73%",
        "vs_simd_architecture": "comparison baseline"
      },
      "sr_lut_generator": {
        "power_increase": "42%",
        "vs_straightforward_implementation": "baseline comparison",
        "overall_energy_reduction": "31%",
        "support": "column-wise group quantization with 4 FP multipliers"
      },
      "key_features": [
        "Many-to-Many LUT-based Processing Elements (MM-LPEs)",
        "Scale-Reflected LUT (SR-LUT) generator for column-wise quantization",
        "Element-wise layer fusion for sequential FP-FP operations",
        "LUT-friendly weight-only quantization"
      ],
      "model_architecture": "Mamba-1.4B",
      "accuracy_notes": "Perplexity trade-off evaluation with mixed-precision quantization",
      "computational_support": [
        "INT-FP matrix multiplication (GEMM/GEMV)",
        "Sequential floating-point element-wise operations",
        "State update loops in SSM blocks"
      ]
    },
    "page_images": [
      "images/31.7/page_1.png",
      "images/31.7/page_2.png",
      "images/31.7/page_3.png"
    ]
  },
  {
    "id": "31.8",
    "session": 31,
    "title": "A 28nm Speculative-Decoding LLM Processor Achieving 105-to-685μs/Token Latency for Billion-Parameter Models",
    "title_zh": "28nm投机解码LLM处理器：十亿参数模型105~685μs/Token延迟",
    "title_annotation": {
      "segments": [
        {
          "text": "28nm",
          "meaning": "28nm工艺",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Speculative-Decoding",
          "meaning": "投机解码",
          "color": "#2ecc71",
          "type": "sw"
        },
        {
          "text": "LLM Processor",
          "meaning": "大语言模型处理器",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "105-to-685μs/Token",
          "meaning": "每token延迟105~685微秒",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Billion-Parameter",
          "meaning": "十亿参数量级",
          "color": "#2ecc71",
          "type": "sw"
        }
      ]
    },
    "challenges": [
      {
        "text": "草稿模型重复令牌产生指数位冗余",
        "related_idea_idx": 0,
        "text_en": "The draft model incurs implicit exponent redundancy from duplicate tokens"
      },
      {
        "text": "目标模型含大量低效权重与KV缓存",
        "related_idea_idx": 1,
        "text_en": "The target model contains inefficient weights and KV cache"
      },
      {
        "text": "草稿-验证串行执行导致硬件利用率低",
        "related_idea_idx": 2,
        "text_en": "The SD suffers from dual hardware underutilization"
      }
    ],
    "ideas": [
      {
        "text": "指数双重复用MAC节省浮点运算能耗",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "An exponent dual-reuse MAC (EDRM) compute engine reuses the exponent addition in the multiplier and the exponent alignment logic in accumulators for duplicate tokens related vectors"
      },
      {
        "text": "草稿反向传播指导目标模型混合精度",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "A draft back-propagation target mixed-precision (DBTM) dataflow performs back-propagation on the draft model to obtain weight/KV gradients"
      },
      {
        "text": "草稿提前启动实现草稿验证并行计算",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "A draft early start parallel compute (DEPC) utilizes layer-wise verification results to start the draft model early, enabling draft-verify parallel computing"
      }
    ],
    "affiliation": "Tsinghua University",
    "authors": "Tsinghua University",
    "process_node": "28nm",
    "die_area_mm2": "",
    "power_mw": "",
    "energy_efficiency": "105-685μs/token",
    "target_model": "TinyLLaMA 1B / Llama 13B",
    "application": "LLM投机解码推理",
    "innovations": [
      {
        "tag": "指数去重共享MAC",
        "type": "hw-arch"
      },
      {
        "tag": "树注意力剪枝",
        "type": "sw"
      },
      {
        "tag": "投机解码专用处理器",
        "type": "system"
      }
    ],
    "tags": [
      "LLM",
      "投机解码",
      "指数去重",
      "树注意力",
      "草稿模型",
      "28nm"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Speculative decoding LLM achieves performance advantages with rapid drafting and parallel veriﬁcation, but suffers from three challenges.",
        "path": "images/31.8/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Overall architecture of the proposed energy-efﬁcient speculative decoding LLM processor for billion-scale LLM applications with three key features.",
        "path": "images/31.8/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Exponent Dual-Reuse MAC (EDRM) for saving MAC energy by reusing exponent processing of semantically identical, but positionally distinct tokens.",
        "path": "images/31.8/fig_3.png"
      },
      {
        "num": 4,
        "caption": "Draft Back-propagation Target Mixed-precision (DBTM) for reducing cost of the inefﬁcient weights and KV cache identiﬁed by gradients of draft model.",
        "path": "images/31.8/fig_4.png"
      },
      {
        "num": 5,
        "caption": "Draft Early-start Parallel Compute (DEPC) for improving hardware utilization by early start draft decoding in parallel with target veriﬁcation.",
        "path": "images/31.8/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Measurement results of the SD LLM processor for billion-scale models and performance comparison with state-of-the-art LLM processors.",
        "path": "images/31.8/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Chip micrograph and performance summary.",
        "path": "images/31.8/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "28nm",
      "energy_efficiency": "105-685μs/token",
      "target_model": "TinyLLaMA 1B / Llama 13B",
      "source_figure": "fig_7"
    },
    "data_path": "data/31.8/",
    "analytical_tags": [
      "稀疏化",
      "LLM/NLP",
      "学界"
    ],
    "affiliation_info": {
      "name": "Tsinghua University",
      "name_zh": "清华大学",
      "type": "academia",
      "country": "中国大陆",
      "country_code": "CN",
      "logo": "assets/logos/tsinghua-university.svg"
    },
    "abstract": "LLMs face decoding bottlenecks. Speculative Decoding (SD) reduces latency via a small draft model for serial decoding and a large target model to verify in parallel. Despite this advantage, it still suffers from exponent redundancy, inefﬁcient weights/KV, and hardware underutilization. We propose an SD LLM processor with three innovations: an exponent dual-reuse MAC, draft back-propagation target mixed-precision dataﬂow, and draft early start parallel compute, achieving 10.29× speed increase.",
    "metrics_detailed": {
      "paper_id": "31.8",
      "title": "A 28nm Speculative-Decoding LLM Processor Achieving 105-to-685μs/Token Latency for Billion-Parameter Models",
      "technology": "28nm CMOS",
      "die_area": {
        "value": "56.82",
        "unit": "mm²"
      },
      "supply_voltage": {
        "values": [
          {
            "value": "0.58-1.0",
            "unit": "V"
          }
        ]
      },
      "frequency": {
        "values": [
          {
            "value": "180-550",
            "unit": "MHz"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "129.8-887.6",
            "unit": "mW",
            "condition": "operating range"
          }
        ]
      },
      "peak_energy_efficiency": {
        "value": "109.7",
        "unit": "TFLOPS/W",
        "condition": "at FP8, 0.68V, 300MHz"
      },
      "baseline_performance": {
        "value": "4.5",
        "unit": "TFLOPS",
        "condition": "at FP16, 550MHz"
      },
      "latency": {
        "values": [
          {
            "value": "105-685",
            "unit": "μs/token",
            "condition": "token-to-token latency range"
          }
        ]
      },
      "model_latencies": {
        "values": [
          {
            "model": "Gemma-3-1B",
            "latency_reduction": "9.97x",
            "condition": "token-to-token latency"
          },
          {
            "model": "Phi-2-2.7B",
            "latency_reduction": "10.08x"
          },
          {
            "model": "Llama-2-7B",
            "latency_reduction": "10.29x"
          }
        ]
      },
      "comparative_improvements": {
        "vs_prior_work_15": {
          "energy_efficiency": "2.29x"
        },
        "vs_prior_work_6": {
          "energy_efficiency": "1.24x",
          "speedup": "3.04x"
        }
      },
      "edrm_optimization": {
        "mac_energy_reduction": "30.1%",
        "exponent_processing_reduction": "63.8%",
        "mac_power_from_exponent": "69.8% of total"
      },
      "dbtm_optimization": {
        "inefficient_weight_kv_reduction": "74.9%",
        "throughput_improvement": "2.2-2.5x",
        "speedup": "2.35x"
      },
      "depc_optimization": {
        "throughput_improvement": "1.49-1.89x",
        "peak_throughput_improvement": "1.69x"
      },
      "quantization": "FP8 for draft model, FP16/BF16 for target model, mixed-precision with pruning",
      "speculative_decoding_parameters": {
        "draft_model": "1B-scale",
        "target_model": "Billion-parameter scale",
        "size_ratio": "10-20x smaller draft vs target",
        "draft_length": "N typically 4-6",
        "top_k_candidates": "k typically 2-3"
      },
      "duplicate_token_statistics": {
        "duplicate_ratio": "39.5%",
        "exponent_duplicate_ratio": "95.7%"
      },
      "target_model_inefficiency": {
        "inefficient_heads_weights": "78.3%",
        "inefficient_kv_entries": "78.3%"
      },
      "hardware_utilization": {
        "draft_mac_underutilization": "76.7%",
        "target_bandwidth_underutilization": "49.7%"
      },
      "key_features": [
        "Exponent Dual-Reuse MAC (EDRM) for duplicate token handling",
        "Draft Back-propagation Target Mixed-precision (DBTM) dataflow",
        "Draft Early-start Parallel Compute (DEPC) for improved utilization",
        "Layer-wise early stopping with 4 successive layer consistency"
      ],
      "gradient_analysis": {
        "near_zero_gradients": "86.7%",
        "distribution_levels": "1-level even, 2-level, 3-level"
      }
    },
    "page_images": [
      "images/31.8/page_1.png",
      "images/31.8/page_2.png",
      "images/31.8/page_3.png"
    ]
  },
  {
    "id": "31.9",
    "session": 31,
    "title": "ALPhA-Vision: A Real-Time Always-On Vision Processor with 787μs Face Detection Latency in <5mW",
    "title_zh": "ALPhA-Vision：实时常开视觉处理器(人脸检测787μs延迟 <5mW功耗)",
    "title_annotation": {
      "segments": [
        {
          "text": "ALPhA-Vision",
          "meaning": "常开低功耗视觉加速器",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "Always-On",
          "meaning": "常开(持续运行)",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "787μs Face Detection",
          "meaning": "人脸检测延迟787微秒",
          "color": "#3498db",
          "type": "system"
        },
        {
          "text": "<5mW",
          "meaning": "功耗低于5毫瓦",
          "color": "#3498db",
          "type": "system"
        }
      ]
    },
    "challenges": [
      {
        "text": "GPU边缘SoC功耗过高无法常开视觉",
        "related_idea_idx": 0,
        "text_en": "GPU-based edge SoCs high power consumption (≥10W) limits their utility for AoV applications"
      },
      {
        "text": "非GEMM操作成为端到端推理延迟瓶颈",
        "related_idea_idx": 1,
        "text_en": "A long tail of operations with low compute intensity would dominate the remaining runtime and bottleneck low-latency execution"
      },
      {
        "text": "高性能工艺SRAM漏电主导常开功耗",
        "related_idea_idx": 2,
        "text_en": "SRAM leakage is a large component of overall power consumption in standard high-performance process"
      },
      {
        "text": "模型过大需外部存储访问增加功耗",
        "related_idea_idx": 3,
        "text_en": "Models too large requiring external memory access increases power consumption"
      }
    ],
    "ideas": [
      {
        "text": "竞速休眠低功耗子系统独立于主SoC",
        "type": "system",
        "color": "#3498db",
        "text_en": "Race to sleep low-power subsystem operates independently from the main SoC enabling the rest of the SoC to sleep"
      },
      {
        "text": "近存储向量处理器加速非GEMM操作",
        "type": "hw-arch",
        "color": "#e74c3c",
        "text_en": "Near-memory processor (NMP) dedicated to low-compute-intensity kernels accelerates non-GEMM operations"
      },
      {
        "text": "细粒度SRAM分组电源门控降低漏电",
        "type": "hw-circuit",
        "color": "#e67e22",
        "text_en": "Fine-grained SRAM bank-level power gating with independent retention and sleep modes reduces leakage power"
      },
      {
        "text": "HW/SW协同设计QAT实现全片上执行",
        "type": "co-design",
        "color": "#9b59b6",
        "text_en": "Hardware-software codesign with quantization-aware training (QAT) enables end-to-end localized processing without accessing external memory"
      }
    ],
    "affiliation": "Nvidia",
    "authors": "Nvidia",
    "process_node": "16nm",
    "die_area_mm2": "",
    "power_mw": "5",
    "energy_efficiency": "<5mW",
    "target_model": "CNN + ViT",
    "application": "常开视觉(人脸检测/手势)",
    "innovations": [
      {
        "tag": "常开低功耗视觉子系统",
        "type": "system"
      },
      {
        "tag": "非GEMM操作硬件加速",
        "type": "hw-arch"
      },
      {
        "tag": "全栈编译器流程",
        "type": "co-design"
      }
    ],
    "tags": [
      "常开视觉",
      "低功耗",
      "人脸检测",
      "CNN",
      "ViT",
      "移动端"
    ],
    "figures": [
      {
        "num": 1,
        "caption": "Motivation and high-level design principles for the ALPhA-Vision subsystem.",
        "path": "images/31.9/fig_1.png"
      },
      {
        "num": 2,
        "caption": "Block diagram of the ALPhA-Vision architecture. 549 31 using just 21% of active cycles.",
        "path": "images/31.9/fig_2.png"
      },
      {
        "num": 3,
        "caption": "Overview of power-saving features in the ALPhA-Vision subsystem.",
        "path": "images/31.9/fig_3.png"
      },
      {
        "num": 4,
        "caption": "The ALPhA-Vision application software ﬂow and impact of quantization of Yolov5 face detection.",
        "path": "images/31.9/fig_4.png"
      },
      {
        "num": 5,
        "caption": "ALPhA-Vision measurement results on end-to-end Yolov5 face detection at 60fps.",
        "path": "images/31.9/fig_5.png"
      },
      {
        "num": 6,
        "caption": "Comparison table. All measurements for this work report full system power, including leakage power.",
        "path": "images/31.9/fig_6.png"
      },
      {
        "num": 7,
        "caption": "Annotated die plot and evaluation summary of DNN inference kernels (50% weight/activation sparsity).",
        "path": "images/31.9/fig_7.png"
      }
    ],
    "metrics": {
      "technology": "16nm",
      "sram_kb": "2.125MB of SRAM",
      "frequency_mhz": "359",
      "power_mw": "5",
      "energy_efficiency": "<5mW",
      "throughput": "36GOPS",
      "target_model": "CNN + ViT",
      "source_figure": "fig_7"
    },
    "frequency_mhz": "359",
    "data_path": "data/31.9/",
    "analytical_tags": [
      "视觉/CV",
      "业界"
    ],
    "affiliation_info": {
      "name": "Nvidia",
      "name_zh": "英伟达",
      "type": "industry",
      "country": "美国",
      "country_code": "US",
      "logo": "assets/logos/nvidia.svg"
    },
    "abstract": "ALPhA-Vision is an always-on low-power subsystem for DNN-inference-based vision tasks in edge SoCs. Flexible and programmable, the subsystem supports CNN and ViT inference and employs hardware/software co-design to enable fully end-to-end execution with no external memory accesses. Fine-grained power management features to mitigate leakage enable the subsystem to perform face detection with 787μs latency and 99.3% detection accuracy with 4.6mW average power at 60fps.",
    "metrics_detailed": {
      "paper_id": "31.9",
      "title": "ALPhA-Vision: A Real-Time Always-On Vision Processor with 787μs Face Detection Latency in <5mW",
      "technology": "16nm FinFET",
      "die_area": {
        "value": "4.20",
        "unit": "mm²"
      },
      "supply_voltage": {
        "value": "0.6",
        "unit": "V",
        "condition": "measurement point"
      },
      "frequency": {
        "value": "359",
        "unit": "MHz",
        "condition": "logic core"
      },
      "frequency_riscv": {
        "value": "718",
        "unit": "MHz",
        "condition": "RISC-V processor double-clock mode"
      },
      "latency": {
        "values": [
          {
            "value": "787",
            "unit": "μs",
            "condition": "face detection (Yolov5) at 0.6V, 359MHz"
          }
        ]
      },
      "throughput": {
        "values": [
          {
            "value": "1270",
            "unit": "fps",
            "condition": "peak throughput"
          },
          {
            "value": "60",
            "unit": "fps",
            "condition": "realistic use case operating point"
          }
        ]
      },
      "power": {
        "values": [
          {
            "value": "4.6",
            "unit": "mW",
            "condition": "average at 60fps with 95.3% sleep time"
          },
          {
            "value": "1.8",
            "unit": "mW",
            "condition": "unavoidable leakage with clocks halted"
          }
        ]
      },
      "sleep_mode_savings": {
        "active_energy_reduction": "21%",
        "sleep_energy_reduction": "94%",
        "active_energy_savings_from_kernels": "10%"
      },
      "frame_sleep_ratio": {
        "value": "95.3%",
        "condition": "at 60fps"
      },
      "memory": {
        "total_sram": {
          "value": "2.125",
          "unit": "MB"
        },
        "global_weight_memory": {
          "value": "16 banks",
          "bandwidth": "68 B/cycle read"
        },
        "global_scratchpad": {
          "value": "64 banks",
          "bandwidth": "136 B/cycle read, 65 B/cycle write"
        }
      },
      "model_footprints": {
        "model": "Yolov5n-0.5",
        "weight_memory": "318 KB",
        "activation_memory": "461 KB",
        "note": "fully on-chip, no external memory access"
      },
      "accuracy": {
        "face_detection_accuracy": "99.3%",
        "dataset": "WiderFace",
        "test_input": "192×192 grayscale"
      },
      "accelerator_compute": {
        "dla_mac_throughput": "1024",
        "unit": "MACs/cycle (INT8)",
        "dla_mac_throughput_int4": "2048",
        "nmp_depthwise_conv": "32",
        "unit_nmp": "MACs/cycle"
      },
      "compute_utilization": {
        "dla_average": "81%",
        "nmp_average": "86% (bandwidth)"
      },
      "non_gemm_operations": {
        "active_cycles_ratio": "21%",
        "operations": "groupnorm, softmax, elementwise, perspective warp"
      },
      "quantization": "INT8 and INT4 with microscaling (block size 32)",
      "power_management_features": [
        "Independent SRAM bank retention/sleep modes",
        "Leaf-level clock gating (hardware-managed)",
        "Block-level clock gating (software-controlled)",
        "Root clock gating with 31-bit counter timer",
        "Fine-grained SRAM sleep state control per DNN layer"
      ],
      "dataflow": "Output-stationary, local-weight-stationary for high reuse",
      "software_stack": [
        "PyTorch quantization with per-layer configuration",
        "Quantization-aware training (QAT)",
        "Timeloop for GEMM mapping and loop nest optimization",
        "Kernel fusion (up to 384 kernels fused)"
      ],
      "key_features": [
        "Deep-Learning Accelerator (DLA) for GEMM/convolution",
        "Near-Memory Processor (NMP) for low-compute-intensity kernels",
        "Dedicated perspective warp engine for classical CV",
        "Race-to-sleep optimization for sub-5mW power budget",
        "Fully resident weights and activations in on-chip SRAM"
      ],
      "comparison_vs_sota": {
        "note": "Enabled end-to-end AoV execution without external memory"
      }
    },
    "page_images": [
      "images/31.9/page_1.png",
      "images/31.9/page_2.png",
      "images/31.9/page_3.png"
    ]
  }
]